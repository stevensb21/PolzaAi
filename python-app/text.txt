: '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_le
ngth': 127000, 'max_completion_tokens': 0, 'is_moderated': False}, 'per_request_
limits': None, 'supported_parameters': ['frequency_penalty', 'include_reasoning'
, 'max_tokens', 'presence_penalty', 'reasoning', 'temperature', 'top_k', 'top_p'
, 'web_search_options']}, {'id': 'perplexity/sonar', 'canonical_slug': 'perplexi
ty/sonar', 'name': 'Perplexity: Sonar', 'created': 1738013808, 'context_length':
 127072, 'architecture': {'input_modalities': ['text', 'image'], 'output_modalit
ies': ['text'], 'tokenizer': 'Other', 'instruct_type': None}, 'pricing': {'promp
t': '0.00008803', 'completion': '0.00008803', 'image': '0.00000000', 'request':
'0.44014200', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'i
nput_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provide
r': {'context_length': 127072, 'max_completion_tokens': 0, 'is_moderated': False
}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty', 'ma
x_tokens', 'presence_penalty', 'temperature', 'top_k', 'top_p', 'web_search_opti
ons']}, {'id': 'liquid/lfm-7b', 'canonical_slug': 'liquid/lfm-7b', 'name': 'Liqu
id: LFM 7B', 'created': 1737806883, 'context_length': 32768, 'architecture': {'i
nput_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Other',
 'instruct_type': 'chatml'}, 'pricing': {'prompt': '0.00000088', 'completion': '
0.00000088', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00
000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', '
input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 32768, 'ma
x_completion_tokens': 0, 'is_moderated': False}, 'per_request_limits': None, 'su
pported_parameters': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_tokens
', 'min_p', 'presence_penalty', 'repetition_penalty', 'response_format', 'seed',
 'stop', 'temperature', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'liquid/lfm-3
b', 'canonical_slug': 'liquid/lfm-3b', 'name': 'Liquid: LFM 3B', 'created': 1737
806501, 'context_length': 32768, 'architecture': {'input_modalities': ['text'],
'output_modalities': ['text'], 'tokenizer': 'Other', 'instruct_type': 'chatml'},
 'pricing': {'prompt': '0.00000176', 'completion': '0.00000176', 'image': '0.000
00000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning
': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000
000'}, 'top_provider': {'context_length': 32768, 'max_completion_tokens': 0, 'is
_moderated': False}, 'per_request_limits': None, 'supported_parameters': ['frequ
ency_penalty', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_penalty',
'seed', 'stop', 'temperature', 'top_k', 'top_p']}, {'id': 'deepseek/deepseek-r1-
distill-llama-70b', 'canonical_slug': 'deepseek/deepseek-r1-distill-llama-70b',
'name': 'DeepSeek: R1 Distill Llama 70B', 'created': 1737663169, 'context_length
': 131072, 'architecture': {'input_modalities': ['text'], 'output_modalities': [
'text'], 'tokenizer': 'Llama3', 'instruct_type': 'deepseek-r1'}, 'pricing': {'pr
ompt': '0.00000228', 'completion': '0.00000913', 'image': '0.00000000', 'request
': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000',
 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_prov
ider': {'context_length': 131072, 'max_completion_tokens': 0, 'is_moderated': Fa
lse}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty',
'include_reasoning', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_
penalty', 'reasoning', 'repetition_penalty', 'response_format', 'seed', 'stop',
'temperature', 'tool_choice', 'tools', 'top_k', 'top_logprobs', 'top_p']}, {'id'
: 'deepseek/deepseek-r1', 'canonical_slug': 'deepseek/deepseek-r1', 'name': 'Dee
pSeek: R1', 'created': 1737381095, 'context_length': 163840, 'architecture': {'i
nput_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'DeepSee
k', 'instruct_type': 'deepseek-r1'}, 'pricing': {'prompt': '0.00003521', 'comple
tion': '0.00017606', 'image': '0.00000000', 'request': '0.00000000', 'web_search
': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.0000
0000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 16
3840, 'max_completion_tokens': 163840, 'is_moderated': False}, 'per_request_limi
ts': None, 'supported_parameters': ['frequency_penalty', 'include_reasoning', 'l
ogit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'reasoning',
'repetition_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', '
temperature', 'tool_choice', 'tools', 'top_k', 'top_logprobs', 'top_p']}, {'id':
 'minimax/minimax-01', 'canonical_slug': 'minimax/minimax-01', 'name': 'MiniMax:
 MiniMax-01', 'created': 1736915462, 'context_length': 1000192, 'architecture':
{'input_modalities': ['text', 'image'], 'output_modalities': ['text'], 'tokenize
r': 'Other', 'instruct_type': None}, 'pricing': {'prompt': '0.00001761', 'comple
tion': '0.00009683', 'image': '0.00000000', 'request': '0.00000000', 'web_search
': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.0000
0000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 10
00192, 'max_completion_tokens': 1000192, 'is_moderated': False}, 'per_request_li
mits': None, 'supported_parameters': ['max_tokens', 'temperature', 'top_p']}, {'
id': 'mistralai/codestral-2501', 'canonical_slug': 'mistralai/codestral-2501', '
name': 'Mistral: Codestral 2501', 'created': 1736895522, 'context_length': 26214
4, 'architecture': {'input_modalities': ['text'], 'output_modalities': ['text'],
 'tokenizer': 'Mistral', 'instruct_type': None}, 'pricing': {'prompt': '0.000026
41', 'completion': '0.00007923', 'image': '0.00000000', 'request': '0.00000000',
 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_re
ad': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context
_length': 262144, 'max_completion_tokens': 0, 'is_moderated': False}, 'per_reque
st_limits': None, 'supported_parameters': ['frequency_penalty', 'max_tokens', 'p
resence_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temp
erature', 'tool_choice', 'tools', 'top_p']}, {'id': 'microsoft/phi-4', 'canonica
l_slug': 'microsoft/phi-4', 'name': 'Microsoft: Phi 4', 'created': 1736489872, '
context_length': 16384, 'architecture': {'input_modalities': ['text'], 'output_m
odalities': ['text'], 'tokenizer': 'Other', 'instruct_type': None}, 'pricing': {
'prompt': '0.00000528', 'completion': '0.00001232', 'image': '0.00000000', 'requ
est': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.0000000
0', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_p
rovider': {'context_length': 16384, 'max_completion_tokens': 0, 'is_moderated':
False}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty'
, 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'repetiti
on_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperatu
re', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'deepseek/deepseek-chat', 'canon
ical_slug': 'deepseek/deepseek-chat-v3', 'name': 'DeepSeek: DeepSeek V3', 'creat
ed': 1735241320, 'context_length': 163840, 'architecture': {'input_modalities':
['text'], 'output_modalities': ['text'], 'tokenizer': 'DeepSeek', 'instruct_type
': None}, 'pricing': {'prompt': '0.00001760', 'completion': '0.00007043', 'image
': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_
reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write':
 '0.00000000'}, 'top_provider': {'context_length': 163840, 'max_completion_token
s': 0, 'is_moderated': False}, 'per_request_limits': None, 'supported_parameters
': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'prese
nce_penalty', 'repetition_penalty', 'response_format', 'seed', 'stop', 'structur
ed_outputs', 'temperature', 'tool_choice', 'tools', 'top_k', 'top_logprobs', 'to
p_p']}, {'id': 'sao10k/l3.3-euryale-70b', 'canonical_slug': 'sao10k/l3.3-euryale
-70b-v2.3', 'name': 'Sao10K: Llama 3.3 Euryale 70B', 'created': 1734535928, 'con
text_length': 131072, 'architecture': {'input_modalities': ['text'], 'output_mod
alities': ['text'], 'tokenizer': 'Llama3', 'instruct_type': 'llama3'}, 'pricing'
: {'prompt': '0.00005722', 'completion': '0.00006602', 'image': '0.00000000', 'r
equest': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.0000
0000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'to
p_provider': {'context_length': 131072, 'max_completion_tokens': 16384, 'is_mode
rated': False}, 'per_request_limits': None, 'supported_parameters': ['frequency_
penalty', 'logit_bias', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_p
enalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperature',
 'top_k', 'top_p']}, {'id': 'openai/o1', 'canonical_slug': 'openai/o1-2024-12-17
', 'name': 'OpenAI: o1', 'created': 1734459999, 'context_length': 200000, 'archi
tecture': {'input_modalities': ['text', 'image'], 'output_modalities': ['text'],
 'tokenizer': 'GPT', 'instruct_type': None}, 'pricing': {'prompt': '0.00132043',
 'completion': '0.00528170', 'image': '1.90801557', 'request': '0.00000000', 'we
b_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read':
 '0.00066021', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_len
gth': 200000, 'max_completion_tokens': 100000, 'is_moderated': True}, 'per_reque
st_limits': None, 'supported_parameters': ['max_tokens', 'response_format', 'see
d', 'structured_outputs', 'tool_choice', 'tools']}, {'id': 'x-ai/grok-2-vision-1
212', 'canonical_slug': 'x-ai/grok-2-vision-1212', 'name': 'xAI: Grok 2 Vision 1
212', 'created': 1734237338, 'context_length': 32768, 'architecture': {'input_mo
dalities': ['text', 'image'], 'output_modalities': ['text'], 'tokenizer': 'Grok'
, 'instruct_type': None}, 'pricing': {'prompt': '0.00017606', 'completion': '0.0
0088028', 'image': '0.31690224', 'request': '0.00000000', 'web_search': '0.00000
000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'inp
ut_cache_write': '0.00000000'}, 'top_provider': {'context_length': 32768, 'max_c
ompletion_tokens': 0, 'is_moderated': False}, 'per_request_limits': None, 'suppo
rted_parameters': ['frequency_penalty', 'logprobs', 'max_tokens', 'presence_pena
lty', 'response_format', 'seed', 'stop', 'temperature', 'top_logprobs', 'top_p']
}, {'id': 'x-ai/grok-2-1212', 'canonical_slug': 'x-ai/grok-2-1212', 'name': 'xAI
: Grok 2 1212', 'created': 1734232814, 'context_length': 131072, 'architecture':
 {'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Gro
k', 'instruct_type': None}, 'pricing': {'prompt': '0.00017606', 'completion': '0
.00088028', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.000
00000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'i
nput_cache_write': '0.00000000'}, 'top_provider': {'context_length': 131072, 'ma
x_completion_tokens': 0, 'is_moderated': False}, 'per_request_limits': None, 'su
pported_parameters': ['frequency_penalty', 'logprobs', 'max_tokens', 'presence_p
enalty', 'response_format', 'seed', 'stop', 'temperature', 'tool_choice', 'tools
', 'top_logprobs', 'top_p']}, {'id': 'cohere/command-r7b-12-2024', 'canonical_sl
ug': 'cohere/command-r7b-12-2024', 'name': 'Cohere: Command R7B (12-2024)', 'cre
ated': 1734158152, 'context_length': 128000, 'architecture': {'input_modalities'
: ['text'], 'output_modalities': ['text'], 'tokenizer': 'Cohere', 'instruct_type
': None}, 'pricing': {'prompt': '0.00000330', 'completion': '0.00001320', 'image
': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_
reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write':
 '0.00000000'}, 'top_provider': {'context_length': 128000, 'max_completion_token
s': 4000, 'is_moderated': True}, 'per_request_limits': None, 'supported_paramete
rs': ['frequency_penalty', 'max_tokens', 'presence_penalty', 'response_format',
'seed', 'stop', 'structured_outputs', 'temperature', 'top_k', 'top_p']}, {'id':
'meta-llama/llama-3.3-70b-instruct', 'canonical_slug': 'meta-llama/llama-3.3-70b
-instruct', 'name': 'Meta: Llama 3.3 70B Instruct', 'created': 1733506137, 'cont
ext_length': 131072, 'architecture': {'input_modalities': ['text'], 'output_moda
lities': ['text'], 'tokenizer': 'Llama3', 'instruct_type': 'llama3'}, 'pricing':
 {'prompt': '0.00000335', 'completion': '0.00001056', 'image': '0.00000000', 're
quest': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000
000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top
_provider': {'context_length': 131072, 'max_completion_tokens': 16384, 'is_moder
ated': False}, 'per_request_limits': None, 'supported_parameters': ['frequency_p
enalty', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'r
epetition_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'te
mperature', 'tool_choice', 'tools', 'top_k', 'top_logprobs', 'top_p']}, {'id': '
amazon/nova-lite-v1', 'canonical_slug': 'amazon/nova-lite-v1', 'name': 'Amazon:
Nova Lite 1.0', 'created': 1733437363, 'context_length': 300000, 'architecture':
 {'input_modalities': ['text', 'image'], 'output_modalities': ['text'], 'tokeniz
er': 'Nova', 'instruct_type': None}, 'pricing': {'prompt': '0.00000528', 'comple
tion': '0.00002113', 'image': '0.00792256', 'request': '0.00000000', 'web_search
': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.0000
0000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 30
0000, 'max_completion_tokens': 5120, 'is_moderated': True}, 'per_request_limits'
: None, 'supported_parameters': ['max_tokens', 'stop', 'temperature', 'tools', '
top_k', 'top_p']}, {'id': 'amazon/nova-micro-v1', 'canonical_slug': 'amazon/nova
-micro-v1', 'name': 'Amazon: Nova Micro 1.0', 'created': 1733437237, 'context_le
ngth': 128000, 'architecture': {'input_modalities': ['text'], 'output_modalities
': ['text'], 'tokenizer': 'Nova', 'instruct_type': None}, 'pricing': {'prompt':
'0.00000308', 'completion': '0.00001232', 'image': '0.00000000', 'request': '0.0
0000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input
_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider':
{'context_length': 128000, 'max_completion_tokens': 5120, 'is_moderated': True},
 'per_request_limits': None, 'supported_parameters': ['max_tokens', 'stop', 'tem
perature', 'tools', 'top_k', 'top_p']}, {'id': 'amazon/nova-pro-v1', 'canonical_
slug': 'amazon/nova-pro-v1', 'name': 'Amazon: Nova Pro 1.0', 'created': 17334363
03, 'context_length': 300000, 'architecture': {'input_modalities': ['text', 'ima
ge'], 'output_modalities': ['text'], 'tokenizer': 'Nova', 'instruct_type': None}
, 'pricing': {'prompt': '0.00007042', 'completion': '0.00028169', 'image': '0.10
563408', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasonin
g': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.0000
0000'}, 'top_provider': {'context_length': 300000, 'max_completion_tokens': 5120
, 'is_moderated': True}, 'per_request_limits': None, 'supported_parameters': ['m
ax_tokens', 'stop', 'temperature', 'tools', 'top_k', 'top_p']}, {'id': 'qwen/qwq
-32b-preview', 'canonical_slug': 'qwen/qwq-32b-preview', 'name': 'Qwen: QwQ 32B
Preview', 'created': 1732754541, 'context_length': 32768, 'architecture': {'inpu
t_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Qwen', 'in
struct_type': 'deepseek-r1'}, 'pricing': {'prompt': '0.00001761', 'completion':
'0.00001761', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.0
0000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000',
'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 32768, 'm
ax_completion_tokens': 0, 'is_moderated': False}, 'per_request_limits': None, 's
upported_parameters': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_token
s', 'min_p', 'presence_penalty', 'repetition_penalty', 'seed', 'stop', 'temperat
ure', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'openai/gpt-4o-2024-11-20', 'ca
nonical_slug': 'openai/gpt-4o-2024-11-20', 'name': 'OpenAI: GPT-4o (2024-11-20)'
, 'created': 1732127594, 'context_length': 128000, 'architecture': {'input_modal
ities': ['text', 'image', 'file'], 'output_modalities': ['text'], 'tokenizer': '
GPT', 'instruct_type': None}, 'pricing': {'prompt': '0.00022007', 'completion':
'0.00088028', 'image': '0.31804661', 'request': '0.00000000', 'web_search': '0.0
0000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00011004',
'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 128000, '
max_completion_tokens': 16384, 'is_moderated': True}, 'per_request_limits': None
, 'supported_parameters': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_t
okens', 'presence_penalty', 'response_format', 'seed', 'stop', 'structured_outpu
ts', 'temperature', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'web_search
_options']}, {'id': 'mistralai/mistral-large-2411', 'canonical_slug': 'mistralai
/mistral-large-2411', 'name': 'Mistral Large 2411', 'created': 1731978685, 'cont
ext_length': 131072, 'architecture': {'input_modalities': ['text'], 'output_moda
lities': ['text'], 'tokenizer': 'Mistral', 'instruct_type': None}, 'pricing': {'
prompt': '0.00017606', 'completion': '0.00052817', 'image': '0.00000000', 'reque
st': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000
', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_pr
ovider': {'context_length': 131072, 'max_completion_tokens': 0, 'is_moderated':
False}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty'
, 'max_tokens', 'presence_penalty', 'response_format', 'seed', 'stop', 'structur
ed_outputs', 'temperature', 'tool_choice', 'tools', 'top_p']}, {'id': 'mistralai
/mistral-large-2407', 'canonical_slug': 'mistralai/mistral-large-2407', 'name':
'Mistral Large 2407', 'created': 1731978415, 'context_length': 131072, 'architec
ture': {'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer'
: 'Mistral', 'instruct_type': None}, 'pricing': {'prompt': '0.00017606', 'comple
tion': '0.00052817', 'image': '0.00000000', 'request': '0.00000000', 'web_search
': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.0000
0000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 13
1072, 'max_completion_tokens': 0, 'is_moderated': False}, 'per_request_limits':
None, 'supported_parameters': ['frequency_penalty', 'max_tokens', 'presence_pena
lty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperature', 't
ool_choice', 'tools', 'top_p']}, {'id': 'mistralai/pixtral-large-2411', 'canonic
al_slug': 'mistralai/pixtral-large-2411', 'name': 'Mistral: Pixtral Large 2411',
 'created': 1731977388, 'context_length': 131072, 'architecture': {'input_modali
ties': ['text', 'image'], 'output_modalities': ['text'], 'tokenizer': 'Mistral',
 'instruct_type': None}, 'pricing': {'prompt': '0.00017606', 'completion': '0.00
052817', 'image': '0.25422602', 'request': '0.00000000', 'web_search': '0.000000
00', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'inpu
t_cache_write': '0.00000000'}, 'top_provider': {'context_length': 131072, 'max_c
ompletion_tokens': 0, 'is_moderated': False}, 'per_request_limits': None, 'suppo
rted_parameters': ['frequency_penalty', 'max_tokens', 'presence_penalty', 'respo
nse_format', 'seed', 'stop', 'structured_outputs', 'temperature', 'tool_choice',
 'tools', 'top_p']}, {'id': 'x-ai/grok-vision-beta', 'canonical_slug': 'x-ai/gro
k-vision-beta', 'name': 'xAI: Grok Vision Beta', 'created': 1731976624, 'context
_length': 8192, 'architecture': {'input_modalities': ['text', 'image'], 'output_
modalities': ['text'], 'tokenizer': 'Grok', 'instruct_type': None}, 'pricing': {
'prompt': '0.00044014', 'completion': '0.00132043', 'image': '0.79225560', 'requ
est': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.0000000
0', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_p
rovider': {'context_length': 8192, 'max_completion_tokens': 0, 'is_moderated': F
alse}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty',
 'logprobs', 'max_tokens', 'presence_penalty', 'response_format', 'seed', 'stop'
, 'temperature', 'top_logprobs', 'top_p']}, {'id': 'infermatic/mn-inferor-12b',
'canonical_slug': 'infermatic/mn-inferor-12b', 'name': 'Infermatic: Mistral Nemo
 Inferor 12B', 'created': 1731464428, 'context_length': 8192, 'architecture': {'
input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Mistra
l', 'instruct_type': 'mistral'}, 'pricing': {'prompt': '0.00005282', 'completion
': '0.00008803', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '
0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000
', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 8192,
'max_completion_tokens': 8192, 'is_moderated': False}, 'per_request_limits': Non
e, 'supported_parameters': ['frequency_penalty', 'max_tokens', 'min_p', 'presenc
e_penalty', 'repetition_penalty', 'seed', 'stop', 'temperature', 'top_k', 'top_p
']}, {'id': 'qwen/qwen-2.5-coder-32b-instruct', 'canonical_slug': 'qwen/qwen-2.5
-coder-32b-instruct', 'name': 'Qwen2.5 Coder 32B Instruct', 'created': 173136840
0, 'context_length': 32768, 'architecture': {'input_modalities': ['text'], 'outp
ut_modalities': ['text'], 'tokenizer': 'Qwen', 'instruct_type': 'chatml'}, 'pric
ing': {'prompt': '0.00000440', 'completion': '0.00001761', 'image': '0.00000000'
, 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.
00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'},
 'top_provider': {'context_length': 32768, 'max_completion_tokens': 0, 'is_moder
ated': False}, 'per_request_limits': None, 'supported_parameters': ['frequency_p
enalty', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'r
epetition_penalty', 'response_format', 'seed', 'stop', 'temperature', 'top_k', '
top_logprobs', 'top_p']}, {'id': 'raifle/sorcererlm-8x22b', 'canonical_slug': 'r
aifle/sorcererlm-8x22b', 'name': 'SorcererLM 8x22B', 'created': 1731105083, 'con
text_length': 16000, 'architecture': {'input_modalities': ['text'], 'output_moda
lities': ['text'], 'tokenizer': 'Mistral', 'instruct_type': 'vicuna'}, 'pricing'
: {'prompt': '0.00039613', 'completion': '0.00039613', 'image': '0.00000000', 'r
equest': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.0000
0000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'to
p_provider': {'context_length': 16000, 'max_completion_tokens': 0, 'is_moderated
': False}, 'per_request_limits': None, 'supported_parameters': ['frequency_penal
ty', 'logit_bias', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_penalt
y', 'seed', 'stop', 'temperature', 'top_k', 'top_p']}, {'id': 'thedrummer/unslop
nemo-12b', 'canonical_slug': 'thedrummer/unslopnemo-12b', 'name': 'TheDrummer: U
nslopNemo 12B', 'created': 1731103448, 'context_length': 32768, 'architecture':
{'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Mist
ral', 'instruct_type': 'mistral'}, 'pricing': {'prompt': '0.00003521', 'completi
on': '0.00003521', 'image': '0.00000000', 'request': '0.00000000', 'web_search':
 '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.000000
00', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 3276
8, 'max_completion_tokens': 0, 'is_moderated': False}, 'per_request_limits': Non
e, 'supported_parameters': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_
tokens', 'min_p', 'presence_penalty', 'repetition_penalty', 'response_format', '
seed', 'stop', 'structured_outputs', 'temperature', 'tool_choice', 'tools', 'top
_k', 'top_p']}, {'id': 'anthropic/claude-3.5-haiku', 'canonical_slug': 'anthropi
c/claude-3-5-haiku', 'name': 'Anthropic: Claude 3.5 Haiku', 'created': 173067840
0, 'context_length': 200000, 'architecture': {'input_modalities': ['text', 'imag
e'], 'output_modalities': ['text'], 'tokenizer': 'Claude', 'instruct_type': None
}, 'pricing': {'prompt': '0.00007042', 'completion': '0.00035211', 'image': '0.0
0000000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoni
ng': '0.00000000', 'input_cache_read': '0.00000704', 'input_cache_write': '0.000
08803'}, 'top_provider': {'context_length': 200000, 'max_completion_tokens': 819
2, 'is_moderated': True}, 'per_request_limits': None, 'supported_parameters': ['
max_tokens', 'stop', 'temperature', 'tool_choice', 'tools', 'top_k', 'top_p']},
{'id': 'anthropic/claude-3.5-haiku-20241022', 'canonical_slug': 'anthropic/claud
e-3-5-haiku-20241022', 'name': 'Anthropic: Claude 3.5 Haiku (2024-10-22)', 'crea
ted': 1730678400, 'context_length': 200000, 'architecture': {'input_modalities':
 ['text', 'image', 'file'], 'output_modalities': ['text'], 'tokenizer': 'Claude'
, 'instruct_type': None}, 'pricing': {'prompt': '0.00007042', 'completion': '0.0
0035211', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000
000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000704', 'inp
ut_cache_write': '0.00008803'}, 'top_provider': {'context_length': 200000, 'max_
completion_tokens': 8192, 'is_moderated': False}, 'per_request_limits': None, 's
upported_parameters': ['max_tokens', 'stop', 'temperature', 'tool_choice', 'tool
s', 'top_k', 'top_p']}, {'id': 'anthracite-org/magnum-v4-72b', 'canonical_slug':
 'anthracite-org/magnum-v4-72b', 'name': 'Magnum v4 72B', 'created': 1729555200,
 'context_length': 16384, 'architecture': {'input_modalities': ['text'], 'output
_modalities': ['text'], 'tokenizer': 'Qwen', 'instruct_type': 'chatml'}, 'pricin
g': {'prompt': '0.00017606', 'completion': '0.00044014', 'image': '0.00000000',
'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00
000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, '
top_provider': {'context_length': 16384, 'max_completion_tokens': 2048, 'is_mode
rated': False}, 'per_request_limits': None, 'supported_parameters': ['frequency_
penalty', 'logit_bias', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_p
enalty', 'seed', 'stop', 'temperature', 'top_a', 'top_k', 'top_p']}, {'id': 'ant
hropic/claude-3.5-sonnet', 'canonical_slug': 'anthropic/claude-3.5-sonnet', 'nam
e': 'Anthropic: Claude 3.5 Sonnet', 'created': 1729555200, 'context_length': 200
000, 'architecture': {'input_modalities': ['text', 'image', 'file'], 'output_mod
alities': ['text'], 'tokenizer': 'Claude', 'instruct_type': None}, 'pricing': {'
prompt': '0.00026409', 'completion': '0.00132043', 'image': '0.42253632', 'reque
st': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000
', 'input_cache_read': '0.00002641', 'input_cache_write': '0.00033011'}, 'top_pr
ovider': {'context_length': 200000, 'max_completion_tokens': 8192, 'is_moderated
': True}, 'per_request_limits': None, 'supported_parameters': ['max_tokens', 'st
op', 'temperature', 'tool_choice', 'tools', 'top_k', 'top_p']}, {'id': 'mistrala
i/ministral-8b', 'canonical_slug': 'mistralai/ministral-8b', 'name': 'Mistral: M
inistral 8B', 'created': 1729123200, 'context_length': 128000, 'architecture': {
'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Mistr
al', 'instruct_type': None}, 'pricing': {'prompt': '0.00000880', 'completion': '
0.00000880', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00
000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', '
input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 128000, 'm
ax_completion_tokens': 0, 'is_moderated': False}, 'per_request_limits': None, 's
upported_parameters': ['frequency_penalty', 'max_tokens', 'presence_penalty', 'r
esponse_format', 'seed', 'stop', 'structured_outputs', 'temperature', 'tool_choi
ce', 'tools', 'top_p']}, {'id': 'mistralai/ministral-3b', 'canonical_slug': 'mis
tralai/ministral-3b', 'name': 'Mistral: Ministral 3B', 'created': 1729123200, 'c
ontext_length': 32768, 'architecture': {'input_modalities': ['text'], 'output_mo
dalities': ['text'], 'tokenizer': 'Mistral', 'instruct_type': None}, 'pricing':
{'prompt': '0.00000352', 'completion': '0.00000352', 'image': '0.00000000', 'req
uest': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.000000
00', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_
provider': {'context_length': 32768, 'max_completion_tokens': 0, 'is_moderated':
 False}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty
', 'max_tokens', 'presence_penalty', 'response_format', 'seed', 'stop', 'structu
red_outputs', 'temperature', 'top_p']}, {'id': 'qwen/qwen-2.5-7b-instruct', 'can
onical_slug': 'qwen/qwen-2.5-7b-instruct', 'name': 'Qwen2.5 7B Instruct', 'creat
ed': 1729036800, 'context_length': 65536, 'architecture': {'input_modalities': [
'text'], 'output_modalities': ['text'], 'tokenizer': 'Qwen', 'instruct_type': 'c
hatml'}, 'pricing': {'prompt': '0.00000352', 'completion': '0.00000880', 'image'
: '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_r
easoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write':
'0.00000000'}, 'top_provider': {'context_length': 65536, 'max_completion_tokens'
: 0, 'is_moderated': False}, 'per_request_limits': None, 'supported_parameters':
 ['frequency_penalty', 'logit_bias', 'max_tokens', 'min_p', 'presence_penalty',
'repetition_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', '
temperature', 'top_k', 'top_p']}, {'id': 'nvidia/llama-3.1-nemotron-70b-instruct
', 'canonical_slug': 'nvidia/llama-3.1-nemotron-70b-instruct', 'name': 'NVIDIA:
Llama 3.1 Nemotron 70B Instruct', 'created': 1728950400, 'context_length': 13107
2, 'architecture': {'input_modalities': ['text'], 'output_modalities': ['text'],
 'tokenizer': 'Llama3', 'instruct_type': 'llama3'}, 'pricing': {'prompt': '0.000
01056', 'completion': '0.00002641', 'image': '0.00000000', 'request': '0.0000000
0', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache
_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'cont
ext_length': 131072, 'max_completion_tokens': 16384, 'is_moderated': False}, 'pe
r_request_limits': None, 'supported_parameters': ['frequency_penalty', 'logit_bi
as', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_penalty', 'response_
format', 'seed', 'stop', 'temperature', 'tool_choice', 'tools', 'top_k', 'top_p'
]}, {'id': 'inflection/inflection-3-pi', 'canonical_slug': 'inflection/inflectio
n-3-pi', 'name': 'Inflection: Inflection 3 Pi', 'created': 1728604800, 'context_
length': 8000, 'architecture': {'input_modalities': ['text'], 'output_modalities
': ['text'], 'tokenizer': 'Other', 'instruct_type': None}, 'pricing': {'prompt':
 '0.00022007', 'completion': '0.00088028', 'image': '0.00000000', 'request': '0.
00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'inpu
t_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider':
 {'context_length': 8000, 'max_completion_tokens': 1024, 'is_moderated': False},
 'per_request_limits': None, 'supported_parameters': ['max_tokens', 'stop', 'tem
perature', 'top_p']}, {'id': 'inflection/inflection-3-productivity', 'canonical_
slug': 'inflection/inflection-3-productivity', 'name': 'Inflection: Inflection 3
 Productivity', 'created': 1728604800, 'context_length': 8000, 'architecture': {
'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Other
', 'instruct_type': None}, 'pricing': {'prompt': '0.00022007', 'completion': '0.
00088028', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.0000
0000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'in
put_cache_write': '0.00000000'}, 'top_provider': {'context_length': 8000, 'max_c
ompletion_tokens': 1024, 'is_moderated': False}, 'per_request_limits': None, 'su
pported_parameters': ['max_tokens', 'stop', 'temperature', 'top_p']}, {'id': 'go
ogle/gemini-flash-1.5-8b', 'canonical_slug': 'google/gemini-flash-1.5-8b', 'name
': 'Google: Gemini 1.5 Flash 8B', 'created': 1727913600, 'context_length': 10000
00, 'architecture': {'input_modalities': ['text', 'image'], 'output_modalities':
 ['text'], 'tokenizer': 'Gemini', 'instruct_type': None}, 'pricing': {'prompt':
'0.00000330', 'completion': '0.00001320', 'image': '0.00000000', 'request': '0.0
0000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input
_cache_read': '0.00000088', 'input_cache_write': '0.00000513'}, 'top_provider':
{'context_length': 1000000, 'max_completion_tokens': 8192, 'is_moderated': False
}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty', 'ma
x_tokens', 'presence_penalty', 'response_format', 'seed', 'stop', 'structured_ou
tputs', 'temperature', 'tool_choice', 'tools', 'top_p']}, {'id': 'anthracite-org
/magnum-v2-72b', 'canonical_slug': 'anthracite-org/magnum-v2-72b', 'name': 'Magn
um v2 72B', 'created': 1727654400, 'context_length': 32768, 'architecture': {'in
put_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Qwen', '
instruct_type': 'chatml'}, 'pricing': {'prompt': '0.00026409', 'completion': '0.
00026409', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.0000
0000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'in
put_cache_write': '0.00000000'}, 'top_provider': {'context_length': 32768, 'max_
completion_tokens': 0, 'is_moderated': False}, 'per_request_limits': None, 'supp
orted_parameters': ['frequency_penalty', 'logit_bias', 'max_tokens', 'min_p', 'p
resence_penalty', 'repetition_penalty', 'seed', 'stop', 'temperature', 'top_k',
'top_p']}, {'id': 'thedrummer/rocinante-12b', 'canonical_slug': 'thedrummer/roci
nante-12b', 'name': 'TheDrummer: Rocinante 12B', 'created': 1727654400, 'context
_length': 32768, 'architecture': {'input_modalities': ['text'], 'output_modaliti
es': ['text'], 'tokenizer': 'Qwen', 'instruct_type': 'chatml'}, 'pricing': {'pro
mpt': '0.00001496', 'completion': '0.00003785', 'image': '0.00000000', 'request'
: '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000',
'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provi
der': {'context_length': 32768, 'max_completion_tokens': 0, 'is_moderated': Fals
e}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty', 'l
ogit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_p
enalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperature',
 'tool_choice', 'tools', 'top_k', 'top_p']}, {'id': 'meta-llama/llama-3.2-1b-ins
truct', 'canonical_slug': 'meta-llama/llama-3.2-1b-instruct', 'name': 'Meta: Lla
ma 3.2 1B Instruct', 'created': 1727222400, 'context_length': 131072, 'architect
ure': {'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer':
 'Llama3', 'instruct_type': 'llama3'}, 'pricing': {'prompt': '0.00000044', 'comp
letion': '0.00000088', 'image': '0.00000000', 'request': '0.00000000', 'web_sear
ch': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00
000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length':
131072, 'max_completion_tokens': 16384, 'is_moderated': False}, 'per_request_lim
its': None, 'supported_parameters': ['frequency_penalty', 'logit_bias', 'max_tok
ens', 'min_p', 'presence_penalty', 'repetition_penalty', 'response_format', 'see
d', 'stop', 'structured_outputs', 'temperature', 'top_k', 'top_logprobs', 'top_p
']}, {'id': 'meta-llama/llama-3.2-11b-vision-instruct', 'canonical_slug': 'meta-
llama/llama-3.2-11b-vision-instruct', 'name': 'Meta: Llama 3.2 11B Vision Instru
ct', 'created': 1727222400, 'context_length': 131072, 'architecture': {'input_mo
dalities': ['text', 'image'], 'output_modalities': ['text'], 'tokenizer': 'Llama
3', 'instruct_type': 'llama3'}, 'pricing': {'prompt': '0.00000431', 'completion'
: '0.00000431', 'image': '0.00699650', 'request': '0.00000000', 'web_search': '0
.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000'
, 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 131072,
 'max_completion_tokens': 16384, 'is_moderated': False}, 'per_request_limits': N
one, 'supported_parameters': ['frequency_penalty', 'logit_bias', 'max_tokens', '
min_p', 'presence_penalty', 'repetition_penalty', 'response_format', 'seed', 'st
op', 'structured_outputs', 'temperature', 'top_k', 'top_logprobs', 'top_p']}, {'
id': 'meta-llama/llama-3.2-3b-instruct', 'canonical_slug': 'meta-llama/llama-3.2
-3b-instruct', 'name': 'Meta: Llama 3.2 3B Instruct', 'created': 1727222400, 'co
ntext_length': 20000, 'architecture': {'input_modalities': ['text'], 'output_mod
alities': ['text'], 'tokenizer': 'Llama3', 'instruct_type': 'llama3'}, 'pricing'
: {'prompt': '0.00000026', 'completion': '0.00000053', 'image': '0.00000000', 'r
equest': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.0000
0000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'to
p_provider': {'context_length': 20000, 'max_completion_tokens': 20000, 'is_moder
ated': False}, 'per_request_limits': None, 'supported_parameters': ['frequency_p
enalty', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'r
epetition_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'te
mperature', 'tool_choice', 'tools', 'top_k', 'top_logprobs', 'top_p']}, {'id': '
meta-llama/llama-3.2-90b-vision-instruct', 'canonical_slug': 'meta-llama/llama-3
.2-90b-vision-instruct', 'name': 'Meta: Llama 3.2 90B Vision Instruct', 'created
': 1727222400, 'context_length': 32768, 'architecture': {'input_modalities': ['t
ext', 'image'], 'output_modalities': ['text'], 'tokenizer': 'Llama3', 'instruct_
type': 'llama3'}, 'pricing': {'prompt': '0.00003081', 'completion': '0.00003521'
, 'image': '0.04452476', 'request': '0.00000000', 'web_search': '0.00000000', 'i
nternal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache
_write': '0.00000000'}, 'top_provider': {'context_length': 32768, 'max_completio
n_tokens': 16384, 'is_moderated': False}, 'per_request_limits': None, 'supported
_parameters': ['frequency_penalty', 'max_tokens', 'min_p', 'presence_penalty', '
repetition_penalty', 'response_format', 'seed', 'stop', 'temperature', 'top_k',
'top_p']}, {'id': 'qwen/qwen-2.5-72b-instruct', 'canonical_slug': 'qwen/qwen-2.5
-72b-instruct', 'name': 'Qwen2.5 72B Instruct', 'created': 1726704000, 'context_
length': 32768, 'architecture': {'input_modalities': ['text'], 'output_modalitie
s': ['text'], 'tokenizer': 'Qwen', 'instruct_type': 'chatml'}, 'pricing': {'prom
pt': '0.00000456', 'completion': '0.00001826', 'image': '0.00000000', 'request':
 '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', '
input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provid
er': {'context_length': 32768, 'max_completion_tokens': 0, 'is_moderated': False
}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty', 'lo
git_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_pe
nalty', 'response_format', 'seed', 'stop', 'temperature', 'tool_choice', 'tools'
, 'top_k', 'top_logprobs', 'top_p']}, {'id': 'neversleep/llama-3.1-lumimaid-8b',
 'canonical_slug': 'neversleep/llama-3.1-lumimaid-8b', 'name': 'NeverSleep: Lumi
maid v0.2 8B', 'created': 1726358400, 'context_length': 32768, 'architecture': {
'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Llama
3', 'instruct_type': 'llama3'}, 'pricing': {'prompt': '0.00000792', 'completion'
: '0.00005282', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0
.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000'
, 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 32768,
'max_completion_tokens': 0, 'is_moderated': False}, 'per_request_limits': None,
'supported_parameters': ['frequency_penalty', 'logit_bias', 'max_tokens', 'min_p
', 'presence_penalty', 'repetition_penalty', 'response_format', 'seed', 'stop',
'structured_outputs', 'temperature', 'top_a', 'top_k', 'top_p']}, {'id': 'openai
/o1-mini', 'canonical_slug': 'openai/o1-mini', 'name': 'OpenAI: o1-mini', 'creat
ed': 1726099200, 'context_length': 128000, 'architecture': {'input_modalities':
['text'], 'output_modalities': ['text'], 'tokenizer': 'GPT', 'instruct_type': No
ne}, 'pricing': {'prompt': '0.00009683', 'completion': '0.00038732', 'image': '0
.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reaso
ning': '0.00000000', 'input_cache_read': '0.00004842', 'input_cache_write': '0.0
0000000'}, 'top_provider': {'context_length': 128000, 'max_completion_tokens': 6
5536, 'is_moderated': True}, 'per_request_limits': None, 'supported_parameters':
 ['max_tokens', 'seed']}, {'id': 'openai/o1-mini-2024-09-12', 'canonical_slug':
'openai/o1-mini-2024-09-12', 'name': 'OpenAI: o1-mini (2024-09-12)', 'created':
1726099200, 'context_length': 128000, 'architecture': {'input_modalities': ['tex
t'], 'output_modalities': ['text'], 'tokenizer': 'GPT', 'instruct_type': None},
'pricing': {'prompt': '0.00009683', 'completion': '0.00038732', 'image': '0.0000
0000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning'
: '0.00000000', 'input_cache_read': '0.00004842', 'input_cache_write': '0.000000
00'}, 'top_provider': {'context_length': 128000, 'max_completion_tokens': 65536,
 'is_moderated': True}, 'per_request_limits': None, 'supported_parameters': ['ma
x_tokens', 'seed']}, {'id': 'mistralai/pixtral-12b', 'canonical_slug': 'mistrala
i/pixtral-12b', 'name': 'Mistral: Pixtral 12B', 'created': 1725926400, 'context_
length': 32768, 'architecture': {'input_modalities': ['text', 'image'], 'output_
modalities': ['text'], 'tokenizer': 'Mistral', 'instruct_type': None}, 'pricing'
: {'prompt': '0.00000880', 'completion': '0.00000880', 'image': '0.01272010', 'r
equest': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.0000
0000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'to
p_provider': {'context_length': 32768, 'max_completion_tokens': 0, 'is_moderated
': False}, 'per_request_limits': None, 'supported_parameters': ['frequency_penal
ty', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'repet
ition_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temper
ature', 'tool_choice', 'tools', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'cohe
re/command-r-08-2024', 'canonical_slug': 'cohere/command-r-08-2024', 'name': 'Co
here: Command R (08-2024)', 'created': 1724976000, 'context_length': 128000, 'ar
chitecture': {'input_modalities': ['text'], 'output_modalities': ['text'], 'toke
nizer': 'Cohere', 'instruct_type': None}, 'pricing': {'prompt': '0.00001320', 'c
ompletion': '0.00005282', 'image': '0.00000000', 'request': '0.00000000', 'web_s
earch': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0
.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length
': 128000, 'max_completion_tokens': 4000, 'is_moderated': True}, 'per_request_li
mits': None, 'supported_parameters': ['frequency_penalty', 'max_tokens', 'presen
ce_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperatu
re', 'tools', 'top_k', 'top_p']}, {'id': 'cohere/command-r-plus-08-2024', 'canon
ical_slug': 'cohere/command-r-plus-08-2024', 'name': 'Cohere: Command R+ (08-202
4)', 'created': 1724976000, 'context_length': 128000, 'architecture': {'input_mo
dalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Cohere', 'inst
ruct_type': None}, 'pricing': {'prompt': '0.00022007', 'completion': '0.00088028
', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', '
internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cach
e_write': '0.00000000'}, 'top_provider': {'context_length': 128000, 'max_complet
ion_tokens': 4000, 'is_moderated': True}, 'per_request_limits': None, 'supported
_parameters': ['frequency_penalty', 'max_tokens', 'presence_penalty', 'response_
format', 'seed', 'stop', 'structured_outputs', 'temperature', 'tools', 'top_k',
'top_p']}, {'id': 'sao10k/l3.1-euryale-70b', 'canonical_slug': 'sao10k/l3.1-eury
ale-70b', 'name': 'Sao10K: Llama 3.1 Euryale 70B v2.2', 'created': 1724803200, '
context_length': 32768, 'architecture': {'input_modalities': ['text'], 'output_m
odalities': ['text'], 'tokenizer': 'Llama3', 'instruct_type': 'llama3'}, 'pricin
g': {'prompt': '0.00005722', 'completion': '0.00006602', 'image': '0.00000000',
'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00
000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, '
top_provider': {'context_length': 32768, 'max_completion_tokens': 0, 'is_moderat
ed': False}, 'per_request_limits': None, 'supported_parameters': ['frequency_pen
alty', 'logit_bias', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_pena
lty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperature', 't
op_k', 'top_p']}, {'id': 'qwen/qwen-2.5-vl-7b-instruct', 'canonical_slug': 'qwen
/qwen-2-vl-7b-instruct', 'name': 'Qwen: Qwen2.5-VL 7B Instruct', 'created': 1724
803200, 'context_length': 32768, 'architecture': {'input_modalities': ['text', '
image'], 'output_modalities': ['text'], 'tokenizer': 'Qwen', 'instruct_type': No
ne}, 'pricing': {'prompt': '0.00001761', 'completion': '0.00001761', 'image': '0
.01272010', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reaso
ning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.0
0000000'}, 'top_provider': {'context_length': 32768, 'max_completion_tokens': 0,
 'is_moderated': False}, 'per_request_limits': None, 'supported_parameters': ['f
requency_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_pe
nalty', 'repetition_penalty', 'response_format', 'seed', 'stop', 'structured_out
puts', 'temperature', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'microsoft/phi-
3.5-mini-128k-instruct', 'canonical_slug': 'microsoft/phi-3.5-mini-128k-instruct
', 'name': 'Microsoft: Phi-3.5 Mini 128K Instruct', 'created': 1724198400, 'cont
ext_length': 128000, 'architecture': {'input_modalities': ['text'], 'output_moda
lities': ['text'], 'tokenizer': 'Other', 'instruct_type': 'phi3'}, 'pricing': {'
prompt': '0.00000880', 'completion': '0.00000880', 'image': '0.00000000', 'reque
st': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000
', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_pr
ovider': {'context_length': 128000, 'max_completion_tokens': 0, 'is_moderated':
False}, 'per_request_limits': None, 'supported_parameters': ['max_tokens', 'temp
erature', 'tool_choice', 'tools', 'top_p']}, {'id': 'nousresearch/hermes-3-llama
-3.1-70b', 'canonical_slug': 'nousresearch/hermes-3-llama-3.1-70b', 'name': 'Nou
s: Hermes 3 70B Instruct', 'created': 1723939200, 'context_length': 131072, 'arc
hitecture': {'input_modalities': ['text'], 'output_modalities': ['text'], 'token
izer': 'Llama3', 'instruct_type': 'chatml'}, 'pricing': {'prompt': '0.00000880',
 'completion': '0.00002465', 'image': '0.00000000', 'request': '0.00000000', 'we
b_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read':
 '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_len
gth': 131072, 'max_completion_tokens': 0, 'is_moderated': False}, 'per_request_l
imits': None, 'supported_parameters': ['frequency_penalty', 'logit_bias', 'logpr
obs', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_penalty', 'response
_format', 'seed', 'stop', 'structured_outputs', 'temperature', 'tool_choice', 't
ools', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'nousresearch/hermes-3-llama-3
.1-405b', 'canonical_slug': 'nousresearch/hermes-3-llama-3.1-405b', 'name': 'Nou
s: Hermes 3 405B Instruct', 'created': 1723766400, 'context_length': 131072, 'ar
chitecture': {'input_modalities': ['text'], 'output_modalities': ['text'], 'toke
nizer': 'Llama3', 'instruct_type': 'chatml'}, 'pricing': {'prompt': '0.00006162'
, 'completion': '0.00007042', 'image': '0.00000000', 'request': '0.00000000', 'w
eb_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read'
: '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_le
ngth': 131072, 'max_completion_tokens': 16384, 'is_moderated': False}, 'per_requ
est_limits': None, 'supported_parameters': ['frequency_penalty', 'logit_bias', '
logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_penalty', 'res
ponse_format', 'seed', 'stop', 'temperature', 'top_k', 'top_logprobs', 'top_p']}
, {'id': 'openai/chatgpt-4o-latest', 'canonical_slug': 'openai/chatgpt-4o-latest
', 'name': 'OpenAI: ChatGPT-4o', 'created': 1723593600, 'context_length': 128000
, 'architecture': {'input_modalities': ['text', 'image'], 'output_modalities': [
'text'], 'tokenizer': 'GPT', 'instruct_type': None}, 'pricing': {'prompt': '0.00
044014', 'completion': '0.00132043', 'image': '0.63600519', 'request': '0.000000
00', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cach
e_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'con
text_length': 128000, 'max_completion_tokens': 16384, 'is_moderated': True}, 'pe
r_request_limits': None, 'supported_parameters': ['frequency_penalty', 'logit_bi
as', 'logprobs', 'max_tokens', 'presence_penalty', 'response_format', 'seed', 's
top', 'structured_outputs', 'temperature', 'top_logprobs', 'top_p']}, {'id': 'sa
o10k/l3-lunaris-8b', 'canonical_slug': 'sao10k/l3-lunaris-8b', 'name': 'Sao10K:
Llama 3 8B Lunaris', 'created': 1723507200, 'context_length': 8192, 'architectur
e': {'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': '
Llama3', 'instruct_type': 'llama3'}, 'pricing': {'prompt': '0.00000176', 'comple
tion': '0.00000440', 'image': '0.00000000', 'request': '0.00000000', 'web_search
': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.0000
0000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 81
92, 'max_completion_tokens': 0, 'is_moderated': False}, 'per_request_limits': No
ne, 'supported_parameters': ['frequency_penalty', 'logit_bias', 'max_tokens', 'm
in_p', 'presence_penalty', 'repetition_penalty', 'response_format', 'seed', 'sto
p', 'temperature', 'top_k', 'top_p']}, {'id': 'openai/gpt-4o-2024-08-06', 'canon
ical_slug': 'openai/gpt-4o-2024-08-06', 'name': 'OpenAI: GPT-4o (2024-08-06)', '
created': 1722902400, 'context_length': 128000, 'architecture': {'input_modaliti
es': ['text', 'image', 'file'], 'output_modalities': ['text'], 'tokenizer': 'GPT
', 'instruct_type': None}, 'pricing': {'prompt': '0.00022007', 'completion': '0.
00088028', 'image': '0.31804661', 'request': '0.00000000', 'web_search': '0.0000
0000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00011004', 'in
put_cache_write': '0.00000000'}, 'top_provider': {'context_length': 128000, 'max
_completion_tokens': 16384, 'is_moderated': False}, 'per_request_limits': None,
'supported_parameters': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_tok
ens', 'presence_penalty', 'response_format', 'seed', 'stop', 'structured_outputs
', 'temperature', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'web_search_o
ptions']}, {'id': 'meta-llama/llama-3.1-405b', 'canonical_slug': 'meta-llama/lla
ma-3.1-405b', 'name': 'Meta: Llama 3.1 405B (base)', 'created': 1722556800, 'con
text_length': 32768, 'architecture': {'input_modalities': ['text'], 'output_moda
lities': ['text'], 'tokenizer': 'Llama3', 'instruct_type': 'none'}, 'pricing': {
'prompt': '0.00017606', 'completion': '0.00017606', 'image': '0.00000000', 'requ
est': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.0000000
0', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_p
rovider': {'context_length': 32768, 'max_completion_tokens': 0, 'is_moderated':
False}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty'
, 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'repetiti
on_penalty', 'seed', 'stop', 'temperature', 'top_k', 'top_logprobs', 'top_p']},
{'id': 'meta-llama/llama-3.1-8b-instruct', 'canonical_slug': 'meta-llama/llama-3
.1-8b-instruct', 'name': 'Meta: Llama 3.1 8B Instruct', 'created': 1721692800, '
context_length': 131072, 'architecture': {'input_modalities': ['text'], 'output_
modalities': ['text'], 'tokenizer': 'Llama3', 'instruct_type': 'llama3'}, 'prici
ng': {'prompt': '0.00000132', 'completion': '0.00000176', 'image': '0.00000000',
 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.0
0000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'},
'top_provider': {'context_length': 131072, 'max_completion_tokens': 16384, 'is_m
oderated': False}, 'per_request_limits': None, 'supported_parameters': ['frequen
cy_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty'
, 'repetition_penalty', 'response_format', 'seed', 'stop', 'structured_outputs',
 'temperature', 'tool_choice', 'tools', 'top_k', 'top_logprobs', 'top_p']}, {'id
': 'meta-llama/llama-3.1-70b-instruct', 'canonical_slug': 'meta-llama/llama-3.1-
70b-instruct', 'name': 'Meta: Llama 3.1 70B Instruct', 'created': 1721692800, 'c
ontext_length': 131072, 'architecture': {'input_modalities': ['text'], 'output_m
odalities': ['text'], 'tokenizer': 'Llama3', 'instruct_type': 'llama3'}, 'pricin
g': {'prompt': '0.00000880', 'completion': '0.00002465', 'image': '0.00000000',
'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00
000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, '
top_provider': {'context_length': 131072, 'max_completion_tokens': 16384, 'is_mo
derated': False}, 'per_request_limits': None, 'supported_parameters': ['frequenc
y_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty',
 'repetition_penalty', 'response_format', 'seed', 'stop', 'structured_outputs',
'temperature', 'tool_choice', 'tools', 'top_k', 'top_logprobs', 'top_p']}, {'id'
: 'meta-llama/llama-3.1-405b-instruct', 'canonical_slug': 'meta-llama/llama-3.1-
405b-instruct', 'name': 'Meta: Llama 3.1 405B Instruct', 'created': 1721692800,
'context_length': 32768, 'architecture': {'input_modalities': ['text'], 'output_
modalities': ['text'], 'tokenizer': 'Llama3', 'instruct_type': 'llama3'}, 'prici
ng': {'prompt': '0.00007042', 'completion': '0.00007042', 'image': '0.00000000',
 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.0
0000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'},
'top_provider': {'context_length': 32768, 'max_completion_tokens': 16384, 'is_mo
derated': False}, 'per_request_limits': None, 'supported_parameters': ['frequenc
y_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty',
 'repetition_penalty', 'response_format', 'seed', 'stop', 'structured_outputs',
'temperature', 'tool_choice', 'tools', 'top_k', 'top_logprobs', 'top_p']}, {'id'
: 'mistralai/mistral-nemo', 'canonical_slug': 'mistralai/mistral-nemo', 'name':
'Mistral: Mistral Nemo', 'created': 1721347200, 'context_length': 32000, 'archit
ecture': {'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenize
r': 'Mistral', 'instruct_type': 'mistral'}, 'pricing': {'prompt': '0.00000066',
'completion': '0.00000440', 'image': '0.00000000', 'request': '0.00000000', 'web
_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read':
'0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_leng
th': 32000, 'max_completion_tokens': 0, 'is_moderated': False}, 'per_request_lim
its': None, 'supported_parameters': ['frequency_penalty', 'logit_bias', 'logprob
s', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_penalty', 'response_f
ormat', 'seed', 'stop', 'structured_outputs', 'temperature', 'tool_choice', 'too
ls', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'openai/gpt-4o-mini', 'canonical
_slug': 'openai/gpt-4o-mini', 'name': 'OpenAI: GPT-4o-mini', 'created': 17212608
00, 'context_length': 128000, 'architecture': {'input_modalities': ['text', 'ima
ge', 'file'], 'output_modalities': ['text'], 'tokenizer': 'GPT', 'instruct_type'
: None}, 'pricing': {'prompt': '0.00001320', 'completion': '0.00005282', 'image'
: '0.01910216', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_r
easoning': '0.00000000', 'input_cache_read': '0.00000660', 'input_cache_write':
'0.00000000'}, 'top_provider': {'context_length': 128000, 'max_completion_tokens
': 16384, 'is_moderated': True}, 'per_request_limits': None, 'supported_paramete
rs': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'presence_pen
alty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperature', '
tool_choice', 'tools', 'top_logprobs', 'top_p', 'web_search_options']}, {'id': '
openai/gpt-4o-mini-2024-07-18', 'canonical_slug': 'openai/gpt-4o-mini-2024-07-18
', 'name': 'OpenAI: GPT-4o-mini (2024-07-18)', 'created': 1721260800, 'context_l
ength': 128000, 'architecture': {'input_modalities': ['text', 'image', 'file'],
'output_modalities': ['text'], 'tokenizer': 'GPT', 'instruct_type': None}, 'pric
ing': {'prompt': '0.00001320', 'completion': '0.00005282', 'image': '0.63600519'
, 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.
00000000', 'input_cache_read': '0.00000660', 'input_cache_write': '0.00000000'},
 'top_provider': {'context_length': 128000, 'max_completion_tokens': 16384, 'is_
moderated': True}, 'per_request_limits': None, 'supported_parameters': ['frequen
cy_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'presence_penalty', 'respon
se_format', 'seed', 'stop', 'structured_outputs', 'temperature', 'tool_choice',
'tools', 'top_logprobs', 'top_p', 'web_search_options']}, {'id': 'google/gemma-2
-27b-it', 'canonical_slug': 'google/gemma-2-27b-it', 'name': 'Google: Gemma 2 27
B', 'created': 1720828800, 'context_length': 8192, 'architecture': {'input_modal
ities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Gemini', 'instruc
t_type': 'gemma'}, 'pricing': {'prompt': '0.00005722', 'completion': '0.00005722
', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', '
internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cach
e_write': '0.00000000'}, 'top_provider': {'context_length': 8192, 'max_completio
n_tokens': 0, 'is_moderated': False}, 'per_request_limits': None, 'supported_par
ameters': ['frequency_penalty', 'max_tokens', 'presence_penalty', 'response_form
at', 'stop', 'structured_outputs', 'temperature', 'top_p']}, {'id': 'google/gemm
a-2-9b-it', 'canonical_slug': 'google/gemma-2-9b-it', 'name': 'Google: Gemma 2 9
B', 'created': 1719532800, 'context_length': 8192, 'architecture': {'input_modal
ities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Gemini', 'instruc
t_type': 'gemma'}, 'pricing': {'prompt': '0.00000088', 'completion': '0.00000088
', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', '
internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cach
e_write': '0.00000000'}, 'top_provider': {'context_length': 8192, 'max_completio
n_tokens': 8192, 'is_moderated': False}, 'per_request_limits': None, 'supported_
parameters': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'min_
p', 'presence_penalty', 'repetition_penalty', 'response_format', 'seed', 'stop',
 'temperature', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'anthropic/claude-3.5
-sonnet-20240620', 'canonical_slug': 'anthropic/claude-3.5-sonnet-20240620', 'na
me': 'Anthropic: Claude 3.5 Sonnet (2024-06-20)', 'created': 1718841600, 'contex
t_length': 200000, 'architecture': {'input_modalities': ['text', 'image', 'file'
], 'output_modalities': ['text'], 'tokenizer': 'Claude', 'instruct_type': None},
 'pricing': {'prompt': '0.00026409', 'completion': '0.00132043', 'image': '0.422
53632', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning
': '0.00000000', 'input_cache_read': '0.00002641', 'input_cache_write': '0.00033
011'}, 'top_provider': {'context_length': 200000, 'max_completion_tokens': 8192,
 'is_moderated': True}, 'per_request_limits': None, 'supported_parameters': ['ma
x_tokens', 'stop', 'temperature', 'tool_choice', 'tools', 'top_k', 'top_p']}, {'
id': 'sao10k/l3-euryale-70b', 'canonical_slug': 'sao10k/l3-euryale-70b', 'name':
 'Sao10k: Llama 3 Euryale 70B v2.1', 'created': 1718668800, 'context_length': 81
92, 'architecture': {'input_modalities': ['text'], 'output_modalities': ['text']
, 'tokenizer': 'Llama3', 'instruct_type': 'llama3'}, 'pricing': {'prompt': '0.00
013028', 'completion': '0.00013028', 'image': '0.00000000', 'request': '0.000000
00', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cach
e_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'con
text_length': 8192, 'max_completion_tokens': 8192, 'is_moderated': False}, 'per_
request_limits': None, 'supported_parameters': ['frequency_penalty', 'logit_bias
', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_penalty', 'seed', 'sto
p', 'temperature', 'top_k', 'top_p']}, {'id': 'cognitivecomputations/dolphin-mix
tral-8x22b', 'canonical_slug': 'cognitivecomputations/dolphin-mixtral-8x22b', 'n
ame': 'Dolphin 2.9.2 Mixtral 8x22B ', 'created': 1717804800, 'context_length':
 16000, 'architecture': {'input_modalities': ['text'], 'output_modalities': ['te
xt'], 'tokenizer': 'Mistral', 'instruct_type': 'chatml'}, 'pricing': {'prompt':
'0.00007923', 'completion': '0.00007923', 'image': '0.00000000', 'request': '0.0
0000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input
_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider':
{'context_length': 16000, 'max_completion_tokens': 8192, 'is_moderated': False},
 'per_request_limits': None, 'supported_parameters': ['frequency_penalty', 'logi
t_bias', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_penalty', 'seed'
, 'stop', 'temperature', 'top_k', 'top_p']}, {'id': 'qwen/qwen-2-72b-instruct',
'canonical_slug': 'qwen/qwen-2-72b-instruct', 'name': 'Qwen 2 72B Instruct', 'cr
eated': 1717718400, 'context_length': 32768, 'architecture': {'input_modalities'
: ['text'], 'output_modalities': ['text'], 'tokenizer': 'Qwen', 'instruct_type':
 'chatml'}, 'pricing': {'prompt': '0.00007923', 'completion': '0.00007923', 'ima
ge': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'interna
l_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write
': '0.00000000'}, 'top_provider': {'context_length': 32768, 'max_completion_toke
ns': 4096, 'is_moderated': False}, 'per_request_limits': None, 'supported_parame
ters': ['frequency_penalty', 'logit_bias', 'max_tokens', 'min_p', 'presence_pena
lty', 'repetition_penalty', 'stop', 'temperature', 'top_k', 'top_p']}, {'id': 'm
istralai/mistral-7b-instruct-v0.3', 'canonical_slug': 'mistralai/mistral-7b-inst
ruct-v0.3', 'name': 'Mistral: Mistral 7B Instruct v0.3', 'created': 1716768000,
'context_length': 32768, 'architecture': {'input_modalities': ['text'], 'output_
modalities': ['text'], 'tokenizer': 'Mistral', 'instruct_type': 'mistral'}, 'pri
cing': {'prompt': '0.00000246', 'completion': '0.00000475', 'image': '0.00000000
', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0
.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}
, 'top_provider': {'context_length': 32768, 'max_completion_tokens': 16384, 'is_
moderated': False}, 'per_request_limits': None, 'supported_parameters': ['freque
ncy_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty
', 'repetition_penalty', 'response_format', 'seed', 'stop', 'temperature', 'tool
_choice', 'tools', 'top_k', 'top_p']}, {'id': 'mistralai/mistral-7b-instruct', '
canonical_slug': 'mistralai/mistral-7b-instruct', 'name': 'Mistral: Mistral 7B I
nstruct', 'created': 1716768000, 'context_length': 32768, 'architecture': {'inpu
t_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Mistral',
'instruct_type': 'mistral'}, 'pricing': {'prompt': '0.00000246', 'completion': '
0.00000475', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00
000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', '
input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 32768, 'ma
x_completion_tokens': 16384, 'is_moderated': False}, 'per_request_limits': None,
 'supported_parameters': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_to
kens', 'min_p', 'presence_penalty', 'repetition_penalty', 'response_format', 'se
ed', 'stop', 'temperature', 'tool_choice', 'tools', 'top_k', 'top_p']}, {'id': '
nousresearch/hermes-2-pro-llama-3-8b', 'canonical_slug': 'nousresearch/hermes-2-
pro-llama-3-8b', 'name': 'NousResearch: Hermes 2 Pro - Llama-3 8B', 'created': 1
716768000, 'context_length': 131072, 'architecture': {'input_modalities': ['text
'], 'output_modalities': ['text'], 'tokenizer': 'Llama3', 'instruct_type': 'chat
ml'}, 'pricing': {'prompt': '0.00000220', 'completion': '0.00000352', 'image': '
0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reas
oning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.
00000000'}, 'top_provider': {'context_length': 131072, 'max_completion_tokens':
131072, 'is_moderated': False}, 'per_request_limits': None, 'supported_parameter
s': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'pres
ence_penalty', 'repetition_penalty', 'response_format', 'seed', 'stop', 'structu
red_outputs', 'temperature', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'microso
ft/phi-3-mini-128k-instruct', 'canonical_slug': 'microsoft/phi-3-mini-128k-instr
uct', 'name': 'Microsoft: Phi-3 Mini 128K Instruct', 'created': 1716681600, 'con
text_length': 128000, 'architecture': {'input_modalities': ['text'], 'output_mod
alities': ['text'], 'tokenizer': 'Other', 'instruct_type': 'phi3'}, 'pricing': {
'prompt': '0.00000880', 'completion': '0.00000880', 'image': '0.00000000', 'requ
est': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.0000000
0', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_p
rovider': {'context_length': 128000, 'max_completion_tokens': 0, 'is_moderated':
 False}, 'per_request_limits': None, 'supported_parameters': ['max_tokens', 'tem
perature', 'tool_choice', 'tools', 'top_p']}, {'id': 'microsoft/phi-3-medium-128
k-instruct', 'canonical_slug': 'microsoft/phi-3-medium-128k-instruct', 'name': '
Microsoft: Phi-3 Medium 128K Instruct', 'created': 1716508800, 'context_length':
 128000, 'architecture': {'input_modalities': ['text'], 'output_modalities': ['t
ext'], 'tokenizer': 'Other', 'instruct_type': 'phi3'}, 'pricing': {'prompt': '0.
00008803', 'completion': '0.00008803', 'image': '0.00000000', 'request': '0.0000
0000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_ca
che_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'c
ontext_length': 128000, 'max_completion_tokens': 0, 'is_moderated': False}, 'per
_request_limits': None, 'supported_parameters': ['max_tokens', 'temperature', 't
ool_choice', 'tools', 'top_p']}, {'id': 'neversleep/llama-3-lumimaid-70b', 'cano
nical_slug': 'neversleep/llama-3-lumimaid-70b', 'name': 'NeverSleep: Llama 3 Lum
imaid 70B', 'created': 1715817600, 'context_length': 8192, 'architecture': {'inp
ut_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Llama3',
'instruct_type': 'llama3'}, 'pricing': {'prompt': '0.00035211', 'completion': '0
.00052817', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.000
00000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'i
nput_cache_write': '0.00000000'}, 'top_provider': {'context_length': 8192, 'max_
completion_tokens': 4096, 'is_moderated': False}, 'per_request_limits': None, 's
upported_parameters': ['frequency_penalty', 'max_tokens', 'min_p', 'presence_pen
alty', 'repetition_penalty', 'seed', 'stop', 'temperature', 'top_k', 'top_p']},
{'id': 'google/gemini-flash-1.5', 'canonical_slug': 'google/gemini-flash-1.5', '
name': 'Google: Gemini 1.5 Flash ', 'created': 1715644800, 'context_length': 100
0000, 'architecture': {'input_modalities': ['text', 'image'], 'output_modalities
': ['text'], 'tokenizer': 'Gemini', 'instruct_type': None}, 'pricing': {'prompt'
: '0.00000660', 'completion': '0.00002641', 'image': '0.00352114', 'request': '0
.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'inp
ut_cache_read': '0.00000165', 'input_cache_write': '0.00001393'}, 'top_provider'
: {'context_length': 1000000, 'max_completion_tokens': 8192, 'is_moderated': Fal
se}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty', '
max_tokens', 'presence_penalty', 'response_format', 'seed', 'stop', 'structured_
outputs', 'temperature', 'tool_choice', 'tools', 'top_p']}, {'id': 'openai/gpt-4
o', 'canonical_slug': 'openai/gpt-4o', 'name': 'OpenAI: GPT-4o', 'created': 1715
558400, 'context_length': 128000, 'architecture': {'input_modalities': ['text',
'image', 'file'], 'output_modalities': ['text'], 'tokenizer': 'GPT', 'instruct_t
ype': None}, 'pricing': {'prompt': '0.00022007', 'completion': '0.00088028', 'im
age': '0.31804661', 'request': '0.00000000', 'web_search': '0.00000000', 'intern
al_reasoning': '0.00000000', 'input_cache_read': '0.00011004', 'input_cache_writ
e': '0.00000000'}, 'top_provider': {'context_length': 128000, 'max_completion_to
kens': 16384, 'is_moderated': True}, 'per_request_limits': None, 'supported_para
meters': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'presence
_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperature
', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'web_search_options']}, {'id
': 'openai/gpt-4o:extended', 'canonical_slug': 'openai/gpt-4o', 'name': 'OpenAI:
 GPT-4o (extended)', 'created': 1715558400, 'context_length': 128000, 'architect
ure': {'input_modalities': ['text', 'image', 'file'], 'output_modalities': ['tex
t'], 'tokenizer': 'GPT', 'instruct_type': None}, 'pricing': {'prompt': '0.000528
17', 'completion': '0.00158451', 'image': '0.63600519', 'request': '0.00000000',
 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_re
ad': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context
_length': 128000, 'max_completion_tokens': 64000, 'is_moderated': True}, 'per_re
quest_limits': None, 'supported_parameters': ['frequency_penalty', 'logit_bias',
 'logprobs', 'max_tokens', 'presence_penalty', 'response_format', 'seed', 'stop'
, 'structured_outputs', 'temperature', 'tool_choice', 'tools', 'top_logprobs', '
top_p', 'web_search_options']}, {'id': 'meta-llama/llama-guard-2-8b', 'canonical
_slug': 'meta-llama/llama-guard-2-8b', 'name': 'Meta: LlamaGuard 2 8B', 'created
': 1715558400, 'context_length': 8192, 'architecture': {'input_modalities': ['te
xt'], 'output_modalities': ['text'], 'tokenizer': 'Llama3', 'instruct_type': 'no
ne'}, 'pricing': {'prompt': '0.00001761', 'completion': '0.00001761', 'image': '
0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reas
oning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.
00000000'}, 'top_provider': {'context_length': 8192, 'max_completion_tokens': 0,
 'is_moderated': False}, 'per_request_limits': None, 'supported_parameters': ['f
requency_penalty', 'logit_bias', 'max_tokens', 'min_p', 'presence_penalty', 'rep
etition_penalty', 'stop', 'temperature', 'top_k', 'top_p']}, {'id': 'openai/gpt-
4o-2024-05-13', 'canonical_slug': 'openai/gpt-4o-2024-05-13', 'name': 'OpenAI: G
PT-4o (2024-05-13)', 'created': 1715558400, 'context_length': 128000, 'architect
ure': {'input_modalities': ['text', 'image', 'file'], 'output_modalities': ['tex
t'], 'tokenizer': 'GPT', 'instruct_type': None}, 'pricing': {'prompt': '0.000440
14', 'completion': '0.00132043', 'image': '0.63600519', 'request': '0.00000000',
 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_re
ad': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context
_length': 128000, 'max_completion_tokens': 4096, 'is_moderated': True}, 'per_req
uest_limits': None, 'supported_parameters': ['frequency_penalty', 'logit_bias',
'logprobs', 'max_tokens', 'presence_penalty', 'response_format', 'seed', 'stop',
 'structured_outputs', 'temperature', 'tool_choice', 'tools', 'top_logprobs', 't
op_p', 'web_search_options']}, {'id': 'meta-llama/llama-3-70b-instruct', 'canoni
cal_slug': 'meta-llama/llama-3-70b-instruct', 'name': 'Meta: Llama 3 70B Instruc
t', 'created': 1713398400, 'context_length': 8192, 'architecture': {'input_modal
ities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Llama3', 'instruc
t_type': 'llama3'}, 'pricing': {'prompt': '0.00002641', 'completion': '0.0000352
1', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000',
'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cac
he_write': '0.00000000'}, 'top_provider': {'context_length': 8192, 'max_completi
on_tokens': 16384, 'is_moderated': False}, 'per_request_limits': None, 'supporte
d_parameters': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'mi
n_p', 'presence_penalty', 'repetition_penalty', 'response_format', 'seed', 'stop
', 'temperature', 'tool_choice', 'tools', 'top_k', 'top_logprobs', 'top_p']}, {'
id': 'meta-llama/llama-3-8b-instruct', 'canonical_slug': 'meta-llama/llama-3-8b-
instruct', 'name': 'Meta: Llama 3 8B Instruct', 'created': 1713398400, 'context_
length': 8192, 'architecture': {'input_modalities': ['text'], 'output_modalities
': ['text'], 'tokenizer': 'Llama3', 'instruct_type': 'llama3'}, 'pricing': {'pro
mpt': '0.00000264', 'completion': '0.00000528', 'image': '0.00000000', 'request'
: '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000',
'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provi
der': {'context_length': 8192, 'max_completion_tokens': 16384, 'is_moderated': F
alse}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty',
 'logit_bias', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_penalty',
'response_format', 'seed', 'stop', 'temperature', 'tool_choice', 'tools', 'top_k
', 'top_p']}, {'id': 'mistralai/mixtral-8x22b-instruct', 'canonical_slug': 'mist
ralai/mixtral-8x22b-instruct', 'name': 'Mistral: Mixtral 8x22B Instruct', 'creat
ed': 1713312000, 'context_length': 65536, 'architecture': {'input_modalities': [
'text'], 'output_modalities': ['text'], 'tokenizer': 'Mistral', 'instruct_type':
 'mistral'}, 'pricing': {'prompt': '0.00007923', 'completion': '0.00007923', 'im
age': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'intern
al_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_writ
e': '0.00000000'}, 'top_provider': {'context_length': 65536, 'max_completion_tok
ens': 0, 'is_moderated': False}, 'per_request_limits': None, 'supported_paramete
rs': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'presence_pen
alty', 'repetition_penalty', 'response_format', 'seed', 'stop', 'structured_outp
uts', 'temperature', 'tool_choice', 'tools', 'top_k', 'top_logprobs', 'top_p']},
 {'id': 'microsoft/wizardlm-2-8x22b', 'canonical_slug': 'microsoft/wizardlm-2-8x
22b', 'name': 'WizardLM-2 8x22B', 'created': 1713225600, 'context_length': 65536
, 'architecture': {'input_modalities': ['text'], 'output_modalities': ['text'],
'tokenizer': 'Mistral', 'instruct_type': 'vicuna'}, 'pricing': {'prompt': '0.000
04225', 'completion': '0.00004225', 'image': '0.00000000', 'request': '0.0000000
0', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache
_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'cont
ext_length': 65536, 'max_completion_tokens': 65536, 'is_moderated': False}, 'per
_request_limits': None, 'supported_parameters': ['frequency_penalty', 'logit_bia
s', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_penalty', 'response_f
ormat', 'seed', 'stop', 'temperature', 'top_k', 'top_p']}, {'id': 'google/gemini
-pro-1.5', 'canonical_slug': 'google/gemini-pro-1.5', 'name': 'Google: Gemini 1.
5 Pro', 'created': 1712620800, 'context_length': 2000000, 'architecture': {'inpu
t_modalities': ['text', 'image'], 'output_modalities': ['text'], 'tokenizer': 'G
emini', 'instruct_type': None}, 'pricing': {'prompt': '0.00011004', 'completion'
: '0.00044014', 'image': '0.05787867', 'request': '0.00000000', 'web_search': '0
.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000'
, 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 2000000
, 'max_completion_tokens': 8192, 'is_moderated': False}, 'per_request_limits': N
one, 'supported_parameters': ['frequency_penalty', 'max_tokens', 'presence_penal
ty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperature', 'to
ol_choice', 'tools', 'top_p']}, {'id': 'openai/gpt-4-turbo', 'canonical_slug': '
openai/gpt-4-turbo', 'name': 'OpenAI: GPT-4 Turbo', 'created': 1712620800, 'cont
ext_length': 128000, 'architecture': {'input_modalities': ['text', 'image'], 'ou
tput_modalities': ['text'], 'tokenizer': 'GPT', 'instruct_type': None}, 'pricing
': {'prompt': '0.00088028', 'completion': '0.00264085', 'image': '1.27201038', '
request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.000
00000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 't
op_provider': {'context_length': 128000, 'max_completion_tokens': 4096, 'is_mode
rated': True}, 'per_request_limits': None, 'supported_parameters': ['frequency_p
enalty', 'logit_bias', 'logprobs', 'max_tokens', 'presence_penalty', 'response_f
ormat', 'seed', 'stop', 'structured_outputs', 'temperature', 'tool_choice', 'too
ls', 'top_logprobs', 'top_p']}, {'id': 'cohere/command-r-plus', 'canonical_slug'
: 'cohere/command-r-plus', 'name': 'Cohere: Command R+', 'created': 1712188800,
'context_length': 128000, 'architecture': {'input_modalities': ['text'], 'output
_modalities': ['text'], 'tokenizer': 'Cohere', 'instruct_type': None}, 'pricing'
: {'prompt': '0.00026409', 'completion': '0.00132043', 'image': '0.00000000', 'r
equest': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.0000
0000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'to
p_provider': {'context_length': 128000, 'max_completion_tokens': 4000, 'is_moder
ated': True}, 'per_request_limits': None, 'supported_parameters': ['frequency_pe
nalty', 'max_tokens', 'presence_penalty', 'response_format', 'seed', 'stop', 'st
ructured_outputs', 'temperature', 'tools', 'top_k', 'top_p']}, {'id': 'cohere/co
mmand-r-plus-04-2024', 'canonical_slug': 'cohere/command-r-plus-04-2024', 'name'
: 'Cohere: Command R+ (04-2024)', 'created': 1712016000, 'context_length': 12800
0, 'architecture': {'input_modalities': ['text'], 'output_modalities': ['text'],
 'tokenizer': 'Cohere', 'instruct_type': None}, 'pricing': {'prompt': '0.0002640
9', 'completion': '0.00132043', 'image': '0.00000000', 'request': '0.00000000',
'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_rea
d': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_
length': 128000, 'max_completion_tokens': 4000, 'is_moderated': True}, 'per_requ
est_limits': None, 'supported_parameters': ['frequency_penalty', 'max_tokens', '
presence_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'tem
perature', 'tools', 'top_k', 'top_p']}, {'id': 'sophosympatheia/midnight-rose-70
b', 'canonical_slug': 'sophosympatheia/midnight-rose-70b', 'name': 'Midnight Ros
e 70B', 'created': 1711065600, 'context_length': 4096, 'architecture': {'input_m
odalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Llama2', 'ins
truct_type': 'airoboros'}, 'pricing': {'prompt': '0.00007042', 'completion': '0.
00007042', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.0000
0000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'in
put_cache_write': '0.00000000'}, 'top_provider': {'context_length': 4096, 'max_c
ompletion_tokens': 2048, 'is_moderated': False}, 'per_request_limits': None, 'su
pported_parameters': ['frequency_penalty', 'logit_bias', 'max_tokens', 'min_p',
'presence_penalty', 'repetition_penalty', 'seed', 'stop', 'temperature', 'top_k'
, 'top_p']}, {'id': 'cohere/command', 'canonical_slug': 'cohere/command', 'name'
: 'Cohere: Command', 'created': 1710374400, 'context_length': 4096, 'architectur
e': {'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': '
Cohere', 'instruct_type': None}, 'pricing': {'prompt': '0.00008803', 'completion
': '0.00017606', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '
0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000
', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 4096,
'max_completion_tokens': 4000, 'is_moderated': True}, 'per_request_limits': None
, 'supported_parameters': ['frequency_penalty', 'max_tokens', 'presence_penalty'
, 'response_format', 'seed', 'stop', 'structured_outputs', 'temperature', 'top_k
', 'top_p']}, {'id': 'cohere/command-r', 'canonical_slug': 'cohere/command-r', '
name': 'Cohere: Command R', 'created': 1710374400, 'context_length': 128000, 'ar
chitecture': {'input_modalities': ['text'], 'output_modalities': ['text'], 'toke
nizer': 'Cohere', 'instruct_type': None}, 'pricing': {'prompt': '0.00004401', 'c
ompletion': '0.00013204', 'image': '0.00000000', 'request': '0.00000000', 'web_s
earch': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0
.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length
': 128000, 'max_completion_tokens': 4000, 'is_moderated': True}, 'per_request_li
mits': None, 'supported_parameters': ['frequency_penalty', 'max_tokens', 'presen
ce_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperatu
re', 'tools', 'top_k', 'top_p']}, {'id': 'anthropic/claude-3-haiku', 'canonical_
slug': 'anthropic/claude-3-haiku', 'name': 'Anthropic: Claude 3 Haiku', 'created
': 1710288000, 'context_length': 200000, 'architecture': {'input_modalities': ['
text', 'image'], 'output_modalities': ['text'], 'tokenizer': 'Claude', 'instruct
_type': None}, 'pricing': {'prompt': '0.00002201', 'completion': '0.00011004', '
image': '0.03521136', 'request': '0.00000000', 'web_search': '0.00000000', 'inte
rnal_reasoning': '0.00000000', 'input_cache_read': '0.00000264', 'input_cache_wr
ite': '0.00002641'}, 'top_provider': {'context_length': 200000, 'max_completion_
tokens': 4096, 'is_moderated': True}, 'per_request_limits': None, 'supported_par
ameters': ['max_tokens', 'stop', 'temperature', 'tool_choice', 'tools', 'top_k',
 'top_p']}, {'id': 'anthropic/claude-3-opus', 'canonical_slug': 'anthropic/claud
e-3-opus', 'name': 'Anthropic: Claude 3 Opus', 'created': 1709596800, 'context_l
ength': 200000, 'architecture': {'input_modalities': ['text', 'image'], 'output_
modalities': ['text'], 'tokenizer': 'Claude', 'instruct_type': None}, 'pricing':
 {'prompt': '0.00132043', 'completion': '0.00660213', 'image': '2.11268160', 're
quest': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000
000', 'input_cache_read': '0.00013204', 'input_cache_write': '0.00165053'}, 'top
_provider': {'context_length': 200000, 'max_completion_tokens': 4096, 'is_modera
ted': True}, 'per_request_limits': None, 'supported_parameters': ['max_tokens',
'stop', 'temperature', 'tool_choice', 'tools', 'top_k', 'top_p']}, {'id': 'coher
e/command-r-03-2024', 'canonical_slug': 'cohere/command-r-03-2024', 'name': 'Coh
ere: Command R (03-2024)', 'created': 1709341200, 'context_length': 128000, 'arc
hitecture': {'input_modalities': ['text'], 'output_modalities': ['text'], 'token
izer': 'Cohere', 'instruct_type': None}, 'pricing': {'prompt': '0.00004401', 'co
mpletion': '0.00013204', 'image': '0.00000000', 'request': '0.00000000', 'web_se
arch': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.
00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length'
: 128000, 'max_completion_tokens': 4000, 'is_moderated': True}, 'per_request_lim
its': None, 'supported_parameters': ['frequency_penalty', 'max_tokens', 'presenc
e_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperatur
e', 'tools', 'top_k', 'top_p']}, {'id': 'mistralai/mistral-large', 'canonical_sl
ug': 'mistralai/mistral-large', 'name': 'Mistral Large', 'created': 1708905600,
'context_length': 128000, 'architecture': {'input_modalities': ['text'], 'output
_modalities': ['text'], 'tokenizer': 'Mistral', 'instruct_type': None}, 'pricing
': {'prompt': '0.00017606', 'completion': '0.00052817', 'image': '0.00000000', '
request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.000
00000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 't
op_provider': {'context_length': 128000, 'max_completion_tokens': 0, 'is_moderat
ed': False}, 'per_request_limits': None, 'supported_parameters': ['frequency_pen
alty', 'max_tokens', 'presence_penalty', 'response_format', 'seed', 'stop', 'str
uctured_outputs', 'temperature', 'tool_choice', 'tools', 'top_p']}, {'id': 'open
ai/gpt-4-turbo-preview', 'canonical_slug': 'openai/gpt-4-turbo-preview', 'name':
 'OpenAI: GPT-4 Turbo Preview', 'created': 1706140800, 'context_length': 128000,
 'architecture': {'input_modalities': ['text'], 'output_modalities': ['text'], '
tokenizer': 'GPT', 'instruct_type': None}, 'pricing': {'prompt': '0.00088028', '
completion': '0.00264085', 'image': '0.00000000', 'request': '0.00000000', 'web_
search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '
0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_lengt
h': 128000, 'max_completion_tokens': 4096, 'is_moderated': True}, 'per_request_l
imits': None, 'supported_parameters': ['frequency_penalty', 'logit_bias', 'logpr
obs', 'max_tokens', 'presence_penalty', 'response_format', 'seed', 'stop', 'stru
ctured_outputs', 'temperature', 'tool_choice', 'tools', 'top_logprobs', 'top_p']
}, {'id': 'openai/gpt-3.5-turbo-0613', 'canonical_slug': 'openai/gpt-3.5-turbo-0
613', 'name': 'OpenAI: GPT-3.5 Turbo (older v0613)', 'created': 1706140800, 'con
text_length': 4095, 'architecture': {'input_modalities': ['text'], 'output_modal
ities': ['text'], 'tokenizer': 'GPT', 'instruct_type': None}, 'pricing': {'promp
t': '0.00008803', 'completion': '0.00017606', 'image': '0.00000000', 'request':
'0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'i
nput_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provide
r': {'context_length': 4095, 'max_completion_tokens': 4096, 'is_moderated': Fals
e}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty', 'l
ogit_bias', 'logprobs', 'max_tokens', 'presence_penalty', 'response_format', 'se
ed', 'stop', 'structured_outputs', 'temperature', 'tool_choice', 'tools', 'top_l
ogprobs', 'top_p']}, {'id': 'nousresearch/nous-hermes-2-mixtral-8x7b-dpo', 'cano
nical_slug': 'nousresearch/nous-hermes-2-mixtral-8x7b-dpo', 'name': 'Nous: Herme
s 2 Mixtral 8x7B DPO', 'created': 1705363200, 'context_length': 32768, 'architec
ture': {'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer'
: 'Mistral', 'instruct_type': 'chatml'}, 'pricing': {'prompt': '0.00005282', 'co
mpletion': '0.00005282', 'image': '0.00000000', 'request': '0.00000000', 'web_se
arch': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.
00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length'
: 32768, 'max_completion_tokens': 2048, 'is_moderated': False}, 'per_request_lim
its': None, 'supported_parameters': ['frequency_penalty', 'logit_bias', 'max_tok
ens', 'min_p', 'presence_penalty', 'repetition_penalty', 'stop', 'temperature',
'top_k', 'top_p']}, {'id': 'mistralai/mistral-small', 'canonical_slug': 'mistral
ai/mistral-small', 'name': 'Mistral Small', 'created': 1704844800, 'context_leng
th': 32768, 'architecture': {'input_modalities': ['text'], 'output_modalities':
['text'], 'tokenizer': 'Mistral', 'instruct_type': None}, 'pricing': {'prompt':
'0.00001761', 'completion': '0.00005282', 'image': '0.00000000', 'request': '0.0
0000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input
_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider':
{'context_length': 32768, 'max_completion_tokens': 0, 'is_moderated': False}, 'p
er_request_limits': None, 'supported_parameters': ['frequency_penalty', 'max_tok
ens', 'presence_penalty', 'response_format', 'seed', 'stop', 'structured_outputs
', 'temperature', 'tool_choice', 'tools', 'top_p']}, {'id': 'mistralai/mistral-t
iny', 'canonical_slug': 'mistralai/mistral-tiny', 'name': 'Mistral Tiny', 'creat
ed': 1704844800, 'context_length': 32768, 'architecture': {'input_modalities': [
'text'], 'output_modalities': ['text'], 'tokenizer': 'Mistral', 'instruct_type':
 None}, 'pricing': {'prompt': '0.00002201', 'completion': '0.00002201', 'image':
 '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_re
asoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '
0.00000000'}, 'top_provider': {'context_length': 32768, 'max_completion_tokens':
 0, 'is_moderated': False}, 'per_request_limits': None, 'supported_parameters':
['frequency_penalty', 'max_tokens', 'presence_penalty', 'response_format', 'seed
', 'stop', 'structured_outputs', 'temperature', 'tool_choice', 'tools', 'top_p']
}, {'id': 'mistralai/mixtral-8x7b-instruct', 'canonical_slug': 'mistralai/mixtra
l-8x7b-instruct', 'name': 'Mistral: Mixtral 8x7B Instruct', 'created': 170216640
0, 'context_length': 32768, 'architecture': {'input_modalities': ['text'], 'outp
ut_modalities': ['text'], 'tokenizer': 'Mistral', 'instruct_type': 'mistral'}, '
pricing': {'prompt': '0.00000704', 'completion': '0.00002113', 'image': '0.00000
000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning':
 '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.0000000
0'}, 'top_provider': {'context_length': 32768, 'max_completion_tokens': 16384, '
is_moderated': False}, 'per_request_limits': None, 'supported_parameters': ['fre
quency_penalty', 'logit_bias', 'max_tokens', 'min_p', 'presence_penalty', 'repet
ition_penalty', 'response_format', 'seed', 'stop', 'temperature', 'tool_choice',
 'tools', 'top_k', 'top_p']}, {'id': 'neversleep/noromaid-20b', 'canonical_slug'
: 'neversleep/noromaid-20b', 'name': 'Noromaid 20B', 'created': 1700956800, 'con
text_length': 4096, 'architecture': {'input_modalities': ['text'], 'output_modal
ities': ['text'], 'tokenizer': 'Llama2', 'instruct_type': 'alpaca'}, 'pricing':
{'prompt': '0.00008803', 'completion': '0.00015405', 'image': '0.00000000', 'req
uest': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.000000
00', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_
provider': {'context_length': 4096, 'max_completion_tokens': 0, 'is_moderated':
False}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty'
, 'logit_bias', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_penalty',
 'response_format', 'seed', 'stop', 'structured_outputs', 'temperature', 'top_a'
, 'top_k', 'top_p']}, {'id': 'alpindale/goliath-120b', 'canonical_slug': 'alpind
ale/goliath-120b', 'name': 'Goliath 120B', 'created': 1699574400, 'context_lengt
h': 6144, 'architecture': {'input_modalities': ['text'], 'output_modalities': ['
text'], 'tokenizer': 'Llama2', 'instruct_type': 'airoboros'}, 'pricing': {'promp
t': '0.00035211', 'completion': '0.00048416', 'image': '0.00000000', 'request':
'0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'i
nput_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provide
r': {'context_length': 6144, 'max_completion_tokens': 512, 'is_moderated': False
}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty', 'lo
git_bias', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_penalty', 'res
ponse_format', 'seed', 'stop', 'structured_outputs', 'temperature', 'top_a', 'to
p_k', 'top_p']}, {'id': 'openai/gpt-4-1106-preview', 'canonical_slug': 'openai/g
pt-4-1106-preview', 'name': 'OpenAI: GPT-4 Turbo (older v1106)', 'created': 1699
228800, 'context_length': 128000, 'architecture': {'input_modalities': ['text'],
 'output_modalities': ['text'], 'tokenizer': 'GPT', 'instruct_type': None}, 'pri
cing': {'prompt': '0.00088028', 'completion': '0.00264085', 'image': '0.00000000
', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0
.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}
, 'top_provider': {'context_length': 128000, 'max_completion_tokens': 4096, 'is_
moderated': True}, 'per_request_limits': None, 'supported_parameters': ['frequen
cy_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'presence_penalty', 'respon
se_format', 'seed', 'stop', 'structured_outputs', 'temperature', 'tool_choice',
'tools', 'top_logprobs', 'top_p']}, {'id': 'openai/gpt-3.5-turbo-instruct', 'can
onical_slug': 'openai/gpt-3.5-turbo-instruct', 'name': 'OpenAI: GPT-3.5 Turbo In
struct', 'created': 1695859200, 'context_length': 4095, 'architecture': {'input_
modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'GPT', 'instr
uct_type': 'chatml'}, 'pricing': {'prompt': '0.00013204', 'completion': '0.00017
606', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000'
, 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_c
ache_write': '0.00000000'}, 'top_provider': {'context_length': 4095, 'max_comple
tion_tokens': 4096, 'is_moderated': True}, 'per_request_limits': None, 'supporte
d_parameters': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'pr
esence_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'tempe
rature', 'top_logprobs', 'top_p']}, {'id': 'mistralai/mistral-7b-instruct-v0.1',
 'canonical_slug': 'mistralai/mistral-7b-instruct-v0.1', 'name': 'Mistral: Mistr
al 7B Instruct v0.1', 'created': 1695859200, 'context_length': 2824, 'architectu
re': {'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer':
'Mistral', 'instruct_type': 'mistral'}, 'pricing': {'prompt': '0.00000968', 'com
pletion': '0.00001673', 'image': '0.00000000', 'request': '0.00000000', 'web_sea
rch': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.0
0000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length':
 2824, 'max_completion_tokens': 0, 'is_moderated': False}, 'per_request_limits':
 None, 'supported_parameters': ['frequency_penalty', 'logit_bias', 'max_tokens',
 'min_p', 'presence_penalty', 'repetition_penalty', 'seed', 'stop', 'temperature
', 'tool_choice', 'tools', 'top_k', 'top_p']}, {'id': 'pygmalionai/mythalion-13b
', 'canonical_slug': 'pygmalionai/mythalion-13b', 'name': 'Pygmalion: Mythalion
13B', 'created': 1693612800, 'context_length': 4096, 'architecture': {'input_mod
alities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Llama2', 'instr
uct_type': 'alpaca'}, 'pricing': {'prompt': '0.00006162', 'completion': '0.00009
683', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000'
, 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_c
ache_write': '0.00000000'}, 'top_provider': {'context_length': 4096, 'max_comple
tion_tokens': 4096, 'is_moderated': False}, 'per_request_limits': None, 'support
ed_parameters': ['frequency_penalty', 'max_tokens', 'min_p', 'presence_penalty',
 'repetition_penalty', 'seed', 'stop', 'temperature', 'top_k', 'top_p']}, {'id':
 'openai/gpt-3.5-turbo-16k', 'canonical_slug': 'openai/gpt-3.5-turbo-16k', 'name
': 'OpenAI: GPT-3.5 Turbo 16k', 'created': 1693180800, 'context_length': 16385,
'architecture': {'input_modalities': ['text'], 'output_modalities': ['text'], 't
okenizer': 'GPT', 'instruct_type': None}, 'pricing': {'prompt': '0.00026409', 'c
ompletion': '0.00035211', 'image': '0.00000000', 'request': '0.00000000', 'web_s
earch': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0
.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length
': 16385, 'max_completion_tokens': 4096, 'is_moderated': True}, 'per_request_lim
its': None, 'supported_parameters': ['frequency_penalty', 'logit_bias', 'logprob
s', 'max_tokens', 'presence_penalty', 'response_format', 'seed', 'stop', 'struct
ured_outputs', 'temperature', 'tool_choice', 'tools', 'top_logprobs', 'top_p']},
 {'id': 'mancer/weaver', 'canonical_slug': 'mancer/weaver', 'name': 'Mancer: Wea
ver (alpha)', 'created': 1690934400, 'context_length': 8000, 'architecture': {'i
kens': 4096, 'is_moderated': True}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'presence_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperature', 'tool_choice', 'tools', 'top_
logprobs', 'top_p']}, {'id': 'openai/gpt-3.5-turbo', 'canonical_slug': 'openai/gpt-3.5-turbo', 'name': 'OpenAI: GPT-3.5 Turbo', 'created': 1685232000, 'context_length': 16385, 'architecture': {'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'GPT
', 'instruct_type': None}, 'pricing': {'prompt': '0.00004401', 'completion': '0.00013204', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}
, 'top_provider': {'context_length': 16385, 'max_completion_tokens': 4096, 'is_moderated': True}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'presence_penalty', 'response_format', 'seed', 'stop', 'str
uctured_outputs', 'temperature', 'tool_choice', 'tools', 'top_logprobs', 'top_p']}, {'id': 't-tech/T-pro-it-2.0-FP8', 'canonical_slug': 't-tech/T-pro-it-2.0-FP8', 'name': 't-tech/T-pro-it-2.0-FP8', 'created': 1756380717, 'context_length': 32768, 'architecture': {'input_m
odalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'unknown', 'instruct_type': None}, 'pricing': {'prompt': '0.000001', 'completion': '0.000002', 'image': '0', 'request': '0', 'web_search': '0', 'internal_reasoning': '0', 'input_cache_read': '0', 'input_ca
che_write': '0'}, 'top_provider': {'context_length': 32768, 'max_completion_tokens': 4096, 'is_moderated': False}, 'per_request_limits': None, 'supported_parameters': []}]
root@0ae8a1986f6d:/app# grep "gpt" python app.py
[{'id': 'x-ai/grok-code-fast-1', 'canonical_slug': 'x-ai/grok-code-fast-1', 'nam
e': 'xAI: Grok Code Fast 1', 'created': 1756238927, 'context_length': 256000, 'a
rchitecture': {'input_modalities': ['text'], 'output_modalities': ['text'], 'tok
enizer': 'Grok', 'instruct_type': None}, 'pricing': {'prompt': '0.00001761', 'co
mpletion': '0.00013204', 'image': '0.00000000', 'request': '0.00000000', 'web_se
arch': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.
00000176', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length'
: 256000, 'max_completion_tokens': 10000, 'is_moderated': False}, 'per_request_l
imits': None, 'supported_parameters': ['include_reasoning', 'logprobs', 'max_tok
ens', 'reasoning', 'response_format', 'seed', 'stop', 'structured_outputs', 'tem
perature', 'tool_choice', 'tools', 'top_logprobs', 'top_p']}, {'id': 'nousresear
ch/hermes-4-70b', 'canonical_slug': 'nousresearch/hermes-4-70b', 'name': 'Nous:
Hermes 4 70B', 'created': 1756236182, 'context_length': 131072, 'architecture':
{'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Llam
a3', 'instruct_type': None}, 'pricing': {'prompt': '0.00000821', 'completion': '
0.00003287', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00
000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', '
input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 131072, 'm
ax_completion_tokens': 0, 'is_moderated': False}, 'per_request_limits': None, 's
upported_parameters': ['frequency_penalty', 'include_reasoning', 'logit_bias', '
logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'reasoning', 'repetition_p
enalty', 'seed', 'stop', 'temperature', 'tool_choice', 'tools', 'top_k', 'top_lo
gprobs', 'top_p']}, {'id': 'nousresearch/hermes-4-405b', 'canonical_slug': 'nous
research/hermes-4-405b', 'name': 'Nous: Hermes 4 405B', 'created': 1756235463, '
context_length': 131072, 'architecture': {'input_modalities': ['text'], 'output_
modalities': ['text'], 'tokenizer': 'Other', 'instruct_type': None}, 'pricing':
{'prompt': '0.00001760', 'completion': '0.00007043', 'image': '0.00000000', 'req
uest': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.000000
00', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_
provider': {'context_length': 131072, 'max_completion_tokens': 0, 'is_moderated'
: False}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalt
y', 'include_reasoning', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'prese
nce_penalty', 'reasoning', 'repetition_penalty', 'seed', 'stop', 'temperature',
'tool_choice', 'tools', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'google/gemin
i-2.5-flash-image-preview', 'canonical_slug': 'google/gemini-2.5-flash-image-pre
view', 'name': 'Google: Gemini 2.5 Flash Image Preview', 'created': 1756218977,
'context_length': 32768, 'architecture': {'input_modalities': ['image', 'text'],
 'output_modalities': ['image', 'text'], 'tokenizer': 'Gemini', 'instruct_type':
 None}, 'pricing': {'prompt': '0.00002641', 'completion': '0.00022007', 'image':
 '0.10897916', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_re
asoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '
0.00000000'}, 'top_provider': {'context_length': 32768, 'max_completion_tokens':
 8192, 'is_moderated': False}, 'per_request_limits': None, 'supported_parameters
': ['max_tokens', 'response_format', 'seed', 'structured_outputs', 'temperature'
, 'top_p']}, {'id': 'deepseek/deepseek-chat-v3.1', 'canonical_slug': 'deepseek/d
eepseek-chat-v3.1', 'name': 'DeepSeek: DeepSeek V3.1', 'created': 1755779628, 'c
ontext_length': 163840, 'architecture': {'input_modalities': ['text'], 'output_m
odalities': ['text'], 'tokenizer': 'DeepSeek', 'instruct_type': 'deepseek-v3.1'}
, 'pricing': {'prompt': '0.00001761', 'completion': '0.00007042', 'image': '0.00
000000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasonin
g': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.0000
0000'}, 'top_provider': {'context_length': 163840, 'max_completion_tokens': 0, '
is_moderated': False}, 'per_request_limits': None, 'supported_parameters': ['fre
quency_penalty', 'include_reasoning', 'logit_bias', 'logprobs', 'max_tokens', 'm
in_p', 'presence_penalty', 'reasoning', 'repetition_penalty', 'response_format',
 'seed', 'stop', 'structured_outputs', 'temperature', 'tool_choice', 'tools', 't
op_k', 'top_logprobs', 'top_p']}, {'id': 'deepseek/deepseek-v3.1-base', 'canonic
al_slug': 'deepseek/deepseek-v3.1-base', 'name': 'DeepSeek: DeepSeek V3.1 Base',
 'created': 1755727017, 'context_length': 163840, 'architecture': {'input_modali
ties': ['text'], 'output_modalities': ['text'], 'tokenizer': 'DeepSeek', 'instru
ct_type': 'none'}, 'pricing': {'prompt': '0.00001761', 'completion': '0.00007042
', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', '
internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cach
e_write': '0.00000000'}, 'top_provider': {'context_length': 163840, 'max_complet
ion_tokens': 0, 'is_moderated': False}, 'per_request_limits': None, 'supported_p
arameters': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'min_p
', 'presence_penalty', 'repetition_penalty', 'seed', 'stop', 'temperature', 'top
_k', 'top_logprobs', 'top_p']}, {'id': 'openai/gpt-4o-audio-preview', 'canonical
_slug': 'openai/gpt-4o-audio-preview', 'name': 'OpenAI: GPT-4o Audio', 'created'
: 1755233061, 'context_length': 128000, 'architecture': {'input_modalities': ['a
udio', 'text'], 'output_modalities': ['text'], 'tokenizer': 'GPT', 'instruct_typ
e': None}, 'pricing': {'prompt': '0.00022007', 'completion': '0.00088028', 'imag
e': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal
_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write'
: '0.00000000'}, 'top_provider': {'context_length': 128000, 'max_completion_toke
ns': 16384, 'is_moderated': True}, 'per_request_limits': None, 'supported_parame
ters': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'presence_p
enalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperature',
 'tool_choice', 'tools', 'top_logprobs', 'top_p']}, {'id': 'mistralai/mistral-me
dium-3.1', 'canonical_slug': 'mistralai/mistral-medium-3.1', 'name': 'Mistral: M
istral Medium 3.1', 'created': 1755095639, 'context_length': 131072, 'architectu
re': {'input_modalities': ['text', 'image'], 'output_modalities': ['text'], 'tok
enizer': 'Mistral', 'instruct_type': None}, 'pricing': {'prompt': '0.00003521',
'completion': '0.00017606', 'image': '0.00000000', 'request': '0.00000000', 'web
_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read':
'0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_leng
th': 131072, 'max_completion_tokens': 0, 'is_moderated': False}, 'per_request_li
mits': None, 'supported_parameters': ['frequency_penalty', 'max_tokens', 'presen
ce_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperatu
re', 'tool_choice', 'tools', 'top_p']}, {'id': 'baidu/ernie-4.5-21b-a3b', 'canon
ical_slug': 'baidu/ernie-4.5-21b-a3b', 'name': 'Baidu: ERNIE 4.5 21B A3B', 'crea
ted': 1755034167, 'context_length': 120000, 'architecture': {'input_modalities':
 ['text'], 'output_modalities': ['text'], 'tokenizer': 'Other', 'instruct_type':
 None}, 'pricing': {'prompt': '0.00000616', 'completion': '0.00002465', 'image':
 '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_re
asoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '
0.00000000'}, 'top_provider': {'context_length': 120000, 'max_completion_tokens'
: 8000, 'is_moderated': False}, 'per_request_limits': None, 'supported_parameter
s': ['frequency_penalty', 'logit_bias', 'max_tokens', 'min_p', 'presence_penalty
', 'repetition_penalty', 'seed', 'stop', 'temperature', 'top_k', 'top_p']}, {'id
': 'baidu/ernie-4.5-vl-28b-a3b', 'canonical_slug': 'baidu/ernie-4.5-vl-28b-a3b',
 'name': 'Baidu: ERNIE 4.5 VL 28B A3B', 'created': 1755032836, 'context_length':
 30000, 'architecture': {'input_modalities': ['text', 'image'], 'output_modaliti
es': ['text'], 'tokenizer': 'Other', 'instruct_type': None}, 'pricing': {'prompt
': '0.00001232', 'completion': '0.00004930', 'image': '0.00000000', 'request': '
0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'in
put_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider
': {'context_length': 30000, 'max_completion_tokens': 8000, 'is_moderated': Fals
e}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty', 'i
nclude_reasoning', 'logit_bias', 'max_tokens', 'min_p', 'presence_penalty', 'rea
soning', 'repetition_penalty', 'seed', 'stop', 'temperature', 'top_k', 'top_p']}
, {'id': 'z-ai/glm-4.5v', 'canonical_slug': 'z-ai/glm-4.5v', 'name': 'Z.AI: GLM
4.5V', 'created': 1754922288, 'context_length': 65536, 'architecture': {'input_m
odalities': ['text', 'image'], 'output_modalities': ['text'], 'tokenizer': 'Othe
r', 'instruct_type': None}, 'pricing': {'prompt': '0.00004401', 'completion': '0
.00015845', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.000
00000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'i
nput_cache_write': '0.00000000'}, 'top_provider': {'context_length': 65536, 'max
_completion_tokens': 65536, 'is_moderated': False}, 'per_request_limits': None,
'supported_parameters': ['frequency_penalty', 'include_reasoning', 'logit_bias',
 'max_tokens', 'min_p', 'presence_penalty', 'reasoning', 'repetition_penalty', '
seed', 'stop', 'temperature', 'tool_choice', 'tools', 'top_k', 'top_p']}, {'id':
 'ai21/jamba-mini-1.7', 'canonical_slug': 'ai21/jamba-mini-1.7', 'name': 'AI21:
Jamba Mini 1.7', 'created': 1754670601, 'context_length': 256000, 'architecture'
: {'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Ot
her', 'instruct_type': None}, 'pricing': {'prompt': '0.00001761', 'completion':
'0.00003521', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.0
0000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000',
'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 256000, '
max_completion_tokens': 4096, 'is_moderated': False}, 'per_request_limits': None
, 'supported_parameters': ['max_tokens', 'response_format', 'stop', 'temperature
', 'tool_choice', 'tools', 'top_p']}, {'id': 'ai21/jamba-large-1.7', 'canonical_
slug': 'ai21/jamba-large-1.7', 'name': 'AI21: Jamba Large 1.7', 'created': 17546
69020, 'context_length': 256000, 'architecture': {'input_modalities': ['text'],
'output_modalities': ['text'], 'tokenizer': 'Other', 'instruct_type': None}, 'pr
icing': {'prompt': '0.00017606', 'completion': '0.00070423', 'image': '0.0000000
0', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '
0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'
}, 'top_provider': {'context_length': 256000, 'max_completion_tokens': 4096, 'is
_moderated': False}, 'per_request_limits': None, 'supported_parameters': ['max_t
okens', 'response_format', 'stop', 'temperature', 'tool_choice', 'tools', 'top_p
']}, {'id': 'openai/gpt-5-chat', 'canonical_slug': 'openai/gpt-5-chat-2025-08-07
', 'name': 'OpenAI: GPT-5 Chat', 'created': 1754587837, 'context_length': 400000
, 'architecture': {'input_modalities': ['file', 'image', 'text'], 'output_modali
ties': ['text'], 'tokenizer': 'GPT', 'instruct_type': None}, 'pricing': {'prompt
': '0.00011004', 'completion': '0.00088028', 'image': '0.00000000', 'request': '
0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'in
put_cache_read': '0.00001100', 'input_cache_write': '0.00000000'}, 'top_provider
': {'context_length': 400000, 'max_completion_tokens': 128000, 'is_moderated': T
rue}, 'per_request_limits': None, 'supported_parameters': ['include_reasoning',
'max_tokens', 'reasoning', 'response_format', 'seed', 'structured_outputs']}, {'
id': 'openai/gpt-5', 'canonical_slug': 'openai/gpt-5-2025-08-07', 'name': 'OpenA
I: GPT-5', 'created': 1754587413, 'context_length': 400000, 'architecture': {'in
put_modalities': ['text', 'image', 'file'], 'output_modalities': ['text'], 'toke
nizer': 'GPT', 'instruct_type': None}, 'pricing': {'prompt': '0.00011004', 'comp
letion': '0.00088028', 'image': '0.00000000', 'request': '0.00000000', 'web_sear
ch': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00
001100', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length':
400000, 'max_completion_tokens': 128000, 'is_moderated': True}, 'per_request_lim
its': None, 'supported_parameters': ['include_reasoning', 'max_tokens', 'reasoni
ng', 'response_format', 'seed', 'structured_outputs', 'tool_choice', 'tools']},
{'id': 'openai/gpt-5-mini', 'canonical_slug': 'openai/gpt-5-mini-2025-08-07', 'n
ame': 'OpenAI: GPT-5 Mini', 'created': 1754587407, 'context_length': 400000, 'ar
chitecture': {'input_modalities': ['text', 'image', 'file'], 'output_modalities'
: ['text'], 'tokenizer': 'GPT', 'instruct_type': None}, 'pricing': {'prompt': '0
.00002201', 'completion': '0.00017606', 'image': '0.00000000', 'request': '0.000
00000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_c
ache_read': '0.00000220', 'input_cache_write': '0.00000000'}, 'top_provider': {'
context_length': 400000, 'max_completion_tokens': 128000, 'is_moderated': True},
 'per_request_limits': None, 'supported_parameters': ['include_reasoning', 'max_
tokens', 'reasoning', 'response_format', 'seed', 'structured_outputs', 'tool_cho
ice', 'tools']}, {'id': 'openai/gpt-5-nano', 'canonical_slug': 'openai/gpt-5-nan
o-2025-08-07', 'name': 'OpenAI: GPT-5 Nano', 'created': 1754587402, 'context_len
gth': 400000, 'architecture': {'input_modalities': ['text', 'image', 'file'], 'o
utput_modalities': ['text'], 'tokenizer': 'GPT', 'instruct_type': None}, 'pricin
g': {'prompt': '0.00000440', 'completion': '0.00003521', 'image': '0.00000000',
'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00
000000', 'input_cache_read': '0.00000044', 'input_cache_write': '0.00000000'}, '
top_provider': {'context_length': 400000, 'max_completion_tokens': 128000, 'is_m
oderated': True}, 'per_request_limits': None, 'supported_parameters': ['include_
reasoning', 'max_tokens', 'reasoning', 'response_format', 'seed', 'structured_ou
tputs', 'tool_choice', 'tools']}, {'id': 'openai/gpt-oss-120b', 'canonical_slug'
: 'openai/gpt-oss-120b', 'name': 'OpenAI: gpt-oss-120b', 'created': 1754414231,
'context_length': 131000, 'architecture': {'input_modalities': ['text'], 'output
_modalities': ['text'], 'tokenizer': 'GPT', 'instruct_type': None}, 'pricing': {
'prompt': '0.00000634', 'completion': '0.00002465', 'image': '0.00000000', 'requ
est': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.0000000
0', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_p
rovider': {'context_length': 131000, 'max_completion_tokens': 131000, 'is_modera
ted': False}, 'per_request_limits': None, 'supported_parameters': ['frequency_pe
nalty', 'include_reasoning', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'p
resence_penalty', 'reasoning', 'repetition_penalty', 'response_format', 'seed',
'stop', 'structured_outputs', 'temperature', 'tool_choice', 'tools', 'top_k', 't
op_logprobs', 'top_p']}, {'id': 'openai/gpt-oss-20b', 'canonical_slug': 'openai/
gpt-oss-20b', 'name': 'OpenAI: gpt-oss-20b', 'created': 1754414229, 'context_len
gth': 131000, 'architecture': {'input_modalities': ['text'], 'output_modalities'
: ['text'], 'tokenizer': 'GPT', 'instruct_type': None}, 'pricing': {'prompt': '0
.00000352', 'completion': '0.00001320', 'image': '0.00000000', 'request': '0.000
00000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_c
ache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'
context_length': 131000, 'max_completion_tokens': 131000, 'is_moderated': False}
, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty', 'inc
lude_reasoning', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_pena
lty', 'reasoning', 'repetition_penalty', 'response_format', 'seed', 'stop', 'str
uctured_outputs', 'temperature', 'tool_choice', 'tools', 'top_k', 'top_logprobs'
, 'top_p']}, {'id': 'anthropic/claude-opus-4.1', 'canonical_slug': 'anthropic/cl
aude-4.1-opus-20250805', 'name': 'Anthropic: Claude Opus 4.1', 'created': 175441
1591, 'context_length': 200000, 'architecture': {'input_modalities': ['image', '
text', 'file'], 'output_modalities': ['text'], 'tokenizer': 'Claude', 'instruct_
type': None}, 'pricing': {'prompt': '0.00132043', 'completion': '0.00660213', 'i
mage': '2.11268160', 'request': '0.00000000', 'web_search': '0.00000000', 'inter
nal_reasoning': '0.00000000', 'input_cache_read': '0.00013204', 'input_cache_wri
te': '0.00165053'}, 'top_provider': {'context_length': 200000, 'max_completion_t
okens': 32000, 'is_moderated': True}, 'per_request_limits': None, 'supported_par
ameters': ['include_reasoning', 'max_tokens', 'reasoning', 'stop', 'temperature'
, 'tool_choice', 'tools']}, {'id': 'mistralai/codestral-2508', 'canonical_slug':
 'mistralai/codestral-2508', 'name': 'Mistral: Codestral 2508', 'created': 17540
79630, 'context_length': 256000, 'architecture': {'input_modalities': ['text'],
'output_modalities': ['text'], 'tokenizer': 'Mistral', 'instruct_type': None}, '
pricing': {'prompt': '0.00002641', 'completion': '0.00007923', 'image': '0.00000
000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning':
 '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.0000000
0'}, 'top_provider': {'context_length': 256000, 'max_completion_tokens': 0, 'is_
moderated': False}, 'per_request_limits': None, 'supported_parameters': ['freque
ncy_penalty', 'max_tokens', 'presence_penalty', 'response_format', 'seed', 'stop
', 'structured_outputs', 'temperature', 'tool_choice', 'tools', 'top_p']}, {'id'
: 'qwen/qwen3-30b-a3b-instruct-2507', 'canonical_slug': 'qwen/qwen3-30b-a3b-inst
ruct-2507', 'name': 'Qwen: Qwen3 30B A3B Instruct 2507', 'created': 1753806965,
'context_length': 262144, 'architecture': {'input_modalities': ['text'], 'output
_modalities': ['text'], 'tokenizer': 'Qwen3', 'instruct_type': None}, 'pricing':
 {'prompt': '0.00000880', 'completion': '0.00002641', 'image': '0.00000000', 're
quest': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000
000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top
_provider': {'context_length': 262144, 'max_completion_tokens': 0, 'is_moderated
': False}, 'per_request_limits': None, 'supported_parameters': ['frequency_penal
ty', 'logit_bias', 'logprobs', 'max_tokens', 'presence_penalty', 'response_forma
t', 'seed', 'stop', 'temperature', 'tool_choice', 'tools', 'top_k', 'top_logprob
s', 'top_p']}, {'id': 'z-ai/glm-4.5', 'canonical_slug': 'z-ai/glm-4.5', 'name':
'Z.AI: GLM 4.5', 'created': 1753471347, 'context_length': 131072, 'architecture'
: {'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Ot
her', 'instruct_type': None}, 'pricing': {'prompt': '0.00001760', 'completion':
'0.00007043', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.0
0000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000',
'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 131072, '
max_completion_tokens': 0, 'is_moderated': False}, 'per_request_limits': None, '
supported_parameters': ['frequency_penalty', 'include_reasoning', 'logit_bias',
'logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'reasoning', 'repetition_
penalty', 'response_format', 'seed', 'stop', 'temperature', 'tool_choice', 'tool
s', 'top_a', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'z-ai/glm-4.5-air', 'can
onical_slug': 'z-ai/glm-4.5-air', 'name': 'Z.AI: GLM 4.5 Air', 'created': 175347
1258, 'context_length': 131072, 'architecture': {'input_modalities': ['text'], '
output_modalities': ['text'], 'tokenizer': 'Other', 'instruct_type': None}, 'pri
cing': {'prompt': '0.00001761', 'completion': '0.00009683', 'image': '0.00000000
', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0
.00000000', 'input_cache_read': '0.00000264', 'input_cache_write': '0.00000000'}
, 'top_provider': {'context_length': 131072, 'max_completion_tokens': 96000, 'is
_moderated': False}, 'per_request_limits': None, 'supported_parameters': ['inclu
de_reasoning', 'max_tokens', 'reasoning', 'response_format', 'seed', 'structured
_outputs', 'temperature', 'tool_choice', 'tools', 'top_p']}, {'id': 'qwen/qwen3-
235b-a22b-thinking-2507', 'canonical_slug': 'qwen/qwen3-235b-a22b-thinking-2507'
, 'name': 'Qwen: Qwen3 235B A22B Thinking 2507', 'created': 1753449557, 'context
_length': 262144, 'architecture': {'input_modalities': ['text'], 'output_modalit
ies': ['text'], 'tokenizer': 'Qwen3', 'instruct_type': 'qwen3'}, 'pricing': {'pr
ompt': '0.00000686', 'completion': '0.00002747', 'image': '0.00000000', 'request
': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000',
 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_prov
ider': {'context_length': 262144, 'max_completion_tokens': 0, 'is_moderated': Fa
lse}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty',
'include_reasoning', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_
penalty', 'reasoning', 'repetition_penalty', 'response_format', 'seed', 'stop',
'temperature', 'tool_choice', 'tools', 'top_k', 'top_logprobs', 'top_p']}, {'id'
: 'z-ai/glm-4-32b', 'canonical_slug': 'z-ai/glm-4-32b-0414', 'name': 'Z.AI: GLM
4 32B ', 'created': 1753376617, 'context_length': 128000, 'architecture': {'inpu
t_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Other', 'i
nstruct_type': None}, 'pricing': {'prompt': '0.00000880', 'completion': '0.00000
880', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000'
, 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_c
ache_write': '0.00000000'}, 'top_provider': {'context_length': 128000, 'max_comp
letion_tokens': 0, 'is_moderated': False}, 'per_request_limits': None, 'supporte
d_parameters': ['max_tokens', 'temperature', 'tool_choice', 'tools', 'top_p']},
{'id': 'qwen/qwen3-coder', 'canonical_slug': 'qwen/qwen3-coder-480b-a35b-07-25',
 'name': 'Qwen: Qwen3 Coder ', 'created': 1753230546, 'context_length': 262144,
'architecture': {'input_modalities': ['text'], 'output_modalities': ['text'], 't
okenizer': 'Qwen3', 'instruct_type': None}, 'pricing': {'prompt': '0.00001761',
'completion': '0.00007042', 'image': '0.00000000', 'request': '0.00000000', 'web
_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read':
'0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_leng
th': 262144, 'max_completion_tokens': 0, 'is_moderated': False}, 'per_request_li
mits': None, 'supported_parameters': ['frequency_penalty', 'logit_bias', 'logpro
bs', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_penalty', 'response_
format', 'seed', 'stop', 'structured_outputs', 'temperature', 'tool_choice', 'to
ols', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'bytedance/ui-tars-1.5-7b', 'ca
nonical_slug': 'bytedance/ui-tars-1.5-7b', 'name': 'Bytedance: UI-TARS 7B ', 'cr
eated': 1753205056, 'context_length': 128000, 'architecture': {'input_modalities
': ['image', 'text'], 'output_modalities': ['text'], 'tokenizer': 'Other', 'inst
ruct_type': None}, 'pricing': {'prompt': '0.00000880', 'completion': '0.00001761
', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', '
internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cach
e_write': '0.00000000'}, 'top_provider': {'context_length': 128000, 'max_complet
ion_tokens': 2048, 'is_moderated': False}, 'per_request_limits': None, 'supporte
d_parameters': ['frequency_penalty', 'max_tokens', 'min_p', 'presence_penalty',
'repetition_penalty', 'seed', 'stop', 'temperature', 'top_k', 'top_p']}, {'id':
'google/gemini-2.5-flash-lite', 'canonical_slug': 'google/gemini-2.5-flash-lite'
, 'name': 'Google: Gemini 2.5 Flash Lite', 'created': 1753200276, 'context_lengt
h': 1048576, 'architecture': {'input_modalities': ['file', 'image', 'text', 'aud
io'], 'output_modalities': ['text'], 'tokenizer': 'Gemini', 'instruct_type': Non
e}, 'pricing': {'prompt': '0.00000880', 'completion': '0.00003521', 'image': '0.
00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reason
ing': '0.00000000', 'input_cache_read': '0.00000220', 'input_cache_write': '0.00
001614'}, 'top_provider': {'context_length': 1048576, 'max_completion_tokens': 6
5535, 'is_moderated': False}, 'per_request_limits': None, 'supported_parameters'
: ['include_reasoning', 'max_tokens', 'reasoning', 'response_format', 'seed', 's
top', 'structured_outputs', 'temperature', 'tool_choice', 'tools', 'top_p']}, {'
id': 'qwen/qwen3-235b-a22b-2507', 'canonical_slug': 'qwen/qwen3-235b-a22b-07-25'
, 'name': 'Qwen: Qwen3 235B A22B Instruct 2507', 'created': 1753119555, 'context
_length': 262144, 'architecture': {'input_modalities': ['text'], 'output_modalit
ies': ['text'], 'tokenizer': 'Qwen3', 'instruct_type': None}, 'pricing': {'promp
t': '0.00000686', 'completion': '0.00002747', 'image': '0.00000000', 'request':
'0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'i
nput_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provide
r': {'context_length': 262144, 'max_completion_tokens': 0, 'is_moderated': False
}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty', 'lo
git_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_pe
nalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperature',
'tool_choice', 'tools', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'switchpoint/
router', 'canonical_slug': 'switchpoint/router', 'name': 'Switchpoint Router', '
created': 1752272899, 'context_length': 131072, 'architecture': {'input_modaliti
es': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Other', 'instruct_ty
pe': None}, 'pricing': {'prompt': '0.00007482', 'completion': '0.00029930', 'ima
ge': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'interna
l_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write
': '0.00000000'}, 'top_provider': {'context_length': 131072, 'max_completion_tok
ens': 0, 'is_moderated': False}, 'per_request_limits': None, 'supported_paramete
rs': ['include_reasoning', 'max_tokens', 'reasoning', 'seed', 'stop', 'temperatu
re', 'top_k', 'top_p']}, {'id': 'moonshotai/kimi-k2', 'canonical_slug': 'moonsho
tai/kimi-k2', 'name': 'MoonshotAI: Kimi K2', 'created': 1752263252, 'context_len
gth': 63000, 'architecture': {'input_modalities': ['text'], 'output_modalities':
 ['text'], 'tokenizer': 'Other', 'instruct_type': None}, 'pricing': {'prompt': '
0.00001232', 'completion': '0.00021919', 'image': '0.00000000', 'request': '0.00
000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_
cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {
'context_length': 63000, 'max_completion_tokens': 63000, 'is_moderated': False},
 'per_request_limits': None, 'supported_parameters': ['frequency_penalty', 'logi
t_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_pena
lty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperature', 't
ool_choice', 'tools', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'thudm/glm-4.1v
-9b-thinking', 'canonical_slug': 'thudm/glm-4.1v-9b-thinking', 'name': 'THUDM: G
LM 4.1V 9B Thinking', 'created': 1752244385, 'context_length': 65536, 'architect
ure': {'input_modalities': ['image', 'text'], 'output_modalities': ['text'], 'to
kenizer': 'Other', 'instruct_type': None}, 'pricing': {'prompt': '0.00000308', '
completion': '0.00001215', 'image': '0.00000000', 'request': '0.00000000', 'web_
search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '
0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_lengt
h': 65536, 'max_completion_tokens': 8000, 'is_moderated': False}, 'per_request_l
imits': None, 'supported_parameters': ['frequency_penalty', 'include_reasoning',
 'logit_bias', 'max_tokens', 'min_p', 'presence_penalty', 'reasoning', 'repetiti
on_penalty', 'seed', 'stop', 'temperature', 'top_k', 'top_p']}, {'id': 'mistrala
i/devstral-medium', 'canonical_slug': 'mistralai/devstral-medium-2507', 'name':
'Mistral: Devstral Medium', 'created': 1752161321, 'context_length': 131072, 'ar
chitecture': {'input_modalities': ['text'], 'output_modalities': ['text'], 'toke
nizer': 'Mistral', 'instruct_type': None}, 'pricing': {'prompt': '0.00003521', '
completion': '0.00017606', 'image': '0.00000000', 'request': '0.00000000', 'web_
search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '
0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_lengt
h': 131072, 'max_completion_tokens': 0, 'is_moderated': False}, 'per_request_lim
its': None, 'supported_parameters': ['frequency_penalty', 'max_tokens', 'presenc
e_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperatur
e', 'tool_choice', 'tools', 'top_p']}, {'id': 'mistralai/devstral-small', 'canon
ical_slug': 'mistralai/devstral-small-2507', 'name': 'Mistral: Devstral Small 1.
1', 'created': 1752160751, 'context_length': 128000, 'architecture': {'input_mod
alities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Mistral', 'inst
ruct_type': None}, 'pricing': {'prompt': '0.00000616', 'completion': '0.00002465
', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', '
internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cach
e_write': '0.00000000'}, 'top_provider': {'context_length': 128000, 'max_complet
ion_tokens': 0, 'is_moderated': False}, 'per_request_limits': None, 'supported_p
arameters': ['frequency_penalty', 'max_tokens', 'min_p', 'presence_penalty', 're
petition_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'tem
perature', 'tool_choice', 'tools', 'top_k', 'top_p']}, {'id': 'x-ai/grok-4', 'ca
nonical_slug': 'x-ai/grok-4-07-09', 'name': 'xAI: Grok 4', 'created': 1752087689
, 'context_length': 256000, 'architecture': {'input_modalities': ['image', 'text
'], 'output_modalities': ['text'], 'tokenizer': 'Grok', 'instruct_type': None},
'pricing': {'prompt': '0.00026409', 'completion': '0.00132043', 'image': '0.0000
0000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning'
: '0.00000000', 'input_cache_read': '0.00006602', 'input_cache_write': '0.000000
00'}, 'top_provider': {'context_length': 256000, 'max_completion_tokens': 0, 'is
_moderated': False}, 'per_request_limits': None, 'supported_parameters': ['inclu
de_reasoning', 'logprobs', 'max_tokens', 'reasoning', 'response_format', 'seed',
 'structured_outputs', 'temperature', 'tool_choice', 'tools', 'top_logprobs', 't
op_p']}, {'id': 'tencent/hunyuan-a13b-instruct', 'canonical_slug': 'tencent/huny
uan-a13b-instruct', 'name': 'Tencent: Hunyuan A13B Instruct', 'created': 1751987
664, 'context_length': 32768, 'architecture': {'input_modalities': ['text'], 'ou
tput_modalities': ['text'], 'tokenizer': 'Other', 'instruct_type': None}, 'prici
ng': {'prompt': '0.00000264', 'completion': '0.00000264', 'image': '0.00000000',
 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.0
0000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'},
'top_provider': {'context_length': 32768, 'max_completion_tokens': 0, 'is_modera
ted': False}, 'per_request_limits': None, 'supported_parameters': ['frequency_pe
nalty', 'include_reasoning', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'p
resence_penalty', 'reasoning', 'repetition_penalty', 'seed', 'stop', 'temperatur
e', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'morph/morph-v3-large', 'canonica
l_slug': 'morph/morph-v3-large', 'name': 'Morph: Morph V3 Large', 'created': 175
1910858, 'context_length': 81920, 'architecture': {'input_modalities': ['text'],
 'output_modalities': ['text'], 'tokenizer': 'Other', 'instruct_type': None}, 'p
ricing': {'prompt': '0.00007923', 'completion': '0.00016725', 'image': '0.000000
00', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning':
'0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000
'}, 'top_provider': {'context_length': 81920, 'max_completion_tokens': 38000, 'i
s_moderated': False}, 'per_request_limits': None, 'supported_parameters': ['max_
tokens', 'stop', 'temperature']}, {'id': 'morph/morph-v3-fast', 'canonical_slug'
: 'morph/morph-v3-fast', 'name': 'Morph: Morph V3 Fast', 'created': 1751910002,
'context_length': 81920, 'architecture': {'input_modalities': ['text'], 'output_
modalities': ['text'], 'tokenizer': 'Other', 'instruct_type': None}, 'pricing':
{'prompt': '0.00007923', 'completion': '0.00016725', 'image': '0.00000000', 'req
uest': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.000000
00', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_
provider': {'context_length': 81920, 'max_completion_tokens': 38000, 'is_moderat
ed': False}, 'per_request_limits': None, 'supported_parameters': ['max_tokens',
'stop', 'temperature']}, {'id': 'baidu/ernie-4.5-vl-424b-a47b', 'canonical_slug'
: 'baidu/ernie-4.5-vl-424b-a47b', 'name': 'Baidu: ERNIE 4.5 VL 424B A47B ', 'cre
ated': 1751300903, 'context_length': 123000, 'architecture': {'input_modalities'
: ['image', 'text'], 'output_modalities': ['text'], 'tokenizer': 'Other', 'instr
uct_type': None}, 'pricing': {'prompt': '0.00003697', 'completion': '0.00011004'
, 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'i
nternal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache
_write': '0.00000000'}, 'top_provider': {'context_length': 123000, 'max_completi
on_tokens': 16000, 'is_moderated': False}, 'per_request_limits': None, 'supporte
d_parameters': ['frequency_penalty', 'include_reasoning', 'logit_bias', 'max_tok
ens', 'min_p', 'presence_penalty', 'reasoning', 'repetition_penalty', 'seed', 's
top', 'temperature', 'top_k', 'top_p']}, {'id': 'baidu/ernie-4.5-300b-a47b', 'ca
nonical_slug': 'baidu/ernie-4.5-300b-a47b', 'name': 'Baidu: ERNIE 4.5 300B A47B
', 'created': 1751300139, 'context_length': 123000, 'architecture': {'input_moda
lities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Other', 'instruc
t_type': None}, 'pricing': {'prompt': '0.00002465', 'completion': '0.00009683',
'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'int
ernal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_w
rite': '0.00000000'}, 'top_provider': {'context_length': 123000, 'max_completion
_tokens': 12000, 'is_moderated': False}, 'per_request_limits': None, 'supported_
parameters': ['frequency_penalty', 'logit_bias', 'max_tokens', 'min_p', 'presenc
e_penalty', 'repetition_penalty', 'seed', 'stop', 'temperature', 'top_k', 'top_p
']}, {'id': 'thedrummer/anubis-70b-v1.1', 'canonical_slug': 'thedrummer/anubis-7
0b-v1.1', 'name': 'TheDrummer: Anubis 70B V1.1', 'created': 1751208347, 'context
_length': 16384, 'architecture': {'input_modalities': ['text'], 'output_modaliti
es': ['text'], 'tokenizer': 'Llama3', 'instruct_type': None}, 'pricing': {'promp
t': '0.00003521', 'completion': '0.00006162', 'image': '0.00000000', 'request':
'0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'i
nput_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provide
r': {'context_length': 16384, 'max_completion_tokens': 0, 'is_moderated': False}
, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty', 'max
_tokens', 'min_p', 'presence_penalty', 'repetition_penalty', 'response_format',
'seed', 'stop', 'structured_outputs', 'temperature', 'top_k', 'top_p']}, {'id':
'inception/mercury', 'canonical_slug': 'inception/mercury', 'name': 'Inception:
Mercury', 'created': 1750973026, 'context_length': 128000, 'architecture': {'inp
ut_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Other', '
instruct_type': None}, 'pricing': {'prompt': '0.00002201', 'completion': '0.0000
8803', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000
', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_
cache_write': '0.00000000'}, 'top_provider': {'context_length': 128000, 'max_com
pletion_tokens': 16384, 'is_moderated': False}, 'per_request_limits': None, 'sup
ported_parameters': ['frequency_penalty', 'max_tokens', 'presence_penalty', 'res
ponse_format', 'stop', 'structured_outputs', 'temperature', 'tool_choice', 'tool
s', 'top_k', 'top_p']}, {'id': 'mistralai/mistral-small-3.2-24b-instruct', 'cano
nical_slug': 'mistralai/mistral-small-3.2-24b-instruct-2506', 'name': 'Mistral:
Mistral Small 3.2 24B', 'created': 1750443016, 'context_length': 128000, 'archit
ecture': {'input_modalities': ['image', 'text'], 'output_modalities': ['text'],
'tokenizer': 'Mistral', 'instruct_type': None}, 'pricing': {'prompt': '0.0000044
0', 'completion': '0.00000880', 'image': '0.00000000', 'request': '0.00000000',
'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_rea
d': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_
length': 128000, 'max_completion_tokens': 0, 'is_moderated': False}, 'per_reques
t_limits': None, 'supported_parameters': ['frequency_penalty', 'logit_bias', 'lo
gprobs', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_penalty', 'respo
nse_format', 'seed', 'stop', 'structured_outputs', 'temperature', 'tool_choice',
 'tools', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'minimax/minimax-m1', 'cano
nical_slug': 'minimax/minimax-m1', 'name': 'MiniMax: MiniMax M1', 'created': 175
0200414, 'context_length': 1000000, 'architecture': {'input_modalities': ['text'
], 'output_modalities': ['text'], 'tokenizer': 'Other', 'instruct_type': None},
'pricing': {'prompt': '0.00002641', 'completion': '0.00014525', 'image': '0.0000
0000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning'
: '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.000000
00'}, 'top_provider': {'context_length': 1000000, 'max_completion_tokens': 40000
, 'is_moderated': False}, 'per_request_limits': None, 'supported_parameters': ['
frequency_penalty', 'include_reasoning', 'logit_bias', 'max_tokens', 'min_p', 'p
resence_penalty', 'reasoning', 'repetition_penalty', 'seed', 'stop', 'structured
_outputs', 'temperature', 'tool_choice', 'tools', 'top_k', 'top_p']}, {'id': 'go
ogle/gemini-2.5-flash-lite-preview-06-17', 'canonical_slug': 'google/gemini-2.5-
flash-lite-preview-06-17', 'name': 'Google: Gemini 2.5 Flash Lite Preview 06-17'
, 'created': 1750173831, 'context_length': 1048576, 'architecture': {'input_moda
lities': ['file', 'image', 'text', 'audio'], 'output_modalities': ['text'], 'tok
enizer': 'Gemini', 'instruct_type': None}, 'pricing': {'prompt': '0.00000880', '
completion': '0.00003521', 'image': '0.00000000', 'request': '0.00000000', 'web_
search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '
0.00000220', 'input_cache_write': '0.00001614'}, 'top_provider': {'context_lengt
h': 1048576, 'max_completion_tokens': 65535, 'is_moderated': False}, 'per_reques
t_limits': None, 'supported_parameters': ['include_reasoning', 'max_tokens', 're
asoning', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperature'
, 'tool_choice', 'tools', 'top_p']}, {'id': 'google/gemini-2.5-flash', 'canonica
l_slug': 'google/gemini-2.5-flash', 'name': 'Google: Gemini 2.5 Flash', 'created
': 1750172488, 'context_length': 1048576, 'architecture': {'input_modalities': [
'file', 'image', 'text', 'audio'], 'output_modalities': ['text'], 'tokenizer': '
Gemini', 'instruct_type': None}, 'pricing': {'prompt': '0.00002641', 'completion
': '0.00022007', 'image': '0.10897916', 'request': '0.00000000', 'web_search': '
0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000660
', 'input_cache_write': '0.00003374'}, 'top_provider': {'context_length': 104857
6, 'max_completion_tokens': 65535, 'is_moderated': False}, 'per_request_limits':
 None, 'supported_parameters': ['include_reasoning', 'max_tokens', 'reasoning',
'response_format', 'seed', 'stop', 'structured_outputs', 'temperature', 'tool_ch
oice', 'tools', 'top_p']}, {'id': 'google/gemini-2.5-pro', 'canonical_slug': 'go
ogle/gemini-2.5-pro', 'name': 'Google: Gemini 2.5 Pro', 'created': 1750169544, '
context_length': 1048576, 'architecture': {'input_modalities': ['file', 'image',
 'text', 'audio'], 'output_modalities': ['text'], 'tokenizer': 'Gemini', 'instru
ct_type': None}, 'pricing': {'prompt': '0.00011004', 'completion': '0.00088028',
 'image': '0.45422654', 'request': '0.00000000', 'web_search': '0.00000000', 'in
ternal_reasoning': '0.00000000', 'input_cache_read': '0.00002729', 'input_cache_
write': '0.00014305'}, 'top_provider': {'context_length': 1048576, 'max_completi
on_tokens': 65536, 'is_moderated': False}, 'per_request_limits': None, 'supporte
d_parameters': ['include_reasoning', 'max_tokens', 'reasoning', 'response_format
', 'seed', 'stop', 'structured_outputs', 'temperature', 'tool_choice', 'tools',
'top_p']}, {'id': 'openai/o3-pro', 'canonical_slug': 'openai/o3-pro-2025-06-10',
 'name': 'OpenAI: o3 Pro', 'created': 1749598352, 'context_length': 200000, 'arc
hitecture': {'input_modalities': ['text', 'file', 'image'], 'output_modalities':
 ['text'], 'tokenizer': 'GPT', 'instruct_type': None}, 'pricing': {'prompt': '0.
00176057', 'completion': '0.00704227', 'image': '1.34683452', 'request': '0.0000
0000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_ca
che_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'c
ontext_length': 200000, 'max_completion_tokens': 100000, 'is_moderated': True},
'per_request_limits': None, 'supported_parameters': ['include_reasoning', 'max_t
okens', 'reasoning', 'response_format', 'seed', 'structured_outputs', 'tool_choi
ce', 'tools']}, {'id': 'x-ai/grok-3-mini', 'canonical_slug': 'x-ai/grok-3-mini',
 'name': 'xAI: Grok 3 Mini', 'created': 1749583245, 'context_length': 131072, 'a
rchitecture': {'input_modalities': ['text'], 'output_modalities': ['text'], 'tok
enizer': 'Grok', 'instruct_type': None}, 'pricing': {'prompt': '0.00002641', 'co
mpletion': '0.00004401', 'image': '0.00000000', 'request': '0.00000000', 'web_se
arch': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.
00000660', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length'
: 131072, 'max_completion_tokens': 0, 'is_moderated': False}, 'per_request_limit
s': None, 'supported_parameters': ['include_reasoning', 'logprobs', 'max_tokens'
, 'reasoning', 'response_format', 'seed', 'stop', 'structured_outputs', 'tempera
ture', 'tool_choice', 'tools', 'top_logprobs', 'top_p']}, {'id': 'x-ai/grok-3',
'canonical_slug': 'x-ai/grok-3', 'name': 'xAI: Grok 3', 'created': 1749582908, '
context_length': 131072, 'architecture': {'input_modalities': ['text'], 'output_
modalities': ['text'], 'tokenizer': 'Grok', 'instruct_type': None}, 'pricing': {
'prompt': '0.00026409', 'completion': '0.00132043', 'image': '0.00000000', 'requ
est': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.0000000
0', 'input_cache_read': '0.00006602', 'input_cache_write': '0.00000000'}, 'top_p
rovider': {'context_length': 131072, 'max_completion_tokens': 0, 'is_moderated':
 False}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty
', 'logprobs', 'max_tokens', 'presence_penalty', 'response_format', 'seed', 'sto
p', 'structured_outputs', 'temperature', 'tool_choice', 'tools', 'top_logprobs',
 'top_p']}, {'id': 'mistralai/magistral-small-2506', 'canonical_slug': 'mistrala
i/magistral-small-2506', 'name': 'Mistral: Magistral Small 2506', 'created': 174
9569561, 'context_length': 40000, 'architecture': {'input_modalities': ['text'],
 'output_modalities': ['text'], 'tokenizer': 'Mistral', 'instruct_type': None},
'pricing': {'prompt': '0.00004401', 'completion': '0.00013204', 'image': '0.0000
0000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning'
: '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.000000
00'}, 'top_provider': {'context_length': 40000, 'max_completion_tokens': 40000,
'is_moderated': False}, 'per_request_limits': None, 'supported_parameters': ['fr
equency_penalty', 'include_reasoning', 'max_tokens', 'presence_penalty', 'reason
ing', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperature', 't
ool_choice', 'tools', 'top_p']}, {'id': 'mistralai/magistral-medium-2506', 'cano
nical_slug': 'mistralai/magistral-medium-2506', 'name': 'Mistral: Magistral Medi
um 2506', 'created': 1749354054, 'context_length': 40960, 'architecture': {'inpu
t_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Mistral',
'instruct_type': None}, 'pricing': {'prompt': '0.00017606', 'completion': '0.000
44014', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.0000000
0', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input
_cache_write': '0.00000000'}, 'top_provider': {'context_length': 40960, 'max_com
pletion_tokens': 40000, 'is_moderated': False}, 'per_request_limits': None, 'sup
ported_parameters': ['frequency_penalty', 'include_reasoning', 'max_tokens', 'pr
esence_penalty', 'reasoning', 'response_format', 'seed', 'stop', 'structured_out
puts', 'temperature', 'tool_choice', 'tools', 'top_p']}, {'id': 'mistralai/magis
tral-medium-2506:thinking', 'canonical_slug': 'mistralai/magistral-medium-2506',
 'name': 'Mistral: Magistral Medium 2506 (thinking)', 'created': 1749354054, 'co
ntext_length': 40960, 'architecture': {'input_modalities': ['text'], 'output_mod
alities': ['text'], 'tokenizer': 'Mistral', 'instruct_type': None}, 'pricing': {
'prompt': '0.00017606', 'completion': '0.00044014', 'image': '0.00000000', 'requ
est': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.0000000
0', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_p
rovider': {'context_length': 40960, 'max_completion_tokens': 40000, 'is_moderate
d': False}, 'per_request_limits': None, 'supported_parameters': ['frequency_pena
lty', 'include_reasoning', 'max_tokens', 'presence_penalty', 'reasoning', 'respo
nse_format', 'seed', 'stop', 'structured_outputs', 'temperature', 'tool_choice',
 'tools', 'top_p']}, {'id': 'google/gemini-2.5-pro-preview', 'canonical_slug': '
google/gemini-2.5-pro-preview-06-05', 'name': 'Google: Gemini 2.5 Pro Preview 06
-05', 'created': 1749137257, 'context_length': 1048576, 'architecture': {'input_
modalities': ['file', 'image', 'text', 'audio'], 'output_modalities': ['text'],
'tokenizer': 'Gemini', 'instruct_type': None}, 'pricing': {'prompt': '0.00011004
', 'completion': '0.00088028', 'image': '0.45422654', 'request': '0.00000000', '
web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read
': '0.00002729', 'input_cache_write': '0.00014305'}, 'top_provider': {'context_l
ength': 1048576, 'max_completion_tokens': 65536, 'is_moderated': False}, 'per_re
quest_limits': None, 'supported_parameters': ['include_reasoning', 'max_tokens',
 'reasoning', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperat
ure', 'tool_choice', 'tools', 'top_p']}, {'id': 'deepseek/deepseek-r1-0528-qwen3
-8b', 'canonical_slug': 'deepseek/deepseek-r1-0528-qwen3-8b', 'name': 'DeepSeek:
 Deepseek R1 0528 Qwen3 8B', 'created': 1748538543, 'context_length': 32000, 'ar
chitecture': {'input_modalities': ['text'], 'output_modalities': ['text'], 'toke
nizer': 'Qwen', 'instruct_type': 'deepseek-r1'}, 'pricing': {'prompt': '0.000000
88', 'completion': '0.00000176', 'image': '0.00000000', 'request': '0.00000000',
 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_re
ad': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context
_length': 32000, 'max_completion_tokens': 0, 'is_moderated': False}, 'per_reques
t_limits': None, 'supported_parameters': ['frequency_penalty', 'include_reasonin
g', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'reason
ing', 'repetition_penalty', 'seed', 'stop', 'temperature', 'top_k', 'top_logprob
s', 'top_p']}, {'id': 'deepseek/deepseek-r1-0528', 'canonical_slug': 'deepseek/d
eepseek-r1-0528', 'name': 'DeepSeek: R1 0528', 'created': 1748455170, 'context_l
ength': 163840, 'architecture': {'input_modalities': ['text'], 'output_modalitie
s': ['text'], 'tokenizer': 'DeepSeek', 'instruct_type': 'deepseek-r1'}, 'pricing
': {'prompt': '0.00001760', 'completion': '0.00007043', 'image': '0.00000000', '
request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.000
00000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 't
op_provider': {'context_length': 163840, 'max_completion_tokens': 0, 'is_moderat
ed': False}, 'per_request_limits': None, 'supported_parameters': ['frequency_pen
alty', 'include_reasoning', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'pr
esence_penalty', 'reasoning', 'repetition_penalty', 'response_format', 'seed', '
stop', 'structured_outputs', 'temperature', 'tool_choice', 'tools', 'top_k', 'to
p_logprobs', 'top_p']}, {'id': 'anthropic/claude-opus-4', 'canonical_slug': 'ant
hropic/claude-4-opus-20250522', 'name': 'Anthropic: Claude Opus 4', 'created': 1
747931245, 'context_length': 200000, 'architecture': {'input_modalities': ['imag
e', 'text', 'file'], 'output_modalities': ['text'], 'tokenizer': 'Claude', 'inst
ruct_type': None}, 'pricing': {'prompt': '0.00132043', 'completion': '0.00660213
', 'image': '2.11268160', 'request': '0.00000000', 'web_search': '0.00000000', '
internal_reasoning': '0.00000000', 'input_cache_read': '0.00013204', 'input_cach
e_write': '0.00165053'}, 'top_provider': {'context_length': 200000, 'max_complet
ion_tokens': 32000, 'is_moderated': True}, 'per_request_limits': None, 'supporte
d_parameters': ['include_reasoning', 'max_tokens', 'reasoning', 'stop', 'tempera
ture', 'tool_choice', 'tools', 'top_k', 'top_p']}, {'id': 'anthropic/claude-sonn
et-4', 'canonical_slug': 'anthropic/claude-4-sonnet-20250522', 'name': 'Anthropi
c: Claude Sonnet 4', 'created': 1747930371, 'context_length': 200000, 'architect
ure': {'input_modalities': ['image', 'text', 'file'], 'output_modalities': ['tex
t'], 'tokenizer': 'Claude', 'instruct_type': None}, 'pricing': {'prompt': '0.000
26409', 'completion': '0.00132043', 'image': '0.42253632', 'request': '0.0000000
0', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache
_read': '0.00002641', 'input_cache_write': '0.00033011'}, 'top_provider': {'cont
ext_length': 200000, 'max_completion_tokens': 64000, 'is_moderated': False}, 'pe
r_request_limits': None, 'supported_parameters': ['include_reasoning', 'max_toke
ns', 'reasoning', 'stop', 'temperature', 'tool_choice', 'tools', 'top_k', 'top_p
']}, {'id': 'mistralai/devstral-small-2505', 'canonical_slug': 'mistralai/devstr
al-small-2505', 'name': 'Mistral: Devstral Small 2505', 'created': 1747837379, '
context_length': 131072, 'architecture': {'input_modalities': ['text'], 'output_
modalities': ['text'], 'tokenizer': 'Mistral', 'instruct_type': None}, 'pricing'
: {'prompt': '0.00000176', 'completion': '0.00000704', 'image': '0.00000000', 'r
equest': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.0000
0000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'to
p_provider': {'context_length': 131072, 'max_completion_tokens': 0, 'is_moderate
d': False}, 'per_request_limits': None, 'supported_parameters': ['frequency_pena
lty', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'repe
tition_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'tempe
rature', 'tool_choice', 'tools', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'goo
gle/gemma-3n-e4b-it', 'canonical_slug': 'google/gemma-3n-e4b-it', 'name': 'Googl
e: Gemma 3n 4B', 'created': 1747776824, 'context_length': 32768, 'architecture':
 {'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Oth
er', 'instruct_type': None}, 'pricing': {'prompt': '0.00000176', 'completion': '
0.00000352', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00
000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', '
input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 32768, 'ma
x_completion_tokens': 0, 'is_moderated': False}, 'per_request_limits': None, 'su
pported_parameters': ['frequency_penalty', 'logit_bias', 'max_tokens', 'min_p',
'presence_penalty', 'repetition_penalty', 'stop', 'temperature', 'top_k', 'top_p
']}, {'id': 'openai/codex-mini', 'canonical_slug': 'openai/codex-mini', 'name':
'OpenAI: Codex Mini', 'created': 1747409761, 'context_length': 200000, 'architec
ture': {'input_modalities': ['image', 'text'], 'output_modalities': ['text'], 't
okenizer': 'GPT', 'instruct_type': None}, 'pricing': {'prompt': '0.00013204', 'c
ompletion': '0.00052817', 'image': '0.00000000', 'request': '0.00000000', 'web_s
earch': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0
.00003301', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length
': 200000, 'max_completion_tokens': 100000, 'is_moderated': True}, 'per_request_
limits': None, 'supported_parameters': ['include_reasoning', 'max_tokens', 'reas
oning', 'response_format', 'seed', 'structured_outputs', 'tool_choice', 'tools']
}, {'id': 'nousresearch/deephermes-3-mistral-24b-preview', 'canonical_slug': 'no
usresearch/deephermes-3-mistral-24b-preview', 'name': 'Nous: DeepHermes 3 Mistra
l 24B Preview', 'created': 1746830904, 'context_length': 32768, 'architecture':
{'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Othe
r', 'instruct_type': None}, 'pricing': {'prompt': '0.00000821', 'completion': '0
.00003287', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.000
00000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'i
nput_cache_write': '0.00000000'}, 'top_provider': {'context_length': 32768, 'max
_completion_tokens': 0, 'is_moderated': False}, 'per_request_limits': None, 'sup
ported_parameters': ['frequency_penalty', 'include_reasoning', 'logit_bias', 'lo
gprobs', 'max_tokens', 'min_p', 'presence_penalty', 'reasoning', 'repetition_pen
alty', 'seed', 'stop', 'temperature', 'top_k', 'top_logprobs', 'top_p']}, {'id':
 'mistralai/mistral-medium-3', 'canonical_slug': 'mistralai/mistral-medium-3', '
name': 'Mistral: Mistral Medium 3', 'created': 1746627341, 'context_length': 131
072, 'architecture': {'input_modalities': ['text', 'image'], 'output_modalities'
: ['text'], 'tokenizer': 'Mistral', 'instruct_type': None}, 'pricing': {'prompt'
: '0.00003521', 'completion': '0.00017606', 'image': '0.00000000', 'request': '0
.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'inp
ut_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider'
: {'context_length': 131072, 'max_completion_tokens': 0, 'is_moderated': False},
 'per_request_limits': None, 'supported_parameters': ['frequency_penalty', 'max_
tokens', 'presence_penalty', 'response_format', 'seed', 'stop', 'structured_outp
uts', 'temperature', 'tool_choice', 'tools', 'top_p']}, {'id': 'google/gemini-2.
5-pro-preview-05-06', 'canonical_slug': 'google/gemini-2.5-pro-preview-03-25', '
name': 'Google: Gemini 2.5 Pro Preview 05-06', 'created': 1746578513, 'context_l
ength': 1048576, 'architecture': {'input_modalities': ['text', 'image', 'file',
'audio'], 'output_modalities': ['text'], 'tokenizer': 'Gemini', 'instruct_type':
 None}, 'pricing': {'prompt': '0.00011004', 'completion': '0.00088028', 'image':
 '0.45422654', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_re
asoning': '0.00000000', 'input_cache_read': '0.00002729', 'input_cache_write': '
0.00014305'}, 'top_provider': {'context_length': 1048576, 'max_completion_tokens
': 65535, 'is_moderated': False}, 'per_request_limits': None, 'supported_paramet
ers': ['include_reasoning', 'max_tokens', 'reasoning', 'response_format', 'seed'
, 'stop', 'structured_outputs', 'temperature', 'tool_choice', 'tools', 'top_p']}
, {'id': 'arcee-ai/spotlight', 'canonical_slug': 'arcee-ai/spotlight', 'name': '
Arcee AI: Spotlight', 'created': 1746481552, 'context_length': 131072, 'architec
ture': {'input_modalities': ['image', 'text'], 'output_modalities': ['text'], 't
okenizer': 'Other', 'instruct_type': None}, 'pricing': {'prompt': '0.00001585',
'completion': '0.00001585', 'image': '0.00000000', 'request': '0.00000000', 'web
_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read':
'0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_leng
th': 131072, 'max_completion_tokens': 65537, 'is_moderated': False}, 'per_reques
t_limits': None, 'supported_parameters': ['frequency_penalty', 'logit_bias', 'ma
x_tokens', 'min_p', 'presence_penalty', 'repetition_penalty', 'stop', 'temperatu
re', 'top_k', 'top_p']}, {'id': 'arcee-ai/maestro-reasoning', 'canonical_slug':
'arcee-ai/maestro-reasoning', 'name': 'Arcee AI: Maestro Reasoning', 'created':
1746481269, 'context_length': 131072, 'architecture': {'input_modalities': ['tex
t'], 'output_modalities': ['text'], 'tokenizer': 'Other', 'instruct_type': None}
, 'pricing': {'prompt': '0.00007923', 'completion': '0.00029049', 'image': '0.00
000000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasonin
g': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.0000
0000'}, 'top_provider': {'context_length': 131072, 'max_completion_tokens': 3200
0, 'is_moderated': False}, 'per_request_limits': None, 'supported_parameters': [
'frequency_penalty', 'logit_bias', 'max_tokens', 'min_p', 'presence_penalty', 'r
epetition_penalty', 'stop', 'temperature', 'top_k', 'top_p']}, {'id': 'arcee-ai/
virtuoso-large', 'canonical_slug': 'arcee-ai/virtuoso-large', 'name': 'Arcee AI:
 Virtuoso Large', 'created': 1746478885, 'context_length': 131072, 'architecture
': {'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'O
ther', 'instruct_type': None}, 'pricing': {'prompt': '0.00006602', 'completion':
 '0.00010563', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.
00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000',
 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 131072,
'max_completion_tokens': 64000, 'is_moderated': False}, 'per_request_limits': No
ne, 'supported_parameters': ['frequency_penalty', 'logit_bias', 'max_tokens', 'm
in_p', 'presence_penalty', 'repetition_penalty', 'stop', 'temperature', 'tool_ch
oice', 'tools', 'top_k', 'top_p']}, {'id': 'arcee-ai/coder-large', 'canonical_sl
ug': 'arcee-ai/coder-large', 'name': 'Arcee AI: Coder Large', 'created': 1746478
663, 'context_length': 32768, 'architecture': {'input_modalities': ['text'], 'ou
tput_modalities': ['text'], 'tokenizer': 'Other', 'instruct_type': None}, 'prici
ng': {'prompt': '0.00004401', 'completion': '0.00007042', 'image': '0.00000000',
 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.0
0000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'},
'top_provider': {'context_length': 32768, 'max_completion_tokens': 0, 'is_modera
ted': False}, 'per_request_limits': None, 'supported_parameters': ['frequency_pe
nalty', 'logit_bias', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_pen
alty', 'stop', 'temperature', 'top_k', 'top_p']}, {'id': 'microsoft/phi-4-reason
ing-plus', 'canonical_slug': 'microsoft/phi-4-reasoning-plus-04-30', 'name': 'Mi
crosoft: Phi 4 Reasoning Plus', 'created': 1746130961, 'context_length': 32768,
'architecture': {'input_modalities': ['text'], 'output_modalities': ['text'], 't
okenizer': 'Other', 'instruct_type': None}, 'pricing': {'prompt': '0.00000616',
'completion': '0.00003081', 'image': '0.00000000', 'request': '0.00000000', 'web
_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read':
'0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_leng
th': 32768, 'max_completion_tokens': 0, 'is_moderated': False}, 'per_request_lim
its': None, 'supported_parameters': ['frequency_penalty', 'include_reasoning', '
max_tokens', 'min_p', 'presence_penalty', 'reasoning', 'repetition_penalty', 're
sponse_format', 'seed', 'stop', 'temperature', 'top_k', 'top_p']}, {'id': 'incep
tion/mercury-coder', 'canonical_slug': 'inception/mercury-coder-small-beta', 'na
me': 'Inception: Mercury Coder', 'created': 1746033880, 'context_length': 128000
, 'architecture': {'input_modalities': ['text'], 'output_modalities': ['text'],
'tokenizer': 'Other', 'instruct_type': None}, 'pricing': {'prompt': '0.00002201'
, 'completion': '0.00008803', 'image': '0.00000000', 'request': '0.00000000', 'w
eb_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read'
: '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_le
ngth': 128000, 'max_completion_tokens': 16384, 'is_moderated': False}, 'per_requ
est_limits': None, 'supported_parameters': ['frequency_penalty', 'max_tokens', '
presence_penalty', 'response_format', 'stop', 'structured_outputs', 'temperature
', 'tool_choice', 'tools', 'top_k', 'top_p']}, {'id': 'opengvlab/internvl3-14b',
 'canonical_slug': 'opengvlab/internvl3-14b', 'name': 'OpenGVLab: InternVL3 14B'
, 'created': 1746021355, 'context_length': 12288, 'architecture': {'input_modali
ties': ['image', 'text'], 'output_modalities': ['text'], 'tokenizer': 'Other', '
instruct_type': None}, 'pricing': {'prompt': '0.00001761', 'completion': '0.0000
3521', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000
', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_
cache_write': '0.00000000'}, 'top_provider': {'context_length': 12288, 'max_comp
letion_tokens': 0, 'is_moderated': False}, 'per_request_limits': None, 'supporte
d_parameters': ['max_tokens', 'temperature', 'top_p']}, {'id': 'deepseek/deepsee
k-prover-v2', 'canonical_slug': 'deepseek/deepseek-prover-v2', 'name': 'DeepSeek
: DeepSeek Prover V2', 'created': 1746013094, 'context_length': 163840, 'archite
cture': {'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer
': 'DeepSeek', 'instruct_type': None}, 'pricing': {'prompt': '0.00004401', 'comp
letion': '0.00019190', 'image': '0.00000000', 'request': '0.00000000', 'web_sear
ch': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00
000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length':
163840, 'max_completion_tokens': 0, 'is_moderated': False}, 'per_request_limits'
: None, 'supported_parameters': ['frequency_penalty', 'max_tokens', 'min_p', 'pr
esence_penalty', 'repetition_penalty', 'response_format', 'seed', 'stop', 'tempe
rature', 'top_k', 'top_p']}, {'id': 'meta-llama/llama-guard-4-12b', 'canonical_s
lug': 'meta-llama/llama-guard-4-12b', 'name': 'Meta: Llama Guard 4 12B', 'create
d': 1745975193, 'context_length': 163840, 'architecture': {'input_modalities': [
'image', 'text'], 'output_modalities': ['text'], 'tokenizer': 'Other', 'instruct
_type': None}, 'pricing': {'prompt': '0.00001585', 'completion': '0.00001585', '
image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'inte
rnal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_wr
ite': '0.00000000'}, 'top_provider': {'context_length': 163840, 'max_completion_
tokens': 0, 'is_moderated': False}, 'per_request_limits': None, 'supported_param
eters': ['frequency_penalty', 'logit_bias', 'max_tokens', 'min_p', 'presence_pen
alty', 'repetition_penalty', 'response_format', 'seed', 'stop', 'temperature', '
top_k', 'top_p']}, {'id': 'qwen/qwen3-30b-a3b', 'canonical_slug': 'qwen/qwen3-30
b-a3b-04-28', 'name': 'Qwen: Qwen3 30B A3B', 'created': 1745878604, 'context_len
gth': 40960, 'architecture': {'input_modalities': ['text'], 'output_modalities':
 ['text'], 'tokenizer': 'Qwen3', 'instruct_type': 'qwen3'}, 'pricing': {'prompt'
: '0.00000176', 'completion': '0.00000704', 'image': '0.00000000', 'request': '0
.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'inp
ut_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider'
: {'context_length': 40960, 'max_completion_tokens': 0, 'is_moderated': False},
'per_request_limits': None, 'supported_parameters': ['frequency_penalty', 'inclu
de_reasoning', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalt
y', 'reasoning', 'repetition_penalty', 'response_format', 'seed', 'stop', 'struc
tured_outputs', 'temperature', 'tool_choice', 'tools', 'top_k', 'top_logprobs',
'top_p']}, {'id': 'qwen/qwen3-8b', 'canonical_slug': 'qwen/qwen3-8b-04-28', 'nam
e': 'Qwen: Qwen3 8B', 'created': 1745876632, 'context_length': 128000, 'architec
ture': {'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer'
: 'Qwen3', 'instruct_type': 'qwen3'}, 'pricing': {'prompt': '0.00000308', 'compl
etion': '0.00001215', 'image': '0.00000000', 'request': '0.00000000', 'web_searc
h': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.000
00000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 1
28000, 'max_completion_tokens': 20000, 'is_moderated': False}, 'per_request_limi
ts': None, 'supported_parameters': ['frequency_penalty', 'include_reasoning', 'l
ogit_bias', 'max_tokens', 'min_p', 'presence_penalty', 'reasoning', 'repetition_
penalty', 'seed', 'stop', 'temperature', 'top_k', 'top_p']}, {'id': 'qwen/qwen3-
14b', 'canonical_slug': 'qwen/qwen3-14b-04-28', 'name': 'Qwen: Qwen3 14B', 'crea
ted': 1745876478, 'context_length': 40960, 'architecture': {'input_modalities':
['text'], 'output_modalities': ['text'], 'tokenizer': 'Qwen3', 'instruct_type':
'qwen3'}, 'pricing': {'prompt': '0.00000528', 'completion': '0.00002113', 'image
': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_
reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write':
 '0.00000000'}, 'top_provider': {'context_length': 40960, 'max_completion_tokens
': 40960, 'is_moderated': False}, 'per_request_limits': None, 'supported_paramet
ers': ['frequency_penalty', 'include_reasoning', 'logit_bias', 'logprobs', 'max_
tokens', 'min_p', 'presence_penalty', 'reasoning', 'repetition_penalty', 'respon
se_format', 'seed', 'stop', 'structured_outputs', 'temperature', 'tool_choice',
'tools', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'qwen/qwen3-32b', 'canonical
_slug': 'qwen/qwen3-32b-04-28', 'name': 'Qwen: Qwen3 32B', 'created': 1745875945
, 'context_length': 40960, 'architecture': {'input_modalities': ['text'], 'outpu
t_modalities': ['text'], 'tokenizer': 'Qwen3', 'instruct_type': 'qwen3'}, 'prici
ng': {'prompt': '0.00000158', 'completion': '0.00000634', 'image': '0.00000000',
 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.0
0000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'},
'top_provider': {'context_length': 40960, 'max_completion_tokens': 0, 'is_modera
ted': False}, 'per_request_limits': None, 'supported_parameters': ['frequency_pe
nalty', 'include_reasoning', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'p
resence_penalty', 'reasoning', 'repetition_penalty', 'response_format', 'seed',
'stop', 'structured_outputs', 'temperature', 'tool_choice', 'tools', 'top_k', 't
op_logprobs', 'top_p']}, {'id': 'qwen/qwen3-235b-a22b', 'canonical_slug': 'qwen/
qwen3-235b-a22b-04-28', 'name': 'Qwen: Qwen3 235B A22B', 'created': 1745875757,
'context_length': 40960, 'architecture': {'input_modalities': ['text'], 'output_
modalities': ['text'], 'tokenizer': 'Qwen3', 'instruct_type': 'qwen3'}, 'pricing
': {'prompt': '0.00001144', 'completion': '0.00005282', 'image': '0.00000000', '
request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.000
00000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 't
op_provider': {'context_length': 40960, 'max_completion_tokens': 40960, 'is_mode
rated': False}, 'per_request_limits': None, 'supported_parameters': ['frequency_
penalty', 'include_reasoning', 'logit_bias', 'logprobs', 'max_tokens', 'min_p',
'presence_penalty', 'reasoning', 'repetition_penalty', 'response_format', 'seed'
, 'stop', 'structured_outputs', 'temperature', 'tool_choice', 'tools', 'top_k',
'top_logprobs', 'top_p']}, {'id': 'tngtech/deepseek-r1t-chimera', 'canonical_slu
g': 'tngtech/deepseek-r1t-chimera', 'name': 'TNG: DeepSeek R1T Chimera', 'create
d': 1745760875, 'context_length': 163840, 'architecture': {'input_modalities': [
'text'], 'output_modalities': ['text'], 'tokenizer': 'DeepSeek', 'instruct_type'
: None}, 'pricing': {'prompt': '0.00001760', 'completion': '0.00007043', 'image'
: '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_r
easoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write':
'0.00000000'}, 'top_provider': {'context_length': 163840, 'max_completion_tokens
': 0, 'is_moderated': False}, 'per_request_limits': None, 'supported_parameters'
: ['frequency_penalty', 'include_reasoning', 'logit_bias', 'logprobs', 'max_toke
ns', 'min_p', 'presence_penalty', 'reasoning', 'repetition_penalty', 'seed', 'st
op', 'temperature', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'microsoft/mai-ds
-r1', 'canonical_slug': 'microsoft/mai-ds-r1', 'name': 'Microsoft: MAI DS R1', '
created': 1745194100, 'context_length': 163840, 'architecture': {'input_modaliti
es': ['text'], 'output_modalities': ['text'], 'tokenizer': 'DeepSeek', 'instruct
_type': 'deepseek-r1'}, 'pricing': {'prompt': '0.00001760', 'completion': '0.000
07043', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.0000000
0', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input
_cache_write': '0.00000000'}, 'top_provider': {'context_length': 163840, 'max_co
mpletion_tokens': 0, 'is_moderated': False}, 'per_request_limits': None, 'suppor
ted_parameters': ['frequency_penalty', 'include_reasoning', 'logit_bias', 'logpr
obs', 'max_tokens', 'min_p', 'presence_penalty', 'reasoning', 'repetition_penalt
y', 'seed', 'stop', 'temperature', 'top_k', 'top_logprobs', 'top_p']}, {'id': 't
hudm/glm-z1-32b', 'canonical_slug': 'thudm/glm-z1-32b-0414', 'name': 'THUDM: GLM
 Z1 32B', 'created': 1744924148, 'context_length': 32768, 'architecture': {'inpu
t_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Other', 'i
nstruct_type': 'deepseek-r1'}, 'pricing': {'prompt': '0.00000176', 'completion':
 '0.00000704', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.
00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000',
 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 32768, '
max_completion_tokens': 0, 'is_moderated': False}, 'per_request_limits': None, '
supported_parameters': ['frequency_penalty', 'include_reasoning', 'logit_bias',
'logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'reasoning', 'repetition_
penalty', 'seed', 'stop', 'temperature', 'top_k', 'top_logprobs', 'top_p']}, {'i
d': 'thudm/glm-4-32b', 'canonical_slug': 'thudm/glm-4-32b-0414', 'name': 'THUDM:
 GLM 4 32B', 'created': 1744920915, 'context_length': 32000, 'architecture': {'i
nput_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Other',
 'instruct_type': None}, 'pricing': {'prompt': '0.00004842', 'completion': '0.00
014613', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.000000
00', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'inpu
t_cache_write': '0.00000000'}, 'top_provider': {'context_length': 32000, 'max_co
mpletion_tokens': 32000, 'is_moderated': False}, 'per_request_limits': None, 'su
pported_parameters': ['frequency_penalty', 'logit_bias', 'max_tokens', 'min_p',
'presence_penalty', 'repetition_penalty', 'seed', 'stop', 'temperature', 'top_k'
, 'top_p']}, {'id': 'openai/o4-mini-high', 'canonical_slug': 'openai/o4-mini-hig
h-2025-04-16', 'name': 'OpenAI: o4 Mini High', 'created': 1744824212, 'context_l
ength': 200000, 'architecture': {'input_modalities': ['image', 'text', 'file'],
'output_modalities': ['text'], 'tokenizer': 'Other', 'instruct_type': None}, 'pr
icing': {'prompt': '0.00009683', 'completion': '0.00038732', 'image': '0.0740759
0', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '
0.00000000', 'input_cache_read': '0.00002421', 'input_cache_write': '0.00000000'
}, 'top_provider': {'context_length': 200000, 'max_completion_tokens': 100000, '
is_moderated': True}, 'per_request_limits': None, 'supported_parameters': ['incl
ude_reasoning', 'max_tokens', 'reasoning', 'response_format', 'seed', 'structure
d_outputs', 'tool_choice', 'tools']}, {'id': 'openai/o3', 'canonical_slug': 'ope
nai/o3-2025-04-16', 'name': 'OpenAI: o3', 'created': 1744823457, 'context_length
': 200000, 'architecture': {'input_modalities': ['image', 'text', 'file'], 'outp
ut_modalities': ['text'], 'tokenizer': 'GPT', 'instruct_type': None}, 'pricing':
 {'prompt': '0.00017606', 'completion': '0.00070423', 'image': '0.13468345', 're
quest': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000
000', 'input_cache_read': '0.00004401', 'input_cache_write': '0.00000000'}, 'top
_provider': {'context_length': 200000, 'max_completion_tokens': 100000, 'is_mode
rated': True}, 'per_request_limits': None, 'supported_parameters': ['include_rea
soning', 'max_tokens', 'reasoning', 'response_format', 'seed', 'structured_outpu
ts', 'tool_choice', 'tools']}, {'id': 'openai/o4-mini', 'canonical_slug': 'opena
i/o4-mini-2025-04-16', 'name': 'OpenAI: o4 Mini', 'created': 1744820942, 'contex
t_length': 200000, 'architecture': {'input_modalities': ['image', 'text'], 'outp
ut_modalities': ['text'], 'tokenizer': 'Other', 'instruct_type': None}, 'pricing
': {'prompt': '0.00009683', 'completion': '0.00038732', 'image': '0.07407590', '
request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.000
00000', 'input_cache_read': '0.00002421', 'input_cache_write': '0.00000000'}, 't
op_provider': {'context_length': 200000, 'max_completion_tokens': 100000, 'is_mo
derated': True}, 'per_request_limits': None, 'supported_parameters': ['include_r
easoning', 'max_tokens', 'reasoning', 'response_format', 'seed', 'structured_out
puts', 'tool_choice', 'tools']}, {'id': 'shisa-ai/shisa-v2-llama3.3-70b', 'canon
ical_slug': 'shisa-ai/shisa-v2-llama3.3-70b', 'name': 'Shisa AI: Shisa V2 Llama
3.3 70B ', 'created': 1744754858, 'context_length': 32768, 'architecture': {'inp
ut_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Llama3',
'instruct_type': None}, 'pricing': {'prompt': '0.00000176', 'completion': '0.000
00704', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.0000000
0', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input
_cache_write': '0.00000000'}, 'top_provider': {'context_length': 32768, 'max_com
pletion_tokens': 0, 'is_moderated': False}, 'per_request_limits': None, 'support
ed_parameters': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'm
in_p', 'presence_penalty', 'repetition_penalty', 'seed', 'stop', 'temperature',
'top_k', 'top_logprobs', 'top_p']}, {'id': 'openai/gpt-4.1', 'canonical_slug': '
openai/gpt-4.1-2025-04-14', 'name': 'OpenAI: GPT-4.1', 'created': 1744651385, 'c
ontext_length': 1047576, 'architecture': {'input_modalities': ['image', 'text',
'file'], 'output_modalities': ['text'], 'tokenizer': 'GPT', 'instruct_type': Non
e}, 'pricing': {'prompt': '0.00017606', 'completion': '0.00070423', 'image': '0.
00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reason
ing': '0.00000000', 'input_cache_read': '0.00004401', 'input_cache_write': '0.00
000000'}, 'top_provider': {'context_length': 1047576, 'max_completion_tokens': 3
2768, 'is_moderated': True}, 'per_request_limits': None, 'supported_parameters':
 ['frequency_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'presence_penalty
', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperature', 'tool
_choice', 'tools', 'top_logprobs', 'top_p', 'web_search_options']}, {'id': 'open
ai/gpt-4.1-mini', 'canonical_slug': 'openai/gpt-4.1-mini-2025-04-14', 'name': 'O
penAI: GPT-4.1 Mini', 'created': 1744651381, 'context_length': 1047576, 'archite
cture': {'input_modalities': ['image', 'text', 'file'], 'output_modalities': ['t
ext'], 'tokenizer': 'GPT', 'instruct_type': None}, 'pricing': {'prompt': '0.0000
3521', 'completion': '0.00014085', 'image': '0.00000000', 'request': '0.00000000
', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_
read': '0.00000880', 'input_cache_write': '0.00000000'}, 'top_provider': {'conte
xt_length': 1047576, 'max_completion_tokens': 32768, 'is_moderated': True}, 'per
_request_limits': None, 'supported_parameters': ['frequency_penalty', 'logit_bia
s', 'logprobs', 'max_tokens', 'presence_penalty', 'response_format', 'seed', 'st
op', 'structured_outputs', 'temperature', 'tool_choice', 'tools', 'top_logprobs'
, 'top_p', 'web_search_options']}, {'id': 'openai/gpt-4.1-nano', 'canonical_slug
': 'openai/gpt-4.1-nano-2025-04-14', 'name': 'OpenAI: GPT-4.1 Nano', 'created':
1744651369, 'context_length': 1047576, 'architecture': {'input_modalities': ['im
age', 'text', 'file'], 'output_modalities': ['text'], 'tokenizer': 'GPT', 'instr
uct_type': None}, 'pricing': {'prompt': '0.00000880', 'completion': '0.00003521'
, 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'i
nternal_reasoning': '0.00000000', 'input_cache_read': '0.00000220', 'input_cache
_write': '0.00000000'}, 'top_provider': {'context_length': 1047576, 'max_complet
ion_tokens': 32768, 'is_moderated': True}, 'per_request_limits': None, 'supporte
d_parameters': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'pr
esence_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'tempe
rature', 'tool_choice', 'tools', 'top_logprobs', 'top_p']}, {'id': 'eleutherai/l
lemma_7b', 'canonical_slug': 'eleutherai/llemma_7b', 'name': 'EleutherAI: Llemma
 7b', 'created': 1744643225, 'context_length': 4096, 'architecture': {'input_mod
alities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Other', 'instru
ct_type': 'code-llama'}, 'pricing': {'prompt': '0.00007042', 'completion': '0.00
010563', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.000000
00', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'inpu
t_cache_write': '0.00000000'}, 'top_provider': {'context_length': 4096, 'max_com
pletion_tokens': 4096, 'is_moderated': False}, 'per_request_limits': None, 'supp
orted_parameters': ['frequency_penalty', 'max_tokens', 'min_p', 'presence_penalt
y', 'repetition_penalty', 'seed', 'stop', 'temperature', 'top_k', 'top_p']}, {'i
d': 'alfredpros/codellama-7b-instruct-solidity', 'canonical_slug': 'alfredpros/c
odellama-7b-instruct-solidity', 'name': 'AlfredPros: CodeLLaMa 7B Instruct Solid
ity', 'created': 1744641874, 'context_length': 8192, 'architecture': {'input_mod
alities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Other', 'instru
ct_type': 'alpaca'}, 'pricing': {'prompt': '0.00006162', 'completion': '0.000096
83', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000',
 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_ca
che_write': '0.00000000'}, 'top_provider': {'context_length': 8192, 'max_complet
ion_tokens': 8192, 'is_moderated': False}, 'per_request_limits': None, 'supporte
d_parameters': ['frequency_penalty', 'max_tokens', 'min_p', 'presence_penalty',
'repetition_penalty', 'seed', 'stop', 'temperature', 'top_k', 'top_p']}, {'id':
'arliai/qwq-32b-arliai-rpr-v1', 'canonical_slug': 'arliai/qwq-32b-arliai-rpr-v1'
, 'name': 'ArliAI: QwQ 32B RpR v1', 'created': 1744555982, 'context_length': 327
68, 'architecture': {'input_modalities': ['text'], 'output_modalities': ['text']
, 'tokenizer': 'Other', 'instruct_type': 'deepseek-r1'}, 'pricing': {'prompt': '
0.00000088', 'completion': '0.00000352', 'image': '0.00000000', 'request': '0.00
000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_
cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {
'context_length': 32768, 'max_completion_tokens': 0, 'is_moderated': False}, 'pe
r_request_limits': None, 'supported_parameters': ['frequency_penalty', 'include_
reasoning', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty',
 'reasoning', 'repetition_penalty', 'seed', 'stop', 'temperature', 'top_k', 'top
_logprobs', 'top_p']}, {'id': 'agentica-org/deepcoder-14b-preview', 'canonical_s
lug': 'agentica-org/deepcoder-14b-preview', 'name': 'Agentica: Deepcoder 14B Pre
view', 'created': 1744555395, 'context_length': 96000, 'architecture': {'input_m
odalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Other', 'inst
ruct_type': 'deepseek-r1'}, 'pricing': {'prompt': '0.00000132', 'completion': '0
.00000132', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.000
00000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'i
nput_cache_write': '0.00000000'}, 'top_provider': {'context_length': 96000, 'max
_completion_tokens': 0, 'is_moderated': False}, 'per_request_limits': None, 'sup
ported_parameters': ['frequency_penalty', 'include_reasoning', 'logit_bias', 'lo
gprobs', 'max_tokens', 'min_p', 'presence_penalty', 'reasoning', 'repetition_pen
alty', 'seed', 'stop', 'temperature', 'top_k', 'top_logprobs', 'top_p']}, {'id':
 'moonshotai/kimi-vl-a3b-thinking', 'canonical_slug': 'moonshotai/kimi-vl-a3b-th
inking', 'name': 'MoonshotAI: Kimi VL A3B Thinking', 'created': 1744304841, 'con
text_length': 131072, 'architecture': {'input_modalities': ['image', 'text'], 'o
utput_modalities': ['text'], 'tokenizer': 'Other', 'instruct_type': None}, 'pric
ing': {'prompt': '0.00000220', 'completion': '0.00000880', 'image': '0.00000000'
, 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.
00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'},
 'top_provider': {'context_length': 131072, 'max_completion_tokens': 0, 'is_mode
rated': False}, 'per_request_limits': None, 'supported_parameters': ['frequency_
penalty', 'include_reasoning', 'logit_bias', 'logprobs', 'max_tokens', 'min_p',
'presence_penalty', 'reasoning', 'repetition_penalty', 'seed', 'stop', 'temperat
ure', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'x-ai/grok-3-mini-beta', 'canon
ical_slug': 'x-ai/grok-3-mini-beta', 'name': 'xAI: Grok 3 Mini Beta', 'created':
 1744240195, 'context_length': 131072, 'architecture': {'input_modalities': ['te
xt'], 'output_modalities': ['text'], 'tokenizer': 'Grok', 'instruct_type': None}
, 'pricing': {'prompt': '0.00002641', 'completion': '0.00004401', 'image': '0.00
000000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasonin
g': '0.00000000', 'input_cache_read': '0.00000660', 'input_cache_write': '0.0000
0000'}, 'top_provider': {'context_length': 131072, 'max_completion_tokens': 0, '
is_moderated': False}, 'per_request_limits': None, 'supported_parameters': ['inc
lude_reasoning', 'logprobs', 'max_tokens', 'reasoning', 'response_format', 'seed
', 'stop', 'temperature', 'tool_choice', 'tools', 'top_logprobs', 'top_p']}, {'i
d': 'x-ai/grok-3-beta', 'canonical_slug': 'x-ai/grok-3-beta', 'name': 'xAI: Grok
 3 Beta', 'created': 1744240068, 'context_length': 131072, 'architecture': {'inp
ut_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Grok', 'i
nstruct_type': None}, 'pricing': {'prompt': '0.00026409', 'completion': '0.00132
043', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000'
, 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00006602', 'input_c
ache_write': '0.00000000'}, 'top_provider': {'context_length': 131072, 'max_comp
letion_tokens': 0, 'is_moderated': False}, 'per_request_limits': None, 'supporte
d_parameters': ['frequency_penalty', 'logprobs', 'max_tokens', 'presence_penalty
', 'response_format', 'seed', 'stop', 'temperature', 'tool_choice', 'tools', 'to
p_logprobs', 'top_p']}, {'id': 'nvidia/llama-3.3-nemotron-super-49b-v1', 'canoni
cal_slug': 'nvidia/llama-3.3-nemotron-super-49b-v1', 'name': 'NVIDIA: Llama 3.3
Nemotron Super 49B v1', 'created': 1744119494, 'context_length': 131072, 'archit
ecture': {'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenize
r': 'Other', 'instruct_type': None}, 'pricing': {'prompt': '0.00001144', 'comple
tion': '0.00003521', 'image': '0.00000000', 'request': '0.00000000', 'web_search
': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.0000
0000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 13
1072, 'max_completion_tokens': 0, 'is_moderated': False}, 'per_request_limits':
None, 'supported_parameters': ['frequency_penalty', 'logit_bias', 'logprobs', 'm
ax_tokens', 'presence_penalty', 'seed', 'stop', 'temperature', 'top_k', 'top_log
probs', 'top_p']}, {'id': 'nvidia/llama-3.1-nemotron-ultra-253b-v1', 'canonical_
slug': 'nvidia/llama-3.1-nemotron-ultra-253b-v1', 'name': 'NVIDIA: Llama 3.1 Nem
otron Ultra 253B v1', 'created': 1744115059, 'context_length': 131072, 'architec
ture': {'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer'
: 'Llama3', 'instruct_type': None}, 'pricing': {'prompt': '0.00005282', 'complet
ion': '0.00015845', 'image': '0.00000000', 'request': '0.00000000', 'web_search'
: '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000
000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 131
072, 'max_completion_tokens': 0, 'is_moderated': False}, 'per_request_limits': N
one, 'supported_parameters': ['frequency_penalty', 'include_reasoning', 'logit_b
ias', 'logprobs', 'max_tokens', 'presence_penalty', 'reasoning', 'seed', 'stop',
 'temperature', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'meta-llama/llama-4-m
averick', 'canonical_slug': 'meta-llama/llama-4-maverick-17b-128e-instruct', 'na
me': 'Meta: Llama 4 Maverick', 'created': 1743881822, 'context_length': 1048576,
 'architecture': {'input_modalities': ['text', 'image'], 'output_modalities': ['
text'], 'tokenizer': 'Llama4', 'instruct_type': None}, 'pricing': {'prompt': '0.
00001320', 'completion': '0.00005282', 'image': '0.05883818', 'request': '0.0000
0000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_ca
che_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'c
ontext_length': 1048576, 'max_completion_tokens': 16384, 'is_moderated': False},
 'per_request_limits': None, 'supported_parameters': ['frequency_penalty', 'logi
t_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_pena
lty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperature', 't
ool_choice', 'tools', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'meta-llama/lla
ma-4-scout', 'canonical_slug': 'meta-llama/llama-4-scout-17b-16e-instruct', 'nam
e': 'Meta: Llama 4 Scout', 'created': 1743881519, 'context_length': 1048576, 'ar
chitecture': {'input_modalities': ['text', 'image'], 'output_modalities': ['text
'], 'tokenizer': 'Llama4', 'instruct_type': None}, 'pricing': {'prompt': '0.0000
0704', 'completion': '0.00002641', 'image': '0.00000000', 'request': '0.00000000
', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_
read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'conte
xt_length': 1048576, 'max_completion_tokens': 1048576, 'is_moderated': False}, '
per_request_limits': None, 'supported_parameters': ['frequency_penalty', 'logit_
bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_penalt
y', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperature', 'too
l_choice', 'tools', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'scb10x/llama3.1-
typhoon2-70b-instruct', 'canonical_slug': 'scb10x/llama3.1-typhoon2-70b-instruct
', 'name': 'Typhoon2 70B Instruct', 'created': 1743196170, 'context_length': 819
2, 'architecture': {'input_modalities': ['text'], 'output_modalities': ['text'],
 'tokenizer': 'Llama3', 'instruct_type': 'llama3'}, 'pricing': {'prompt': '0.000
07746', 'completion': '0.00007746', 'image': '0.00000000', 'request': '0.0000000
0', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache
_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'cont
ext_length': 8192, 'max_completion_tokens': 0, 'is_moderated': False}, 'per_requ
est_limits': None, 'supported_parameters': ['frequency_penalty', 'logit_bias', '
max_tokens', 'min_p', 'presence_penalty', 'repetition_penalty', 'stop', 'tempera
ture', 'top_k', 'top_p']}, {'id': 'google/gemini-2.5-pro-exp-03-25', 'canonical_
slug': 'google/gemini-2.5-pro-exp-03-25', 'name': 'Google: Gemini 2.5 Pro Experi
mental', 'created': 1742922099, 'context_length': 1048576, 'architecture': {'inp
ut_modalities': ['text', 'image', 'file'], 'output_modalities': ['text'], 'token
izer': 'Gemini', 'instruct_type': None}, 'pricing': {'prompt': '0.00000000', 'co
mpletion': '0.00000000', 'image': '0.00000000', 'request': '0.00000000', 'web_se
arch': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.
00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length'
: 1048576, 'max_completion_tokens': 65535, 'is_moderated': False}, 'per_request_
limits': None, 'supported_parameters': ['max_tokens', 'response_format', 'seed',
 'stop', 'structured_outputs', 'temperature', 'tool_choice', 'tools', 'top_p']},
 {'id': 'qwen/qwen2.5-vl-32b-instruct', 'canonical_slug': 'qwen/qwen2.5-vl-32b-i
nstruct', 'name': 'Qwen: Qwen2.5 VL 32B Instruct', 'created': 1742839838, 'conte
xt_length': 16384, 'architecture': {'input_modalities': ['text', 'image'], 'outp
ut_modalities': ['text'], 'tokenizer': 'Qwen', 'instruct_type': None}, 'pricing'
: {'prompt': '0.00000176', 'completion': '0.00000704', 'image': '0.00000000', 'r
equest': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.0000
0000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'to
p_provider': {'context_length': 16384, 'max_completion_tokens': 0, 'is_moderated
': False}, 'per_request_limits': None, 'supported_parameters': ['frequency_penal
ty', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'repet
ition_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temper
ature', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'deepseek/deepseek-chat-v3-03
24', 'canonical_slug': 'deepseek/deepseek-chat-v3-0324', 'name': 'DeepSeek: Deep
Seek V3 0324', 'created': 1742824755, 'context_length': 163840, 'architecture':
{'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Deep
Seek', 'instruct_type': None}, 'pricing': {'prompt': '0.00001760', 'completion':
 '0.00007043', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.
00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000',
 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 163840,
'max_completion_tokens': 0, 'is_moderated': False}, 'per_request_limits': None,
'supported_parameters': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_tok
ens', 'min_p', 'presence_penalty', 'repetition_penalty', 'response_format', 'see
d', 'stop', 'structured_outputs', 'temperature', 'tool_choice', 'tools', 'top_k'
, 'top_logprobs', 'top_p']}, {'id': 'openai/o1-pro', 'canonical_slug': 'openai/o
1-pro', 'name': 'OpenAI: o1-pro', 'created': 1742423211, 'context_length': 20000
0, 'architecture': {'input_modalities': ['text', 'image'], 'output_modalities':
['text'], 'tokenizer': 'GPT', 'instruct_type': None}, 'pricing': {'prompt': '0.0
1320426', 'completion': '0.05281704', 'image': '19.08015570', 'request': '0.0000
0000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_ca
che_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'c
ontext_length': 200000, 'max_completion_tokens': 100000, 'is_moderated': True},
'per_request_limits': None, 'supported_parameters': ['include_reasoning', 'max_t
okens', 'reasoning', 'response_format', 'seed', 'structured_outputs']}, {'id': '
mistralai/mistral-small-3.1-24b-instruct', 'canonical_slug': 'mistralai/mistral-
small-3.1-24b-instruct-2503', 'name': 'Mistral: Mistral Small 3.1 24B', 'created
': 1742238937, 'context_length': 131072, 'architecture': {'input_modalities': ['
text', 'image'], 'output_modalities': ['text'], 'tokenizer': 'Mistral', 'instruc
t_type': None}, 'pricing': {'prompt': '0.00000176', 'completion': '0.00000704',
'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'int
ernal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_w
rite': '0.00000000'}, 'top_provider': {'context_length': 131072, 'max_completion
_tokens': 96000, 'is_moderated': False}, 'per_request_limits': None, 'supported_
parameters': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'min_
p', 'presence_penalty', 'repetition_penalty', 'response_format', 'seed', 'stop',
 'structured_outputs', 'temperature', 'tool_choice', 'tools', 'top_k', 'top_logp
robs', 'top_p']}, {'id': 'google/gemma-3-4b-it', 'canonical_slug': 'google/gemma
-3-4b-it', 'name': 'Google: Gemma 3 4B', 'created': 1741905510, 'context_length'
: 131072, 'architecture': {'input_modalities': ['text', 'image'], 'output_modali
ties': ['text'], 'tokenizer': 'Gemini', 'instruct_type': 'gemma'}, 'pricing': {'
prompt': '0.00000176', 'completion': '0.00000352', 'image': '0.00000000', 'reque
st': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000
', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_pr
ovider': {'context_length': 131072, 'max_completion_tokens': 0, 'is_moderated':
False}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty'
, 'max_tokens', 'min_p', 'presence_penalty', 'repetition_penalty', 'response_for
mat', 'seed', 'stop', 'temperature', 'top_k', 'top_p']}, {'id': 'google/gemma-3-
12b-it', 'canonical_slug': 'google/gemma-3-12b-it', 'name': 'Google: Gemma 3 12B
', 'created': 1741902625, 'context_length': 96000, 'architecture': {'input_modal
ities': ['text', 'image'], 'output_modalities': ['text'], 'tokenizer': 'Gemini',
 'instruct_type': 'gemma'}, 'pricing': {'prompt': '0.00000424', 'completion': '0
.00001695', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.000
00000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'i
nput_cache_write': '0.00000000'}, 'top_provider': {'context_length': 96000, 'max
_completion_tokens': 8192, 'is_moderated': False}, 'per_request_limits': None, '
supported_parameters': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_toke
ns', 'min_p', 'presence_penalty', 'repetition_penalty', 'response_format', 'seed
', 'stop', 'temperature', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'cohere/com
mand-a', 'canonical_slug': 'cohere/command-a-03-2025', 'name': 'Cohere: Command
A', 'created': 1741894342, 'context_length': 32768, 'architecture': {'input_moda
lities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Other', 'instruc
t_type': None}, 'pricing': {'prompt': '0.00017606', 'completion': '0.00070423',
'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'int
ernal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_w
rite': '0.00000000'}, 'top_provider': {'context_length': 32768, 'max_completion_
tokens': 0, 'is_moderated': False}, 'per_request_limits': None, 'supported_param
eters': ['frequency_penalty', 'max_tokens', 'presence_penalty', 'response_format
', 'seed', 'stop', 'structured_outputs', 'temperature', 'top_k', 'top_p']}, {'id
': 'openai/gpt-4o-mini-search-preview', 'canonical_slug': 'openai/gpt-4o-mini-se
arch-preview-2025-03-11', 'name': 'OpenAI: GPT-4o-mini Search Preview', 'created
': 1741818122, 'context_length': 128000, 'architecture': {'input_modalities': ['
text'], 'output_modalities': ['text'], 'tokenizer': 'GPT', 'instruct_type': None
}, 'pricing': {'prompt': '0.00001320', 'completion': '0.00005282', 'image': '0.0
1910216', 'request': '2.42078100', 'web_search': '0.00000000', 'internal_reasoni
ng': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.000
00000'}, 'top_provider': {'context_length': 128000, 'max_completion_tokens': 163
84, 'is_moderated': True}, 'per_request_limits': None, 'supported_parameters': [
'max_tokens', 'response_format', 'structured_outputs', 'web_search_options']}, {
'id': 'openai/gpt-4o-search-preview', 'canonical_slug': 'openai/gpt-4o-search-pr
eview-2025-03-11', 'name': 'OpenAI: GPT-4o Search Preview', 'created': 174181794
9, 'context_length': 128000, 'architecture': {'input_modalities': ['text'], 'out
put_modalities': ['text'], 'tokenizer': 'GPT', 'instruct_type': None}, 'pricing'
: {'prompt': '0.00022007', 'completion': '0.00088028', 'image': '0.31804661', 'r
equest': '3.08099400', 'web_search': '0.00000000', 'internal_reasoning': '0.0000
0000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'to
p_provider': {'context_length': 128000, 'max_completion_tokens': 16384, 'is_mode
rated': True}, 'per_request_limits': None, 'supported_parameters': ['max_tokens'
, 'response_format', 'structured_outputs', 'web_search_options']}, {'id': 'googl
e/gemma-3-27b-it', 'canonical_slug': 'google/gemma-3-27b-it', 'name': 'Google: G
emma 3 27B', 'created': 1741756359, 'context_length': 96000, 'architecture': {'i
nput_modalities': ['text', 'image'], 'output_modalities': ['text'], 'tokenizer':
 'Gemini', 'instruct_type': 'gemma'}, 'pricing': {'prompt': '0.00000587', 'compl
etion': '0.00002348', 'image': '0.00000000', 'request': '0.00000000', 'web_searc
h': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.000
00000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 9
6000, 'max_completion_tokens': 8192, 'is_moderated': False}, 'per_request_limits
': None, 'supported_parameters': ['frequency_penalty', 'logit_bias', 'logprobs',
 'max_tokens', 'min_p', 'presence_penalty', 'repetition_penalty', 'response_form
at', 'seed', 'stop', 'structured_outputs', 'temperature', 'top_k', 'top_logprobs
', 'top_p']}, {'id': 'thedrummer/anubis-pro-105b-v1', 'canonical_slug': 'thedrum
mer/anubis-pro-105b-v1', 'name': 'TheDrummer: Anubis Pro 105B V1', 'created': 17
41642290, 'context_length': 131072, 'architecture': {'input_modalities': ['text'
], 'output_modalities': ['text'], 'tokenizer': 'Other', 'instruct_type': None},
'pricing': {'prompt': '0.00004401', 'completion': '0.00008803', 'image': '0.0000
0000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning'
: '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.000000
00'}, 'top_provider': {'context_length': 131072, 'max_completion_tokens': 131072
, 'is_moderated': False}, 'per_request_limits': None, 'supported_parameters': ['
frequency_penalty', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_penal
ty', 'seed', 'stop', 'temperature', 'top_k', 'top_p']}, {'id': 'thedrummer/skyfa
ll-36b-v2', 'canonical_slug': 'thedrummer/skyfall-36b-v2', 'name': 'TheDrummer:
Skyfall 36B V2', 'created': 1741636566, 'context_length': 32768, 'architecture':
 {'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Oth
er', 'instruct_type': None}, 'pricing': {'prompt': '0.00000424', 'completion': '
0.00001695', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00
000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', '
input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 32768, 'ma
x_completion_tokens': 0, 'is_moderated': False}, 'per_request_limits': None, 'su
pported_parameters': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_tokens
', 'min_p', 'presence_penalty', 'repetition_penalty', 'response_format', 'seed',
 'stop', 'structured_outputs', 'temperature', 'top_k', 'top_logprobs', 'top_p']}
, {'id': 'microsoft/phi-4-multimodal-instruct', 'canonical_slug': 'microsoft/phi
-4-multimodal-instruct', 'name': 'Microsoft: Phi 4 Multimodal Instruct', 'create
d': 1741396284, 'context_length': 131072, 'architecture': {'input_modalities': [
'text', 'image'], 'output_modalities': ['text'], 'tokenizer': 'Other', 'instruct
_type': None}, 'pricing': {'prompt': '0.00000440', 'completion': '0.00000880', '
image': '0.01556782', 'request': '0.00000000', 'web_search': '0.00000000', 'inte
rnal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_wr
ite': '0.00000000'}, 'top_provider': {'context_length': 131072, 'max_completion_
tokens': 0, 'is_moderated': False}, 'per_request_limits': None, 'supported_param
eters': ['frequency_penalty', 'max_tokens', 'min_p', 'presence_penalty', 'repeti
tion_penalty', 'response_format', 'seed', 'stop', 'temperature', 'top_k', 'top_p
']}, {'id': 'perplexity/sonar-reasoning-pro', 'canonical_slug': 'perplexity/sona
r-reasoning-pro', 'name': 'Perplexity: Sonar Reasoning Pro', 'created': 17413133
08, 'context_length': 128000, 'architecture': {'input_modalities': ['text', 'ima
ge'], 'output_modalities': ['text'], 'tokenizer': 'Other', 'instruct_type': 'dee
pseek-r1'}, 'pricing': {'prompt': '0.00017606', 'completion': '0.00070423', 'ima
ge': '0.00000000', 'request': '0.00000000', 'web_search': '0.44014200', 'interna
l_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write
': '0.00000000'}, 'top_provider': {'context_length': 128000, 'max_completion_tok
ens': 0, 'is_moderated': False}, 'per_request_limits': None, 'supported_paramete
rs': ['frequency_penalty', 'include_reasoning', 'max_tokens', 'presence_penalty'
, 'reasoning', 'temperature', 'top_k', 'top_p', 'web_search_options']}, {'id': '
perplexity/sonar-pro', 'canonical_slug': 'perplexity/sonar-pro', 'name': 'Perple
xity: Sonar Pro', 'created': 1741312423, 'context_length': 200000, 'architecture
': {'input_modalities': ['text', 'image'], 'output_modalities': ['text'], 'token
izer': 'Other', 'instruct_type': None}, 'pricing': {'prompt': '0.00026409', 'com
pletion': '0.00132043', 'image': '0.00000000', 'request': '0.00000000', 'web_sea
rch': '0.44014200', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.0
0000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length':
 200000, 'max_completion_tokens': 8000, 'is_moderated': False}, 'per_request_lim
its': None, 'supported_parameters': ['frequency_penalty', 'max_tokens', 'presenc
e_penalty', 'temperature', 'top_k', 'top_p', 'web_search_options']}, {'id': 'per
plexity/sonar-deep-research', 'canonical_slug': 'perplexity/sonar-deep-research'
, 'name': 'Perplexity: Sonar Deep Research', 'created': 1741311246, 'context_len
gth': 128000, 'architecture': {'input_modalities': ['text'], 'output_modalities'
: ['text'], 'tokenizer': 'Other', 'instruct_type': 'deepseek-r1'}, 'pricing': {'
prompt': '0.00017606', 'completion': '0.00070423', 'image': '0.00000000', 'reque
st': '0.00000000', 'web_search': '0.44014200', 'internal_reasoning': '0.00026409
', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_pr
ovider': {'context_length': 128000, 'max_completion_tokens': 0, 'is_moderated':
False}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty'
, 'include_reasoning', 'max_tokens', 'presence_penalty', 'reasoning', 'temperatu
re', 'top_k', 'top_p', 'web_search_options']}, {'id': 'qwen/qwq-32b', 'canonical
_slug': 'qwen/qwq-32b', 'name': 'Qwen: QwQ 32B', 'created': 1741208814, 'context
_length': 131072, 'architecture': {'input_modalities': ['text'], 'output_modalit
ies': ['text'], 'tokenizer': 'Qwen', 'instruct_type': 'qwq'}, 'pricing': {'promp
t': '0.00000660', 'completion': '0.00001320', 'image': '0.00000000', 'request':
'0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'i
nput_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provide
r': {'context_length': 131072, 'max_completion_tokens': 0, 'is_moderated': False
}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty', 'in
clude_reasoning', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_pen
alty', 'reasoning', 'repetition_penalty', 'response_format', 'seed', 'stop', 'st
ructured_outputs', 'temperature', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'go
ogle/gemini-2.0-flash-lite-001', 'canonical_slug': 'google/gemini-2.0-flash-lite
-001', 'name': 'Google: Gemini 2.0 Flash Lite', 'created': 1740506212, 'context_
length': 1048576, 'architecture': {'input_modalities': ['text', 'image', 'file',
 'audio'], 'output_modalities': ['text'], 'tokenizer': 'Gemini', 'instruct_type'
: None}, 'pricing': {'prompt': '0.00000660', 'completion': '0.00002641', 'image'
: '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_r
easoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write':
'0.00000000'}, 'top_provider': {'context_length': 1048576, 'max_completion_token
s': 8192, 'is_moderated': False}, 'per_request_limits': None, 'supported_paramet
ers': ['max_tokens', 'response_format', 'seed', 'stop', 'structured_outputs', 't
emperature', 'tool_choice', 'tools', 'top_p']}, {'id': 'anthropic/claude-3.7-son
net', 'canonical_slug': 'anthropic/claude-3-7-sonnet-20250219', 'name': 'Anthrop
ic: Claude 3.7 Sonnet', 'created': 1740422110, 'context_length': 200000, 'archit
ecture': {'input_modalities': ['text', 'image', 'file'], 'output_modalities': ['
text'], 'tokenizer': 'Claude', 'instruct_type': None}, 'pricing': {'prompt': '0.
00026409', 'completion': '0.00132043', 'image': '0.42253632', 'request': '0.0000
0000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_ca
che_read': '0.00002641', 'input_cache_write': '0.00033011'}, 'top_provider': {'c
ontext_length': 200000, 'max_completion_tokens': 64000, 'is_moderated': False},
'per_request_limits': None, 'supported_parameters': ['include_reasoning', 'max_t
okens', 'reasoning', 'stop', 'temperature', 'tool_choice', 'tools', 'top_k', 'to
p_p']}, {'id': 'anthropic/claude-3.7-sonnet:thinking', 'canonical_slug': 'anthro
pic/claude-3-7-sonnet-20250219', 'name': 'Anthropic: Claude 3.7 Sonnet (thinking
)', 'created': 1740422110, 'context_length': 200000, 'architecture': {'input_mod
alities': ['text', 'image', 'file'], 'output_modalities': ['text'], 'tokenizer':
 'Claude', 'instruct_type': None}, 'pricing': {'prompt': '0.00026409', 'completi
on': '0.00132043', 'image': '0.42253632', 'request': '0.00000000', 'web_search':
 '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.000026
41', 'input_cache_write': '0.00033011'}, 'top_provider': {'context_length': 2000
00, 'max_completion_tokens': 64000, 'is_moderated': False}, 'per_request_limits'
: None, 'supported_parameters': ['include_reasoning', 'max_tokens', 'reasoning',
 'stop', 'temperature', 'tool_choice', 'tools']}, {'id': 'perplexity/r1-1776', '
canonical_slug': 'perplexity/r1-1776', 'name': 'Perplexity: R1 1776', 'created':
 1740004929, 'context_length': 128000, 'architecture': {'input_modalities': ['te
xt'], 'output_modalities': ['text'], 'tokenizer': 'DeepSeek', 'instruct_type': '
deepseek-r1'}, 'pricing': {'prompt': '0.00017606', 'completion': '0.00070423', '
image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'inte
rnal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_wr
ite': '0.00000000'}, 'top_provider': {'context_length': 128000, 'max_completion_
tokens': 0, 'is_moderated': False}, 'per_request_limits': None, 'supported_param
eters': ['frequency_penalty', 'include_reasoning', 'max_tokens', 'presence_penal
ty', 'reasoning', 'temperature', 'top_k', 'top_p']}, {'id': 'mistralai/mistral-s
aba', 'canonical_slug': 'mistralai/mistral-saba-2502', 'name': 'Mistral: Saba',
'created': 1739803239, 'context_length': 32768, 'architecture': {'input_modaliti
es': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Mistral', 'instruct_
type': None}, 'pricing': {'prompt': '0.00001761', 'completion': '0.00005282', 'i
mage': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'inter
nal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_wri
te': '0.00000000'}, 'top_provider': {'context_length': 32768, 'max_completion_to
kens': 0, 'is_moderated': False}, 'per_request_limits': None, 'supported_paramet
ers': ['frequency_penalty', 'max_tokens', 'presence_penalty', 'response_format',
 'seed', 'stop', 'structured_outputs', 'temperature', 'tool_choice', 'tools', 't
op_p']}, {'id': 'cognitivecomputations/dolphin3.0-r1-mistral-24b', 'canonical_sl
ug': 'cognitivecomputations/dolphin3.0-r1-mistral-24b', 'name': 'Dolphin3.0 R1 M
istral 24B', 'created': 1739462498, 'context_length': 32768, 'architecture': {'i
nput_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Other',
 'instruct_type': 'deepseek-r1'}, 'pricing': {'prompt': '0.00000088', 'completio
n': '0.00000300', 'image': '0.00000000', 'request': '0.00000000', 'web_search':
'0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.0000000
0', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 32768
, 'max_completion_tokens': 0, 'is_moderated': False}, 'per_request_limits': None
, 'supported_parameters': ['frequency_penalty', 'include_reasoning', 'logit_bias
', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'reasoning', 'repetiti
on_penalty', 'seed', 'stop', 'temperature', 'top_k', 'top_logprobs', 'top_p']},
{'id': 'cognitivecomputations/dolphin3.0-mistral-24b', 'canonical_slug': 'cognit
ivecomputations/dolphin3.0-mistral-24b', 'name': 'Dolphin3.0 Mistral 24B', 'crea
ted': 1739462019, 'context_length': 32768, 'architecture': {'input_modalities':
['text'], 'output_modalities': ['text'], 'tokenizer': 'Other', 'instruct_type':
None}, 'pricing': {'prompt': '0.00000326', 'completion': '0.00001304', 'image':
'0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_rea
soning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0
.00000000'}, 'top_provider': {'context_length': 32768, 'max_completion_tokens':
0, 'is_moderated': False}, 'per_request_limits': None, 'supported_parameters': [
'frequency_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_
penalty', 'repetition_penalty', 'seed', 'stop', 'temperature', 'top_k', 'top_log
probs', 'top_p']}, {'id': 'meta-llama/llama-guard-3-8b', 'canonical_slug': 'meta
-llama/llama-guard-3-8b', 'name': 'Llama Guard 3 8B', 'created': 1739401318, 'co
ntext_length': 131072, 'architecture': {'input_modalities': ['text'], 'output_mo
dalities': ['text'], 'tokenizer': 'Llama3', 'instruct_type': 'none'}, 'pricing':
 {'prompt': '0.00000176', 'completion': '0.00000528', 'image': '0.00000000', 're
quest': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000
000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top
_provider': {'context_length': 131072, 'max_completion_tokens': 0, 'is_moderated
': False}, 'per_request_limits': None, 'supported_parameters': ['frequency_penal
ty', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'repet
ition_penalty', 'response_format', 'seed', 'stop', 'temperature', 'top_k', 'top_
logprobs', 'top_p']}, {'id': 'openai/o3-mini-high', 'canonical_slug': 'openai/o3
-mini-high-2025-01-31', 'name': 'OpenAI: o3 Mini High', 'created': 1739372611, '
context_length': 200000, 'architecture': {'input_modalities': ['text'], 'output_
modalities': ['text'], 'tokenizer': 'Other', 'instruct_type': None}, 'pricing':
{'prompt': '0.00009683', 'completion': '0.00038732', 'image': '0.00000000', 'req
uest': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.000000
00', 'input_cache_read': '0.00004842', 'input_cache_write': '0.00000000'}, 'top_
provider': {'context_length': 200000, 'max_completion_tokens': 100000, 'is_moder
ated': True}, 'per_request_limits': None, 'supported_parameters': ['max_tokens',
 'response_format', 'seed', 'structured_outputs', 'tool_choice', 'tools']}, {'id
': 'deepseek/deepseek-r1-distill-llama-8b', 'canonical_slug': 'deepseek/deepseek
-r1-distill-llama-8b', 'name': 'DeepSeek: R1 Distill Llama 8B', 'created': 17389
37718, 'context_length': 32000, 'architecture': {'input_modalities': ['text'], '
output_modalities': ['text'], 'tokenizer': 'Llama3', 'instruct_type': 'deepseek-
r1'}, 'pricing': {'prompt': '0.00000352', 'completion': '0.00000352', 'image': '
0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reas
oning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.
00000000'}, 'top_provider': {'context_length': 32000, 'max_completion_tokens': 3
2000, 'is_moderated': False}, 'per_request_limits': None, 'supported_parameters'
: ['frequency_penalty', 'include_reasoning', 'logit_bias', 'max_tokens', 'min_p'
, 'presence_penalty', 'reasoning', 'repetition_penalty', 'seed', 'stop', 'temper
ature', 'top_k', 'top_p']}, {'id': 'google/gemini-2.0-flash-001', 'canonical_slu
g': 'google/gemini-2.0-flash-001', 'name': 'Google: Gemini 2.0 Flash', 'created'
: 1738769413, 'context_length': 1048576, 'architecture': {'input_modalities': ['
text', 'image', 'file', 'audio'], 'output_modalities': ['text'], 'tokenizer': 'G
emini', 'instruct_type': None}, 'pricing': {'prompt': '0.00000880', 'completion'
: '0.00003521', 'image': '0.00227113', 'request': '0.00000000', 'web_search': '0
.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000220'
, 'input_cache_write': '0.00001614'}, 'top_provider': {'context_length': 1048576
, 'max_completion_tokens': 8192, 'is_moderated': False}, 'per_request_limits': N
one, 'supported_parameters': ['max_tokens', 'response_format', 'seed', 'stop', '
structured_outputs', 'temperature', 'tool_choice', 'tools', 'top_p']}, {'id': 'q
wen/qwen-vl-plus', 'canonical_slug': 'qwen/qwen-vl-plus', 'name': 'Qwen: Qwen VL
 Plus', 'created': 1738731255, 'context_length': 7500, 'architecture': {'input_m
odalities': ['text', 'image'], 'output_modalities': ['text'], 'tokenizer': 'Qwen
', 'instruct_type': None}, 'pricing': {'prompt': '0.00001849', 'completion': '0.
00005546', 'image': '0.02366203', 'request': '0.00000000', 'web_search': '0.0000
0000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'in
put_cache_write': '0.00000000'}, 'top_provider': {'context_length': 7500, 'max_c
ompletion_tokens': 1500, 'is_moderated': False}, 'per_request_limits': None, 'su
pported_parameters': ['max_tokens', 'presence_penalty', 'response_format', 'seed
', 'temperature', 'top_p']}, {'id': 'aion-labs/aion-1.0', 'canonical_slug': 'aio
n-labs/aion-1.0', 'name': 'AionLabs: Aion-1.0', 'created': 1738697557, 'context_
length': 131072, 'architecture': {'input_modalities': ['text'], 'output_modaliti
es': ['text'], 'tokenizer': 'Other', 'instruct_type': None}, 'pricing': {'prompt
': '0.00035211', 'completion': '0.00070423', 'image': '0.00000000', 'request': '
0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'in
put_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider
': {'context_length': 131072, 'max_completion_tokens': 32768, 'is_moderated': Fa
lse}, 'per_request_limits': None, 'supported_parameters': ['include_reasoning',
'max_tokens', 'reasoning', 'temperature', 'top_p']}, {'id': 'aion-labs/aion-1.0-
mini', 'canonical_slug': 'aion-labs/aion-1.0-mini', 'name': 'AionLabs: Aion-1.0-
Mini', 'created': 1738697107, 'context_length': 131072, 'architecture': {'input_
modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Other', 'ins
truct_type': None}, 'pricing': {'prompt': '0.00006162', 'completion': '0.0001232
4', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000',
'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cac
he_write': '0.00000000'}, 'top_provider': {'context_length': 131072, 'max_comple
tion_tokens': 32768, 'is_moderated': False}, 'per_request_limits': None, 'suppor
ted_parameters': ['include_reasoning', 'max_tokens', 'reasoning', 'temperature',
 'top_p']}, {'id': 'aion-labs/aion-rp-llama-3.1-8b', 'canonical_slug': 'aion-lab
s/aion-rp-llama-3.1-8b', 'name': 'AionLabs: Aion-RP 1.0 (8B)', 'created': 173869
6718, 'context_length': 32768, 'architecture': {'input_modalities': ['text'], 'o
utput_modalities': ['text'], 'tokenizer': 'Other', 'instruct_type': None}, 'pric
ing': {'prompt': '0.00001761', 'completion': '0.00001761', 'image': '0.00000000'
, 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.
00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'},
 'top_provider': {'context_length': 32768, 'max_completion_tokens': 32768, 'is_m
oderated': False}, 'per_request_limits': None, 'supported_parameters': ['max_tok
ens', 'temperature', 'top_p']}, {'id': 'qwen/qwen-vl-max', 'canonical_slug': 'qw
en/qwen-vl-max-2025-01-25', 'name': 'Qwen: Qwen VL Max', 'created': 1738434304,
'context_length': 7500, 'architecture': {'input_modalities': ['text', 'image'],
'output_modalities': ['text'], 'tokenizer': 'Qwen', 'instruct_type': None}, 'pri
cing': {'prompt': '0.00007042', 'completion': '0.00028169', 'image': '0.09014108
', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0
.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}
, 'top_provider': {'context_length': 7500, 'max_completion_tokens': 1500, 'is_mo
derated': False}, 'per_request_limits': None, 'supported_parameters': ['max_toke
ns', 'presence_penalty', 'response_format', 'seed', 'temperature', 'top_p']}, {'
id': 'qwen/qwen-turbo', 'canonical_slug': 'qwen/qwen-turbo-2024-11-01', 'name':
'Qwen: Qwen-Turbo', 'created': 1738410974, 'context_length': 1000000, 'architect
ure': {'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer':
 'Qwen', 'instruct_type': None}, 'pricing': {'prompt': '0.00000440', 'completion
': '0.00001761', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '
0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000176
', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 100000
0, 'max_completion_tokens': 8192, 'is_moderated': False}, 'per_request_limits':
None, 'supported_parameters': ['max_tokens', 'presence_penalty', 'response_forma
t', 'seed', 'temperature', 'tool_choice', 'tools', 'top_p']}, {'id': 'qwen/qwen2
.5-vl-72b-instruct', 'canonical_slug': 'qwen/qwen2.5-vl-72b-instruct', 'name': '
Qwen: Qwen2.5 VL 72B Instruct', 'created': 1738410311, 'context_length': 32768,
'architecture': {'input_modalities': ['text', 'image'], 'output_modalities': ['t
ext'], 'tokenizer': 'Qwen', 'instruct_type': None}, 'pricing': {'prompt': '0.000
00880', 'completion': '0.00003521', 'image': '0.00000000', 'request': '0.0000000
0', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache
_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'cont
ext_length': 32768, 'max_completion_tokens': 0, 'is_moderated': False}, 'per_req
uest_limits': None, 'supported_parameters': ['frequency_penalty', 'logit_bias',
'logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_penalty', 'se
ed', 'stop', 'temperature', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'qwen/qwe
n-plus', 'canonical_slug': 'qwen/qwen-plus-2025-01-25', 'name': 'Qwen: Qwen-Plus
', 'created': 1738409840, 'context_length': 131072, 'architecture': {'input_moda
lities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Qwen', 'instruct
_type': None}, 'pricing': {'prompt': '0.00003521', 'completion': '0.00010563', '
image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'inte
rnal_reasoning': '0.00000000', 'input_cache_read': '0.00001408', 'input_cache_wr
ite': '0.00000000'}, 'top_provider': {'context_length': 131072, 'max_completion_
tokens': 8192, 'is_moderated': False}, 'per_request_limits': None, 'supported_pa
rameters': ['max_tokens', 'presence_penalty', 'response_format', 'seed', 'temper
ature', 'tool_choice', 'tools', 'top_p']}, {'id': 'qwen/qwen-max', 'canonical_sl
ug': 'qwen/qwen-max-2025-01-25', 'name': 'Qwen: Qwen-Max ', 'created': 173840228
9, 'context_length': 32768, 'architecture': {'input_modalities': ['text'], 'outp
ut_modalities': ['text'], 'tokenizer': 'Qwen', 'instruct_type': None}, 'pricing'
: {'prompt': '0.00014085', 'completion': '0.00056338', 'image': '0.00000000', 'r
equest': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.0000
0000', 'input_cache_read': '0.00005634', 'input_cache_write': '0.00000000'}, 'to
p_provider': {'context_length': 32768, 'max_completion_tokens': 8192, 'is_modera
ted': False}, 'per_request_limits': None, 'supported_parameters': ['max_tokens',
 'presence_penalty', 'response_format', 'seed', 'temperature', 'tool_choice', 't
ools', 'top_p']}, {'id': 'openai/o3-mini', 'canonical_slug': 'openai/o3-mini-202
5-01-31', 'name': 'OpenAI: o3 Mini', 'created': 1738351721, 'context_length': 20
0000, 'architecture': {'input_modalities': ['text'], 'output_modalities': ['text
'], 'tokenizer': 'Other', 'instruct_type': None}, 'pricing': {'prompt': '0.00009
683', 'completion': '0.00038732', 'image': '0.00000000', 'request': '0.00000000'
, 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_r
ead': '0.00004842', 'input_cache_write': '0.00000000'}, 'top_provider': {'contex
t_length': 200000, 'max_completion_tokens': 100000, 'is_moderated': True}, 'per_
request_limits': None, 'supported_parameters': ['max_tokens', 'response_format',
 'seed', 'structured_outputs', 'tool_choice', 'tools']}, {'id': 'mistralai/mistr
al-small-24b-instruct-2501', 'canonical_slug': 'mistralai/mistral-small-24b-inst
ruct-2501', 'name': 'Mistral: Mistral Small 3', 'created': 1738255409, 'context_
length': 32768, 'architecture': {'input_modalities': ['text'], 'output_modalitie
s': ['text'], 'tokenizer': 'Mistral', 'instruct_type': None}, 'pricing': {'promp
t': '0.00000176', 'completion': '0.00000704', 'image': '0.00000000', 'request':
'0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'i
nput_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provide
r': {'context_length': 32768, 'max_completion_tokens': 0, 'is_moderated': False}
, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty', 'log
it_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_pen
alty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperature', '
tool_choice', 'tools', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'deepseek/deep
seek-r1-distill-qwen-32b', 'canonical_slug': 'deepseek/deepseek-r1-distill-qwen-
32b', 'name': 'DeepSeek: R1 Distill Qwen 32B', 'created': 1738194830, 'context_l
ength': 131072, 'architecture': {'input_modalities': ['text'], 'output_modalitie
s': ['text'], 'tokenizer': 'Qwen', 'instruct_type': 'deepseek-r1'}, 'pricing': {
'prompt': '0.00000660', 'completion': '0.00001320', 'image': '0.00000000', 'requ
est': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.0000000
0', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_p
rovider': {'context_length': 131072, 'max_completion_tokens': 16384, 'is_moderat
ed': False}, 'per_request_limits': None, 'supported_parameters': ['frequency_pen
alty', 'include_reasoning', 'logit_bias', 'max_tokens', 'min_p', 'presence_penal
ty', 'reasoning', 'repetition_penalty', 'response_format', 'seed', 'stop', 'temp
erature', 'top_k', 'top_p']}, {'id': 'deepseek/deepseek-r1-distill-qwen-14b', 'c
anonical_slug': 'deepseek/deepseek-r1-distill-qwen-14b', 'name': 'DeepSeek: R1 D
istill Qwen 14B', 'created': 1738193940, 'context_length': 64000, 'architecture'
: {'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Qw
en', 'instruct_type': 'deepseek-r1'}, 'pricing': {'prompt': '0.00001320', 'compl
etion': '0.00001320', 'image': '0.00000000', 'request': '0.00000000', 'web_searc
h': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.000
00000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 6
4000, 'max_completion_tokens': 32000, 'is_moderated': False}, 'per_request_limit
s': None, 'supported_parameters': ['frequency_penalty', 'include_reasoning', 'lo
git_bias', 'max_tokens', 'min_p', 'presence_penalty', 'reasoning', 'repetition_p
enalty', 'seed', 'stop', 'temperature', 'top_k', 'top_p']}, {'id': 'perplexity/s
onar-reasoning', 'canonical_slug': 'perplexity/sonar-reasoning', 'name': 'Perple
xity: Sonar Reasoning', 'created': 1738131107, 'context_length': 127000, 'archit
ecture': {'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenize
r': 'Other', 'instruct_type': 'deepseek-r1'}, 'pricing': {'prompt': '0.00008803'
, 'completion': '0.00044014', 'image': '0.00000000', 'request': '0.44014200', 'w
eb_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read'
: '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_le
ngth': 127000, 'max_completion_tokens': 0, 'is_moderated': False}, 'per_request_
limits': None, 'supported_parameters': ['frequency_penalty', 'include_reasoning'
, 'max_tokens', 'presence_penalty', 'reasoning', 'temperature', 'top_k', 'top_p'
, 'web_search_options']}, {'id': 'perplexity/sonar', 'canonical_slug': 'perplexi
ty/sonar', 'name': 'Perplexity: Sonar', 'created': 1738013808, 'context_length':
 127072, 'architecture': {'input_modalities': ['text', 'image'], 'output_modalit
ies': ['text'], 'tokenizer': 'Other', 'instruct_type': None}, 'pricing': {'promp
t': '0.00008803', 'completion': '0.00008803', 'image': '0.00000000', 'request':
'0.44014200', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'i
nput_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provide
r': {'context_length': 127072, 'max_completion_tokens': 0, 'is_moderated': False
}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty', 'ma
x_tokens', 'presence_penalty', 'temperature', 'top_k', 'top_p', 'web_search_opti
ons']}, {'id': 'liquid/lfm-7b', 'canonical_slug': 'liquid/lfm-7b', 'name': 'Liqu
id: LFM 7B', 'created': 1737806883, 'context_length': 32768, 'architecture': {'i
nput_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Other',
 'instruct_type': 'chatml'}, 'pricing': {'prompt': '0.00000088', 'completion': '
0.00000088', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00
000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', '
input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 32768, 'ma
x_completion_tokens': 0, 'is_moderated': False}, 'per_request_limits': None, 'su
pported_parameters': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_tokens
', 'min_p', 'presence_penalty', 'repetition_penalty', 'response_format', 'seed',
 'stop', 'temperature', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'liquid/lfm-3
b', 'canonical_slug': 'liquid/lfm-3b', 'name': 'Liquid: LFM 3B', 'created': 1737
806501, 'context_length': 32768, 'architecture': {'input_modalities': ['text'],
'output_modalities': ['text'], 'tokenizer': 'Other', 'instruct_type': 'chatml'},
 'pricing': {'prompt': '0.00000176', 'completion': '0.00000176', 'image': '0.000
00000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning
': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000
000'}, 'top_provider': {'context_length': 32768, 'max_completion_tokens': 0, 'is
_moderated': False}, 'per_request_limits': None, 'supported_parameters': ['frequ
ency_penalty', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_penalty',
'seed', 'stop', 'temperature', 'top_k', 'top_p']}, {'id': 'deepseek/deepseek-r1-
distill-llama-70b', 'canonical_slug': 'deepseek/deepseek-r1-distill-llama-70b',
'name': 'DeepSeek: R1 Distill Llama 70B', 'created': 1737663169, 'context_length
': 131072, 'architecture': {'input_modalities': ['text'], 'output_modalities': [
'text'], 'tokenizer': 'Llama3', 'instruct_type': 'deepseek-r1'}, 'pricing': {'pr
ompt': '0.00000228', 'completion': '0.00000913', 'image': '0.00000000', 'request
': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000',
 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_prov
ider': {'context_length': 131072, 'max_completion_tokens': 0, 'is_moderated': Fa
lse}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty',
'include_reasoning', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_
penalty', 'reasoning', 'repetition_penalty', 'response_format', 'seed', 'stop',
'temperature', 'tool_choice', 'tools', 'top_k', 'top_logprobs', 'top_p']}, {'id'
: 'deepseek/deepseek-r1', 'canonical_slug': 'deepseek/deepseek-r1', 'name': 'Dee
pSeek: R1', 'created': 1737381095, 'context_length': 163840, 'architecture': {'i
nput_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'DeepSee
k', 'instruct_type': 'deepseek-r1'}, 'pricing': {'prompt': '0.00003521', 'comple
tion': '0.00017606', 'image': '0.00000000', 'request': '0.00000000', 'web_search
': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.0000
0000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 16
3840, 'max_completion_tokens': 163840, 'is_moderated': False}, 'per_request_limi
ts': None, 'supported_parameters': ['frequency_penalty', 'include_reasoning', 'l
ogit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'reasoning',
'repetition_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', '
temperature', 'tool_choice', 'tools', 'top_k', 'top_logprobs', 'top_p']}, {'id':
 'minimax/minimax-01', 'canonical_slug': 'minimax/minimax-01', 'name': 'MiniMax:
 MiniMax-01', 'created': 1736915462, 'context_length': 1000192, 'architecture':
{'input_modalities': ['text', 'image'], 'output_modalities': ['text'], 'tokenize
r': 'Other', 'instruct_type': None}, 'pricing': {'prompt': '0.00001761', 'comple
tion': '0.00009683', 'image': '0.00000000', 'request': '0.00000000', 'web_search
': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.0000
0000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 10
00192, 'max_completion_tokens': 1000192, 'is_moderated': False}, 'per_request_li
mits': None, 'supported_parameters': ['max_tokens', 'temperature', 'top_p']}, {'
id': 'mistralai/codestral-2501', 'canonical_slug': 'mistralai/codestral-2501', '
name': 'Mistral: Codestral 2501', 'created': 1736895522, 'context_length': 26214
4, 'architecture': {'input_modalities': ['text'], 'output_modalities': ['text'],
 'tokenizer': 'Mistral', 'instruct_type': None}, 'pricing': {'prompt': '0.000026
41', 'completion': '0.00007923', 'image': '0.00000000', 'request': '0.00000000',
 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_re
ad': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context
_length': 262144, 'max_completion_tokens': 0, 'is_moderated': False}, 'per_reque
st_limits': None, 'supported_parameters': ['frequency_penalty', 'max_tokens', 'p
resence_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temp
erature', 'tool_choice', 'tools', 'top_p']}, {'id': 'microsoft/phi-4', 'canonica
l_slug': 'microsoft/phi-4', 'name': 'Microsoft: Phi 4', 'created': 1736489872, '
context_length': 16384, 'architecture': {'input_modalities': ['text'], 'output_m
odalities': ['text'], 'tokenizer': 'Other', 'instruct_type': None}, 'pricing': {
'prompt': '0.00000528', 'completion': '0.00001232', 'image': '0.00000000', 'requ
est': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.0000000
0', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_p
rovider': {'context_length': 16384, 'max_completion_tokens': 0, 'is_moderated':
False}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty'
, 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'repetiti
on_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperatu
re', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'deepseek/deepseek-chat', 'canon
ical_slug': 'deepseek/deepseek-chat-v3', 'name': 'DeepSeek: DeepSeek V3', 'creat
ed': 1735241320, 'context_length': 163840, 'architecture': {'input_modalities':
['text'], 'output_modalities': ['text'], 'tokenizer': 'DeepSeek', 'instruct_type
': None}, 'pricing': {'prompt': '0.00001760', 'completion': '0.00007043', 'image
': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_
reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write':
 '0.00000000'}, 'top_provider': {'context_length': 163840, 'max_completion_token
s': 0, 'is_moderated': False}, 'per_request_limits': None, 'supported_parameters
': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'prese
nce_penalty', 'repetition_penalty', 'response_format', 'seed', 'stop', 'structur
ed_outputs', 'temperature', 'tool_choice', 'tools', 'top_k', 'top_logprobs', 'to
p_p']}, {'id': 'sao10k/l3.3-euryale-70b', 'canonical_slug': 'sao10k/l3.3-euryale
-70b-v2.3', 'name': 'Sao10K: Llama 3.3 Euryale 70B', 'created': 1734535928, 'con
text_length': 131072, 'architecture': {'input_modalities': ['text'], 'output_mod
alities': ['text'], 'tokenizer': 'Llama3', 'instruct_type': 'llama3'}, 'pricing'
: {'prompt': '0.00005722', 'completion': '0.00006602', 'image': '0.00000000', 'r
equest': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.0000
0000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'to
p_provider': {'context_length': 131072, 'max_completion_tokens': 16384, 'is_mode
rated': False}, 'per_request_limits': None, 'supported_parameters': ['frequency_
penalty', 'logit_bias', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_p
enalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperature',
 'top_k', 'top_p']}, {'id': 'openai/o1', 'canonical_slug': 'openai/o1-2024-12-17
', 'name': 'OpenAI: o1', 'created': 1734459999, 'context_length': 200000, 'archi
tecture': {'input_modalities': ['text', 'image'], 'output_modalities': ['text'],
 'tokenizer': 'GPT', 'instruct_type': None}, 'pricing': {'prompt': '0.00132043',
 'completion': '0.00528170', 'image': '1.90801557', 'request': '0.00000000', 'we
b_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read':
 '0.00066021', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_len
gth': 200000, 'max_completion_tokens': 100000, 'is_moderated': True}, 'per_reque
st_limits': None, 'supported_parameters': ['max_tokens', 'response_format', 'see
d', 'structured_outputs', 'tool_choice', 'tools']}, {'id': 'x-ai/grok-2-vision-1
212', 'canonical_slug': 'x-ai/grok-2-vision-1212', 'name': 'xAI: Grok 2 Vision 1
212', 'created': 1734237338, 'context_length': 32768, 'architecture': {'input_mo
dalities': ['text', 'image'], 'output_modalities': ['text'], 'tokenizer': 'Grok'
, 'instruct_type': None}, 'pricing': {'prompt': '0.00017606', 'completion': '0.0
0088028', 'image': '0.31690224', 'request': '0.00000000', 'web_search': '0.00000
000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'inp
ut_cache_write': '0.00000000'}, 'top_provider': {'context_length': 32768, 'max_c
ompletion_tokens': 0, 'is_moderated': False}, 'per_request_limits': None, 'suppo
rted_parameters': ['frequency_penalty', 'logprobs', 'max_tokens', 'presence_pena
lty', 'response_format', 'seed', 'stop', 'temperature', 'top_logprobs', 'top_p']
}, {'id': 'x-ai/grok-2-1212', 'canonical_slug': 'x-ai/grok-2-1212', 'name': 'xAI
: Grok 2 1212', 'created': 1734232814, 'context_length': 131072, 'architecture':
 {'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Gro
k', 'instruct_type': None}, 'pricing': {'prompt': '0.00017606', 'completion': '0
.00088028', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.000
00000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'i
nput_cache_write': '0.00000000'}, 'top_provider': {'context_length': 131072, 'ma
x_completion_tokens': 0, 'is_moderated': False}, 'per_request_limits': None, 'su
pported_parameters': ['frequency_penalty', 'logprobs', 'max_tokens', 'presence_p
enalty', 'response_format', 'seed', 'stop', 'temperature', 'tool_choice', 'tools
', 'top_logprobs', 'top_p']}, {'id': 'cohere/command-r7b-12-2024', 'canonical_sl
ug': 'cohere/command-r7b-12-2024', 'name': 'Cohere: Command R7B (12-2024)', 'cre
ated': 1734158152, 'context_length': 128000, 'architecture': {'input_modalities'
: ['text'], 'output_modalities': ['text'], 'tokenizer': 'Cohere', 'instruct_type
': None}, 'pricing': {'prompt': '0.00000330', 'completion': '0.00001320', 'image
': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_
reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write':
 '0.00000000'}, 'top_provider': {'context_length': 128000, 'max_completion_token
s': 4000, 'is_moderated': True}, 'per_request_limits': None, 'supported_paramete
rs': ['frequency_penalty', 'max_tokens', 'presence_penalty', 'response_format',
'seed', 'stop', 'structured_outputs', 'temperature', 'top_k', 'top_p']}, {'id':
'meta-llama/llama-3.3-70b-instruct', 'canonical_slug': 'meta-llama/llama-3.3-70b
-instruct', 'name': 'Meta: Llama 3.3 70B Instruct', 'created': 1733506137, 'cont
ext_length': 131072, 'architecture': {'input_modalities': ['text'], 'output_moda
lities': ['text'], 'tokenizer': 'Llama3', 'instruct_type': 'llama3'}, 'pricing':
 {'prompt': '0.00000335', 'completion': '0.00001056', 'image': '0.00000000', 're
quest': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000
000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top
_provider': {'context_length': 131072, 'max_completion_tokens': 16384, 'is_moder
ated': False}, 'per_request_limits': None, 'supported_parameters': ['frequency_p
enalty', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'r
epetition_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'te
mperature', 'tool_choice', 'tools', 'top_k', 'top_logprobs', 'top_p']}, {'id': '
amazon/nova-lite-v1', 'canonical_slug': 'amazon/nova-lite-v1', 'name': 'Amazon:
Nova Lite 1.0', 'created': 1733437363, 'context_length': 300000, 'architecture':
 {'input_modalities': ['text', 'image'], 'output_modalities': ['text'], 'tokeniz
er': 'Nova', 'instruct_type': None}, 'pricing': {'prompt': '0.00000528', 'comple
tion': '0.00002113', 'image': '0.00792256', 'request': '0.00000000', 'web_search
': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.0000
0000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 30
0000, 'max_completion_tokens': 5120, 'is_moderated': True}, 'per_request_limits'
: None, 'supported_parameters': ['max_tokens', 'stop', 'temperature', 'tools', '
top_k', 'top_p']}, {'id': 'amazon/nova-micro-v1', 'canonical_slug': 'amazon/nova
-micro-v1', 'name': 'Amazon: Nova Micro 1.0', 'created': 1733437237, 'context_le
ngth': 128000, 'architecture': {'input_modalities': ['text'], 'output_modalities
': ['text'], 'tokenizer': 'Nova', 'instruct_type': None}, 'pricing': {'prompt':
'0.00000308', 'completion': '0.00001232', 'image': '0.00000000', 'request': '0.0
0000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input
_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider':
{'context_length': 128000, 'max_completion_tokens': 5120, 'is_moderated': True},
 'per_request_limits': None, 'supported_parameters': ['max_tokens', 'stop', 'tem
perature', 'tools', 'top_k', 'top_p']}, {'id': 'amazon/nova-pro-v1', 'canonical_
slug': 'amazon/nova-pro-v1', 'name': 'Amazon: Nova Pro 1.0', 'created': 17334363
03, 'context_length': 300000, 'architecture': {'input_modalities': ['text', 'ima
ge'], 'output_modalities': ['text'], 'tokenizer': 'Nova', 'instruct_type': None}
, 'pricing': {'prompt': '0.00007042', 'completion': '0.00028169', 'image': '0.10
563408', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasonin
g': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.0000
0000'}, 'top_provider': {'context_length': 300000, 'max_completion_tokens': 5120
, 'is_moderated': True}, 'per_request_limits': None, 'supported_parameters': ['m
ax_tokens', 'stop', 'temperature', 'tools', 'top_k', 'top_p']}, {'id': 'qwen/qwq
-32b-preview', 'canonical_slug': 'qwen/qwq-32b-preview', 'name': 'Qwen: QwQ 32B
Preview', 'created': 1732754541, 'context_length': 32768, 'architecture': {'inpu
t_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Qwen', 'in
struct_type': 'deepseek-r1'}, 'pricing': {'prompt': '0.00001761', 'completion':
'0.00001761', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.0
0000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000',
'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 32768, 'm
ax_completion_tokens': 0, 'is_moderated': False}, 'per_request_limits': None, 's
upported_parameters': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_token
s', 'min_p', 'presence_penalty', 'repetition_penalty', 'seed', 'stop', 'temperat
ure', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'openai/gpt-4o-2024-11-20', 'ca
nonical_slug': 'openai/gpt-4o-2024-11-20', 'name': 'OpenAI: GPT-4o (2024-11-20)'
, 'created': 1732127594, 'context_length': 128000, 'architecture': {'input_modal
ities': ['text', 'image', 'file'], 'output_modalities': ['text'], 'tokenizer': '
GPT', 'instruct_type': None}, 'pricing': {'prompt': '0.00022007', 'completion':
'0.00088028', 'image': '0.31804661', 'request': '0.00000000', 'web_search': '0.0
0000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00011004',
'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 128000, '
max_completion_tokens': 16384, 'is_moderated': True}, 'per_request_limits': None
, 'supported_parameters': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_t
okens', 'presence_penalty', 'response_format', 'seed', 'stop', 'structured_outpu
ts', 'temperature', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'web_search
_options']}, {'id': 'mistralai/mistral-large-2411', 'canonical_slug': 'mistralai
/mistral-large-2411', 'name': 'Mistral Large 2411', 'created': 1731978685, 'cont
ext_length': 131072, 'architecture': {'input_modalities': ['text'], 'output_moda
lities': ['text'], 'tokenizer': 'Mistral', 'instruct_type': None}, 'pricing': {'
prompt': '0.00017606', 'completion': '0.00052817', 'image': '0.00000000', 'reque
st': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000
', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_pr
ovider': {'context_length': 131072, 'max_completion_tokens': 0, 'is_moderated':
False}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty'
, 'max_tokens', 'presence_penalty', 'response_format', 'seed', 'stop', 'structur
ed_outputs', 'temperature', 'tool_choice', 'tools', 'top_p']}, {'id': 'mistralai
/mistral-large-2407', 'canonical_slug': 'mistralai/mistral-large-2407', 'name':
'Mistral Large 2407', 'created': 1731978415, 'context_length': 131072, 'architec
ture': {'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer'
: 'Mistral', 'instruct_type': None}, 'pricing': {'prompt': '0.00017606', 'comple
tion': '0.00052817', 'image': '0.00000000', 'request': '0.00000000', 'web_search
': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.0000
0000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 13
1072, 'max_completion_tokens': 0, 'is_moderated': False}, 'per_request_limits':
None, 'supported_parameters': ['frequency_penalty', 'max_tokens', 'presence_pena
lty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperature', 't
ool_choice', 'tools', 'top_p']}, {'id': 'mistralai/pixtral-large-2411', 'canonic
al_slug': 'mistralai/pixtral-large-2411', 'name': 'Mistral: Pixtral Large 2411',
 'created': 1731977388, 'context_length': 131072, 'architecture': {'input_modali
ties': ['text', 'image'], 'output_modalities': ['text'], 'tokenizer': 'Mistral',
 'instruct_type': None}, 'pricing': {'prompt': '0.00017606', 'completion': '0.00
052817', 'image': '0.25422602', 'request': '0.00000000', 'web_search': '0.000000
00', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'inpu
t_cache_write': '0.00000000'}, 'top_provider': {'context_length': 131072, 'max_c
ompletion_tokens': 0, 'is_moderated': False}, 'per_request_limits': None, 'suppo
rted_parameters': ['frequency_penalty', 'max_tokens', 'presence_penalty', 'respo
nse_format', 'seed', 'stop', 'structured_outputs', 'temperature', 'tool_choice',
 'tools', 'top_p']}, {'id': 'x-ai/grok-vision-beta', 'canonical_slug': 'x-ai/gro
k-vision-beta', 'name': 'xAI: Grok Vision Beta', 'created': 1731976624, 'context
_length': 8192, 'architecture': {'input_modalities': ['text', 'image'], 'output_
modalities': ['text'], 'tokenizer': 'Grok', 'instruct_type': None}, 'pricing': {
'prompt': '0.00044014', 'completion': '0.00132043', 'image': '0.79225560', 'requ
est': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.0000000
0', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_p
rovider': {'context_length': 8192, 'max_completion_tokens': 0, 'is_moderated': F
alse}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty',
 'logprobs', 'max_tokens', 'presence_penalty', 'response_format', 'seed', 'stop'
, 'temperature', 'top_logprobs', 'top_p']}, {'id': 'infermatic/mn-inferor-12b',
'canonical_slug': 'infermatic/mn-inferor-12b', 'name': 'Infermatic: Mistral Nemo
 Inferor 12B', 'created': 1731464428, 'context_length': 8192, 'architecture': {'
input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Mistra
l', 'instruct_type': 'mistral'}, 'pricing': {'prompt': '0.00005282', 'completion
': '0.00008803', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '
0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000
', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 8192,
'max_completion_tokens': 8192, 'is_moderated': False}, 'per_request_limits': Non
e, 'supported_parameters': ['frequency_penalty', 'max_tokens', 'min_p', 'presenc
e_penalty', 'repetition_penalty', 'seed', 'stop', 'temperature', 'top_k', 'top_p
']}, {'id': 'qwen/qwen-2.5-coder-32b-instruct', 'canonical_slug': 'qwen/qwen-2.5
-coder-32b-instruct', 'name': 'Qwen2.5 Coder 32B Instruct', 'created': 173136840
0, 'context_length': 32768, 'architecture': {'input_modalities': ['text'], 'outp
ut_modalities': ['text'], 'tokenizer': 'Qwen', 'instruct_type': 'chatml'}, 'pric
ing': {'prompt': '0.00000440', 'completion': '0.00001761', 'image': '0.00000000'
, 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.
00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'},
 'top_provider': {'context_length': 32768, 'max_completion_tokens': 0, 'is_moder
ated': False}, 'per_request_limits': None, 'supported_parameters': ['frequency_p
enalty', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'r
epetition_penalty', 'response_format', 'seed', 'stop', 'temperature', 'top_k', '
top_logprobs', 'top_p']}, {'id': 'raifle/sorcererlm-8x22b', 'canonical_slug': 'r
aifle/sorcererlm-8x22b', 'name': 'SorcererLM 8x22B', 'created': 1731105083, 'con
text_length': 16000, 'architecture': {'input_modalities': ['text'], 'output_moda
lities': ['text'], 'tokenizer': 'Mistral', 'instruct_type': 'vicuna'}, 'pricing'
: {'prompt': '0.00039613', 'completion': '0.00039613', 'image': '0.00000000', 'r
equest': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.0000
0000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'to
p_provider': {'context_length': 16000, 'max_completion_tokens': 0, 'is_moderated
': False}, 'per_request_limits': None, 'supported_parameters': ['frequency_penal
ty', 'logit_bias', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_penalt
y', 'seed', 'stop', 'temperature', 'top_k', 'top_p']}, {'id': 'thedrummer/unslop
nemo-12b', 'canonical_slug': 'thedrummer/unslopnemo-12b', 'name': 'TheDrummer: U
nslopNemo 12B', 'created': 1731103448, 'context_length': 32768, 'architecture':
{'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Mist
ral', 'instruct_type': 'mistral'}, 'pricing': {'prompt': '0.00003521', 'completi
on': '0.00003521', 'image': '0.00000000', 'request': '0.00000000', 'web_search':
 '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.000000
00', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 3276
8, 'max_completion_tokens': 0, 'is_moderated': False}, 'per_request_limits': Non
e, 'supported_parameters': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_
tokens', 'min_p', 'presence_penalty', 'repetition_penalty', 'response_format', '
seed', 'stop', 'structured_outputs', 'temperature', 'tool_choice', 'tools', 'top
_k', 'top_p']}, {'id': 'anthropic/claude-3.5-haiku', 'canonical_slug': 'anthropi
c/claude-3-5-haiku', 'name': 'Anthropic: Claude 3.5 Haiku', 'created': 173067840
0, 'context_length': 200000, 'architecture': {'input_modalities': ['text', 'imag
e'], 'output_modalities': ['text'], 'tokenizer': 'Claude', 'instruct_type': None
}, 'pricing': {'prompt': '0.00007042', 'completion': '0.00035211', 'image': '0.0
0000000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoni
ng': '0.00000000', 'input_cache_read': '0.00000704', 'input_cache_write': '0.000
08803'}, 'top_provider': {'context_length': 200000, 'max_completion_tokens': 819
2, 'is_moderated': True}, 'per_request_limits': None, 'supported_parameters': ['
max_tokens', 'stop', 'temperature', 'tool_choice', 'tools', 'top_k', 'top_p']},
{'id': 'anthropic/claude-3.5-haiku-20241022', 'canonical_slug': 'anthropic/claud
e-3-5-haiku-20241022', 'name': 'Anthropic: Claude 3.5 Haiku (2024-10-22)', 'crea
ted': 1730678400, 'context_length': 200000, 'architecture': {'input_modalities':
 ['text', 'image', 'file'], 'output_modalities': ['text'], 'tokenizer': 'Claude'
, 'instruct_type': None}, 'pricing': {'prompt': '0.00007042', 'completion': '0.0
0035211', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000
000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000704', 'inp
ut_cache_write': '0.00008803'}, 'top_provider': {'context_length': 200000, 'max_
completion_tokens': 8192, 'is_moderated': False}, 'per_request_limits': None, 's
upported_parameters': ['max_tokens', 'stop', 'temperature', 'tool_choice', 'tool
s', 'top_k', 'top_p']}, {'id': 'anthracite-org/magnum-v4-72b', 'canonical_slug':
 'anthracite-org/magnum-v4-72b', 'name': 'Magnum v4 72B', 'created': 1729555200,
 'context_length': 16384, 'architecture': {'input_modalities': ['text'], 'output
_modalities': ['text'], 'tokenizer': 'Qwen', 'instruct_type': 'chatml'}, 'pricin
g': {'prompt': '0.00017606', 'completion': '0.00044014', 'image': '0.00000000',
'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00
000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, '
top_provider': {'context_length': 16384, 'max_completion_tokens': 2048, 'is_mode
rated': False}, 'per_request_limits': None, 'supported_parameters': ['frequency_
penalty', 'logit_bias', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_p
enalty', 'seed', 'stop', 'temperature', 'top_a', 'top_k', 'top_p']}, {'id': 'ant
hropic/claude-3.5-sonnet', 'canonical_slug': 'anthropic/claude-3.5-sonnet', 'nam
e': 'Anthropic: Claude 3.5 Sonnet', 'created': 1729555200, 'context_length': 200
000, 'architecture': {'input_modalities': ['text', 'image', 'file'], 'output_mod
alities': ['text'], 'tokenizer': 'Claude', 'instruct_type': None}, 'pricing': {'
prompt': '0.00026409', 'completion': '0.00132043', 'image': '0.42253632', 'reque
st': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000
', 'input_cache_read': '0.00002641', 'input_cache_write': '0.00033011'}, 'top_pr
ovider': {'context_length': 200000, 'max_completion_tokens': 8192, 'is_moderated
': True}, 'per_request_limits': None, 'supported_parameters': ['max_tokens', 'st
op', 'temperature', 'tool_choice', 'tools', 'top_k', 'top_p']}, {'id': 'mistrala
i/ministral-8b', 'canonical_slug': 'mistralai/ministral-8b', 'name': 'Mistral: M
inistral 8B', 'created': 1729123200, 'context_length': 128000, 'architecture': {
'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Mistr
al', 'instruct_type': None}, 'pricing': {'prompt': '0.00000880', 'completion': '
0.00000880', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00
000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', '
input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 128000, 'm
ax_completion_tokens': 0, 'is_moderated': False}, 'per_request_limits': None, 's
upported_parameters': ['frequency_penalty', 'max_tokens', 'presence_penalty', 'r
esponse_format', 'seed', 'stop', 'structured_outputs', 'temperature', 'tool_choi
ce', 'tools', 'top_p']}, {'id': 'mistralai/ministral-3b', 'canonical_slug': 'mis
tralai/ministral-3b', 'name': 'Mistral: Ministral 3B', 'created': 1729123200, 'c
ontext_length': 32768, 'architecture': {'input_modalities': ['text'], 'output_mo
dalities': ['text'], 'tokenizer': 'Mistral', 'instruct_type': None}, 'pricing':
{'prompt': '0.00000352', 'completion': '0.00000352', 'image': '0.00000000', 'req
uest': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.000000
00', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_
provider': {'context_length': 32768, 'max_completion_tokens': 0, 'is_moderated':
 False}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty
', 'max_tokens', 'presence_penalty', 'response_format', 'seed', 'stop', 'structu
red_outputs', 'temperature', 'top_p']}, {'id': 'qwen/qwen-2.5-7b-instruct', 'can
onical_slug': 'qwen/qwen-2.5-7b-instruct', 'name': 'Qwen2.5 7B Instruct', 'creat
ed': 1729036800, 'context_length': 65536, 'architecture': {'input_modalities': [
'text'], 'output_modalities': ['text'], 'tokenizer': 'Qwen', 'instruct_type': 'c
hatml'}, 'pricing': {'prompt': '0.00000352', 'completion': '0.00000880', 'image'
: '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_r
easoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write':
'0.00000000'}, 'top_provider': {'context_length': 65536, 'max_completion_tokens'
: 0, 'is_moderated': False}, 'per_request_limits': None, 'supported_parameters':
 ['frequency_penalty', 'logit_bias', 'max_tokens', 'min_p', 'presence_penalty',
'repetition_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', '
temperature', 'top_k', 'top_p']}, {'id': 'nvidia/llama-3.1-nemotron-70b-instruct
', 'canonical_slug': 'nvidia/llama-3.1-nemotron-70b-instruct', 'name': 'NVIDIA:
Llama 3.1 Nemotron 70B Instruct', 'created': 1728950400, 'context_length': 13107
2, 'architecture': {'input_modalities': ['text'], 'output_modalities': ['text'],
 'tokenizer': 'Llama3', 'instruct_type': 'llama3'}, 'pricing': {'prompt': '0.000
01056', 'completion': '0.00002641', 'image': '0.00000000', 'request': '0.0000000
0', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache
_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'cont
ext_length': 131072, 'max_completion_tokens': 16384, 'is_moderated': False}, 'pe
r_request_limits': None, 'supported_parameters': ['frequency_penalty', 'logit_bi
as', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_penalty', 'response_
format', 'seed', 'stop', 'temperature', 'tool_choice', 'tools', 'top_k', 'top_p'
]}, {'id': 'inflection/inflection-3-pi', 'canonical_slug': 'inflection/inflectio
n-3-pi', 'name': 'Inflection: Inflection 3 Pi', 'created': 1728604800, 'context_
length': 8000, 'architecture': {'input_modalities': ['text'], 'output_modalities
': ['text'], 'tokenizer': 'Other', 'instruct_type': None}, 'pricing': {'prompt':
 '0.00022007', 'completion': '0.00088028', 'image': '0.00000000', 'request': '0.
00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'inpu
t_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider':
 {'context_length': 8000, 'max_completion_tokens': 1024, 'is_moderated': False},
 'per_request_limits': None, 'supported_parameters': ['max_tokens', 'stop', 'tem
perature', 'top_p']}, {'id': 'inflection/inflection-3-productivity', 'canonical_
slug': 'inflection/inflection-3-productivity', 'name': 'Inflection: Inflection 3
 Productivity', 'created': 1728604800, 'context_length': 8000, 'architecture': {
'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Other
', 'instruct_type': None}, 'pricing': {'prompt': '0.00022007', 'completion': '0.
00088028', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.0000
0000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'in
put_cache_write': '0.00000000'}, 'top_provider': {'context_length': 8000, 'max_c
ompletion_tokens': 1024, 'is_moderated': False}, 'per_request_limits': None, 'su
pported_parameters': ['max_tokens', 'stop', 'temperature', 'top_p']}, {'id': 'go
ogle/gemini-flash-1.5-8b', 'canonical_slug': 'google/gemini-flash-1.5-8b', 'name
': 'Google: Gemini 1.5 Flash 8B', 'created': 1727913600, 'context_length': 10000
00, 'architecture': {'input_modalities': ['text', 'image'], 'output_modalities':
 ['text'], 'tokenizer': 'Gemini', 'instruct_type': None}, 'pricing': {'prompt':
'0.00000330', 'completion': '0.00001320', 'image': '0.00000000', 'request': '0.0
0000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input
_cache_read': '0.00000088', 'input_cache_write': '0.00000513'}, 'top_provider':
{'context_length': 1000000, 'max_completion_tokens': 8192, 'is_moderated': False
}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty', 'ma
x_tokens', 'presence_penalty', 'response_format', 'seed', 'stop', 'structured_ou
tputs', 'temperature', 'tool_choice', 'tools', 'top_p']}, {'id': 'anthracite-org
/magnum-v2-72b', 'canonical_slug': 'anthracite-org/magnum-v2-72b', 'name': 'Magn
um v2 72B', 'created': 1727654400, 'context_length': 32768, 'architecture': {'in
put_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Qwen', '
instruct_type': 'chatml'}, 'pricing': {'prompt': '0.00026409', 'completion': '0.
00026409', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.0000
0000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'in
put_cache_write': '0.00000000'}, 'top_provider': {'context_length': 32768, 'max_
completion_tokens': 0, 'is_moderated': False}, 'per_request_limits': None, 'supp
orted_parameters': ['frequency_penalty', 'logit_bias', 'max_tokens', 'min_p', 'p
resence_penalty', 'repetition_penalty', 'seed', 'stop', 'temperature', 'top_k',
'top_p']}, {'id': 'thedrummer/rocinante-12b', 'canonical_slug': 'thedrummer/roci
nante-12b', 'name': 'TheDrummer: Rocinante 12B', 'created': 1727654400, 'context
_length': 32768, 'architecture': {'input_modalities': ['text'], 'output_modaliti
es': ['text'], 'tokenizer': 'Qwen', 'instruct_type': 'chatml'}, 'pricing': {'pro
mpt': '0.00001496', 'completion': '0.00003785', 'image': '0.00000000', 'request'
: '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000',
'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provi
der': {'context_length': 32768, 'max_completion_tokens': 0, 'is_moderated': Fals
e}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty', 'l
ogit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_p
enalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperature',
 'tool_choice', 'tools', 'top_k', 'top_p']}, {'id': 'meta-llama/llama-3.2-1b-ins
truct', 'canonical_slug': 'meta-llama/llama-3.2-1b-instruct', 'name': 'Meta: Lla
ma 3.2 1B Instruct', 'created': 1727222400, 'context_length': 131072, 'architect
ure': {'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer':
 'Llama3', 'instruct_type': 'llama3'}, 'pricing': {'prompt': '0.00000044', 'comp
letion': '0.00000088', 'image': '0.00000000', 'request': '0.00000000', 'web_sear
ch': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00
000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length':
131072, 'max_completion_tokens': 16384, 'is_moderated': False}, 'per_request_lim
its': None, 'supported_parameters': ['frequency_penalty', 'logit_bias', 'max_tok
ens', 'min_p', 'presence_penalty', 'repetition_penalty', 'response_format', 'see
d', 'stop', 'structured_outputs', 'temperature', 'top_k', 'top_logprobs', 'top_p
']}, {'id': 'meta-llama/llama-3.2-11b-vision-instruct', 'canonical_slug': 'meta-
llama/llama-3.2-11b-vision-instruct', 'name': 'Meta: Llama 3.2 11B Vision Instru
ct', 'created': 1727222400, 'context_length': 131072, 'architecture': {'input_mo
dalities': ['text', 'image'], 'output_modalities': ['text'], 'tokenizer': 'Llama
3', 'instruct_type': 'llama3'}, 'pricing': {'prompt': '0.00000431', 'completion'
: '0.00000431', 'image': '0.00699650', 'request': '0.00000000', 'web_search': '0
.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000'
, 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 131072,
 'max_completion_tokens': 16384, 'is_moderated': False}, 'per_request_limits': N
one, 'supported_parameters': ['frequency_penalty', 'logit_bias', 'max_tokens', '
min_p', 'presence_penalty', 'repetition_penalty', 'response_format', 'seed', 'st
op', 'structured_outputs', 'temperature', 'top_k', 'top_logprobs', 'top_p']}, {'
id': 'meta-llama/llama-3.2-3b-instruct', 'canonical_slug': 'meta-llama/llama-3.2
-3b-instruct', 'name': 'Meta: Llama 3.2 3B Instruct', 'created': 1727222400, 'co
ntext_length': 20000, 'architecture': {'input_modalities': ['text'], 'output_mod
alities': ['text'], 'tokenizer': 'Llama3', 'instruct_type': 'llama3'}, 'pricing'
: {'prompt': '0.00000026', 'completion': '0.00000053', 'image': '0.00000000', 'r
equest': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.0000
0000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'to
p_provider': {'context_length': 20000, 'max_completion_tokens': 20000, 'is_moder
ated': False}, 'per_request_limits': None, 'supported_parameters': ['frequency_p
enalty', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'r
epetition_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'te
mperature', 'tool_choice', 'tools', 'top_k', 'top_logprobs', 'top_p']}, {'id': '
meta-llama/llama-3.2-90b-vision-instruct', 'canonical_slug': 'meta-llama/llama-3
.2-90b-vision-instruct', 'name': 'Meta: Llama 3.2 90B Vision Instruct', 'created
': 1727222400, 'context_length': 32768, 'architecture': {'input_modalities': ['t
ext', 'image'], 'output_modalities': ['text'], 'tokenizer': 'Llama3', 'instruct_
type': 'llama3'}, 'pricing': {'prompt': '0.00003081', 'completion': '0.00003521'
, 'image': '0.04452476', 'request': '0.00000000', 'web_search': '0.00000000', 'i
nternal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache
_write': '0.00000000'}, 'top_provider': {'context_length': 32768, 'max_completio
n_tokens': 16384, 'is_moderated': False}, 'per_request_limits': None, 'supported
_parameters': ['frequency_penalty', 'max_tokens', 'min_p', 'presence_penalty', '
repetition_penalty', 'response_format', 'seed', 'stop', 'temperature', 'top_k',
'top_p']}, {'id': 'qwen/qwen-2.5-72b-instruct', 'canonical_slug': 'qwen/qwen-2.5
-72b-instruct', 'name': 'Qwen2.5 72B Instruct', 'created': 1726704000, 'context_
length': 32768, 'architecture': {'input_modalities': ['text'], 'output_modalitie
s': ['text'], 'tokenizer': 'Qwen', 'instruct_type': 'chatml'}, 'pricing': {'prom
pt': '0.00000456', 'completion': '0.00001826', 'image': '0.00000000', 'request':
 '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', '
input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provid
er': {'context_length': 32768, 'max_completion_tokens': 0, 'is_moderated': False
}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty', 'lo
git_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_pe
nalty', 'response_format', 'seed', 'stop', 'temperature', 'tool_choice', 'tools'
, 'top_k', 'top_logprobs', 'top_p']}, {'id': 'neversleep/llama-3.1-lumimaid-8b',
 'canonical_slug': 'neversleep/llama-3.1-lumimaid-8b', 'name': 'NeverSleep: Lumi
maid v0.2 8B', 'created': 1726358400, 'context_length': 32768, 'architecture': {
'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Llama
3', 'instruct_type': 'llama3'}, 'pricing': {'prompt': '0.00000792', 'completion'
: '0.00005282', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0
.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000'
, 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 32768,
'max_completion_tokens': 0, 'is_moderated': False}, 'per_request_limits': None,
'supported_parameters': ['frequency_penalty', 'logit_bias', 'max_tokens', 'min_p
', 'presence_penalty', 'repetition_penalty', 'response_format', 'seed', 'stop',
'structured_outputs', 'temperature', 'top_a', 'top_k', 'top_p']}, {'id': 'openai
/o1-mini', 'canonical_slug': 'openai/o1-mini', 'name': 'OpenAI: o1-mini', 'creat
ed': 1726099200, 'context_length': 128000, 'architecture': {'input_modalities':
['text'], 'output_modalities': ['text'], 'tokenizer': 'GPT', 'instruct_type': No
ne}, 'pricing': {'prompt': '0.00009683', 'completion': '0.00038732', 'image': '0
.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reaso
ning': '0.00000000', 'input_cache_read': '0.00004842', 'input_cache_write': '0.0
0000000'}, 'top_provider': {'context_length': 128000, 'max_completion_tokens': 6
5536, 'is_moderated': True}, 'per_request_limits': None, 'supported_parameters':
 ['max_tokens', 'seed']}, {'id': 'openai/o1-mini-2024-09-12', 'canonical_slug':
'openai/o1-mini-2024-09-12', 'name': 'OpenAI: o1-mini (2024-09-12)', 'created':
1726099200, 'context_length': 128000, 'architecture': {'input_modalities': ['tex
t'], 'output_modalities': ['text'], 'tokenizer': 'GPT', 'instruct_type': None},
'pricing': {'prompt': '0.00009683', 'completion': '0.00038732', 'image': '0.0000
0000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning'
: '0.00000000', 'input_cache_read': '0.00004842', 'input_cache_write': '0.000000
00'}, 'top_provider': {'context_length': 128000, 'max_completion_tokens': 65536,
 'is_moderated': True}, 'per_request_limits': None, 'supported_parameters': ['ma
x_tokens', 'seed']}, {'id': 'mistralai/pixtral-12b', 'canonical_slug': 'mistrala
i/pixtral-12b', 'name': 'Mistral: Pixtral 12B', 'created': 1725926400, 'context_
length': 32768, 'architecture': {'input_modalities': ['text', 'image'], 'output_
modalities': ['text'], 'tokenizer': 'Mistral', 'instruct_type': None}, 'pricing'
: {'prompt': '0.00000880', 'completion': '0.00000880', 'image': '0.01272010', 'r
equest': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.0000
0000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'to
p_provider': {'context_length': 32768, 'max_completion_tokens': 0, 'is_moderated
': False}, 'per_request_limits': None, 'supported_parameters': ['frequency_penal
ty', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'repet
ition_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temper
ature', 'tool_choice', 'tools', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'cohe
re/command-r-08-2024', 'canonical_slug': 'cohere/command-r-08-2024', 'name': 'Co
here: Command R (08-2024)', 'created': 1724976000, 'context_length': 128000, 'ar
chitecture': {'input_modalities': ['text'], 'output_modalities': ['text'], 'toke
nizer': 'Cohere', 'instruct_type': None}, 'pricing': {'prompt': '0.00001320', 'c
ompletion': '0.00005282', 'image': '0.00000000', 'request': '0.00000000', 'web_s
earch': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0
.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length
': 128000, 'max_completion_tokens': 4000, 'is_moderated': True}, 'per_request_li
mits': None, 'supported_parameters': ['frequency_penalty', 'max_tokens', 'presen
ce_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperatu
re', 'tools', 'top_k', 'top_p']}, {'id': 'cohere/command-r-plus-08-2024', 'canon
ical_slug': 'cohere/command-r-plus-08-2024', 'name': 'Cohere: Command R+ (08-202
4)', 'created': 1724976000, 'context_length': 128000, 'architecture': {'input_mo
dalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Cohere', 'inst
ruct_type': None}, 'pricing': {'prompt': '0.00022007', 'completion': '0.00088028
', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', '
internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cach
e_write': '0.00000000'}, 'top_provider': {'context_length': 128000, 'max_complet
ion_tokens': 4000, 'is_moderated': True}, 'per_request_limits': None, 'supported
_parameters': ['frequency_penalty', 'max_tokens', 'presence_penalty', 'response_
format', 'seed', 'stop', 'structured_outputs', 'temperature', 'tools', 'top_k',
'top_p']}, {'id': 'sao10k/l3.1-euryale-70b', 'canonical_slug': 'sao10k/l3.1-eury
ale-70b', 'name': 'Sao10K: Llama 3.1 Euryale 70B v2.2', 'created': 1724803200, '
context_length': 32768, 'architecture': {'input_modalities': ['text'], 'output_m
odalities': ['text'], 'tokenizer': 'Llama3', 'instruct_type': 'llama3'}, 'pricin
g': {'prompt': '0.00005722', 'completion': '0.00006602', 'image': '0.00000000',
'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00
000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, '
top_provider': {'context_length': 32768, 'max_completion_tokens': 0, 'is_moderat
ed': False}, 'per_request_limits': None, 'supported_parameters': ['frequency_pen
alty', 'logit_bias', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_pena
lty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperature', 't
op_k', 'top_p']}, {'id': 'qwen/qwen-2.5-vl-7b-instruct', 'canonical_slug': 'qwen
/qwen-2-vl-7b-instruct', 'name': 'Qwen: Qwen2.5-VL 7B Instruct', 'created': 1724
803200, 'context_length': 32768, 'architecture': {'input_modalities': ['text', '
image'], 'output_modalities': ['text'], 'tokenizer': 'Qwen', 'instruct_type': No
ne}, 'pricing': {'prompt': '0.00001761', 'completion': '0.00001761', 'image': '0
.01272010', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reaso
ning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.0
0000000'}, 'top_provider': {'context_length': 32768, 'max_completion_tokens': 0,
 'is_moderated': False}, 'per_request_limits': None, 'supported_parameters': ['f
requency_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_pe
nalty', 'repetition_penalty', 'response_format', 'seed', 'stop', 'structured_out
puts', 'temperature', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'microsoft/phi-
3.5-mini-128k-instruct', 'canonical_slug': 'microsoft/phi-3.5-mini-128k-instruct
', 'name': 'Microsoft: Phi-3.5 Mini 128K Instruct', 'created': 1724198400, 'cont
ext_length': 128000, 'architecture': {'input_modalities': ['text'], 'output_moda
lities': ['text'], 'tokenizer': 'Other', 'instruct_type': 'phi3'}, 'pricing': {'
prompt': '0.00000880', 'completion': '0.00000880', 'image': '0.00000000', 'reque
st': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000
', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_pr
ovider': {'context_length': 128000, 'max_completion_tokens': 0, 'is_moderated':
False}, 'per_request_limits': None, 'supported_parameters': ['max_tokens', 'temp
erature', 'tool_choice', 'tools', 'top_p']}, {'id': 'nousresearch/hermes-3-llama
-3.1-70b', 'canonical_slug': 'nousresearch/hermes-3-llama-3.1-70b', 'name': 'Nou
s: Hermes 3 70B Instruct', 'created': 1723939200, 'context_length': 131072, 'arc
hitecture': {'input_modalities': ['text'], 'output_modalities': ['text'], 'token
izer': 'Llama3', 'instruct_type': 'chatml'}, 'pricing': {'prompt': '0.00000880',
 'completion': '0.00002465', 'image': '0.00000000', 'request': '0.00000000', 'we
b_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read':
 '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_len
gth': 131072, 'max_completion_tokens': 0, 'is_moderated': False}, 'per_request_l
imits': None, 'supported_parameters': ['frequency_penalty', 'logit_bias', 'logpr
obs', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_penalty', 'response
_format', 'seed', 'stop', 'structured_outputs', 'temperature', 'tool_choice', 't
ools', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'nousresearch/hermes-3-llama-3
.1-405b', 'canonical_slug': 'nousresearch/hermes-3-llama-3.1-405b', 'name': 'Nou
s: Hermes 3 405B Instruct', 'created': 1723766400, 'context_length': 131072, 'ar
chitecture': {'input_modalities': ['text'], 'output_modalities': ['text'], 'toke
nizer': 'Llama3', 'instruct_type': 'chatml'}, 'pricing': {'prompt': '0.00006162'
, 'completion': '0.00007042', 'image': '0.00000000', 'request': '0.00000000', 'w
eb_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read'
: '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_le
ngth': 131072, 'max_completion_tokens': 16384, 'is_moderated': False}, 'per_requ
est_limits': None, 'supported_parameters': ['frequency_penalty', 'logit_bias', '
logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_penalty', 'res
ponse_format', 'seed', 'stop', 'temperature', 'top_k', 'top_logprobs', 'top_p']}
, {'id': 'openai/chatgpt-4o-latest', 'canonical_slug': 'openai/chatgpt-4o-latest
', 'name': 'OpenAI: ChatGPT-4o', 'created': 1723593600, 'context_length': 128000
, 'architecture': {'input_modalities': ['text', 'image'], 'output_modalities': [
'text'], 'tokenizer': 'GPT', 'instruct_type': None}, 'pricing': {'prompt': '0.00
044014', 'completion': '0.00132043', 'image': '0.63600519', 'request': '0.000000
00', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cach
e_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'con
text_length': 128000, 'max_completion_tokens': 16384, 'is_moderated': True}, 'pe
r_request_limits': None, 'supported_parameters': ['frequency_penalty', 'logit_bi
as', 'logprobs', 'max_tokens', 'presence_penalty', 'response_format', 'seed', 's
top', 'structured_outputs', 'temperature', 'top_logprobs', 'top_p']}, {'id': 'sa
o10k/l3-lunaris-8b', 'canonical_slug': 'sao10k/l3-lunaris-8b', 'name': 'Sao10K:
Llama 3 8B Lunaris', 'created': 1723507200, 'context_length': 8192, 'architectur
e': {'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': '
Llama3', 'instruct_type': 'llama3'}, 'pricing': {'prompt': '0.00000176', 'comple
tion': '0.00000440', 'image': '0.00000000', 'request': '0.00000000', 'web_search
': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.0000
0000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 81
92, 'max_completion_tokens': 0, 'is_moderated': False}, 'per_request_limits': No
ne, 'supported_parameters': ['frequency_penalty', 'logit_bias', 'max_tokens', 'm
in_p', 'presence_penalty', 'repetition_penalty', 'response_format', 'seed', 'sto
p', 'temperature', 'top_k', 'top_p']}, {'id': 'openai/gpt-4o-2024-08-06', 'canon
ical_slug': 'openai/gpt-4o-2024-08-06', 'name': 'OpenAI: GPT-4o (2024-08-06)', '
created': 1722902400, 'context_length': 128000, 'architecture': {'input_modaliti
es': ['text', 'image', 'file'], 'output_modalities': ['text'], 'tokenizer': 'GPT
', 'instruct_type': None}, 'pricing': {'prompt': '0.00022007', 'completion': '0.
00088028', 'image': '0.31804661', 'request': '0.00000000', 'web_search': '0.0000
0000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00011004', 'in
put_cache_write': '0.00000000'}, 'top_provider': {'context_length': 128000, 'max
_completion_tokens': 16384, 'is_moderated': False}, 'per_request_limits': None,
'supported_parameters': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_tok
ens', 'presence_penalty', 'response_format', 'seed', 'stop', 'structured_outputs
', 'temperature', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'web_search_o
ptions']}, {'id': 'meta-llama/llama-3.1-405b', 'canonical_slug': 'meta-llama/lla
ma-3.1-405b', 'name': 'Meta: Llama 3.1 405B (base)', 'created': 1722556800, 'con
text_length': 32768, 'architecture': {'input_modalities': ['text'], 'output_moda
lities': ['text'], 'tokenizer': 'Llama3', 'instruct_type': 'none'}, 'pricing': {
'prompt': '0.00017606', 'completion': '0.00017606', 'image': '0.00000000', 'requ
est': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.0000000
0', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_p
rovider': {'context_length': 32768, 'max_completion_tokens': 0, 'is_moderated':
False}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty'
, 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty', 'repetiti
on_penalty', 'seed', 'stop', 'temperature', 'top_k', 'top_logprobs', 'top_p']},
{'id': 'meta-llama/llama-3.1-8b-instruct', 'canonical_slug': 'meta-llama/llama-3
.1-8b-instruct', 'name': 'Meta: Llama 3.1 8B Instruct', 'created': 1721692800, '
context_length': 131072, 'architecture': {'input_modalities': ['text'], 'output_
modalities': ['text'], 'tokenizer': 'Llama3', 'instruct_type': 'llama3'}, 'prici
ng': {'prompt': '0.00000132', 'completion': '0.00000176', 'image': '0.00000000',
 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.0
0000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'},
'top_provider': {'context_length': 131072, 'max_completion_tokens': 16384, 'is_m
oderated': False}, 'per_request_limits': None, 'supported_parameters': ['frequen
cy_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty'
, 'repetition_penalty', 'response_format', 'seed', 'stop', 'structured_outputs',
 'temperature', 'tool_choice', 'tools', 'top_k', 'top_logprobs', 'top_p']}, {'id
': 'meta-llama/llama-3.1-70b-instruct', 'canonical_slug': 'meta-llama/llama-3.1-
70b-instruct', 'name': 'Meta: Llama 3.1 70B Instruct', 'created': 1721692800, 'c
ontext_length': 131072, 'architecture': {'input_modalities': ['text'], 'output_m
odalities': ['text'], 'tokenizer': 'Llama3', 'instruct_type': 'llama3'}, 'pricin
g': {'prompt': '0.00000880', 'completion': '0.00002465', 'image': '0.00000000',
'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00
000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, '
top_provider': {'context_length': 131072, 'max_completion_tokens': 16384, 'is_mo
derated': False}, 'per_request_limits': None, 'supported_parameters': ['frequenc
y_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty',
 'repetition_penalty', 'response_format', 'seed', 'stop', 'structured_outputs',
'temperature', 'tool_choice', 'tools', 'top_k', 'top_logprobs', 'top_p']}, {'id'
: 'meta-llama/llama-3.1-405b-instruct', 'canonical_slug': 'meta-llama/llama-3.1-
405b-instruct', 'name': 'Meta: Llama 3.1 405B Instruct', 'created': 1721692800,
'context_length': 32768, 'architecture': {'input_modalities': ['text'], 'output_
modalities': ['text'], 'tokenizer': 'Llama3', 'instruct_type': 'llama3'}, 'prici
ng': {'prompt': '0.00007042', 'completion': '0.00007042', 'image': '0.00000000',
 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.0
0000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'},
'top_provider': {'context_length': 32768, 'max_completion_tokens': 16384, 'is_mo
derated': False}, 'per_request_limits': None, 'supported_parameters': ['frequenc
y_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty',
 'repetition_penalty', 'response_format', 'seed', 'stop', 'structured_outputs',
'temperature', 'tool_choice', 'tools', 'top_k', 'top_logprobs', 'top_p']}, {'id'
: 'mistralai/mistral-nemo', 'canonical_slug': 'mistralai/mistral-nemo', 'name':
'Mistral: Mistral Nemo', 'created': 1721347200, 'context_length': 32000, 'archit
ecture': {'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenize
r': 'Mistral', 'instruct_type': 'mistral'}, 'pricing': {'prompt': '0.00000066',
'completion': '0.00000440', 'image': '0.00000000', 'request': '0.00000000', 'web
_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read':
'0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_leng
th': 32000, 'max_completion_tokens': 0, 'is_moderated': False}, 'per_request_lim
its': None, 'supported_parameters': ['frequency_penalty', 'logit_bias', 'logprob
s', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_penalty', 'response_f
ormat', 'seed', 'stop', 'structured_outputs', 'temperature', 'tool_choice', 'too
ls', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'openai/gpt-4o-mini', 'canonical
_slug': 'openai/gpt-4o-mini', 'name': 'OpenAI: GPT-4o-mini', 'created': 17212608
00, 'context_length': 128000, 'architecture': {'input_modalities': ['text', 'ima
ge', 'file'], 'output_modalities': ['text'], 'tokenizer': 'GPT', 'instruct_type'
: None}, 'pricing': {'prompt': '0.00001320', 'completion': '0.00005282', 'image'
: '0.01910216', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_r
easoning': '0.00000000', 'input_cache_read': '0.00000660', 'input_cache_write':
'0.00000000'}, 'top_provider': {'context_length': 128000, 'max_completion_tokens
': 16384, 'is_moderated': True}, 'per_request_limits': None, 'supported_paramete
rs': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'presence_pen
alty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperature', '
tool_choice', 'tools', 'top_logprobs', 'top_p', 'web_search_options']}, {'id': '
openai/gpt-4o-mini-2024-07-18', 'canonical_slug': 'openai/gpt-4o-mini-2024-07-18
', 'name': 'OpenAI: GPT-4o-mini (2024-07-18)', 'created': 1721260800, 'context_l
ength': 128000, 'architecture': {'input_modalities': ['text', 'image', 'file'],
'output_modalities': ['text'], 'tokenizer': 'GPT', 'instruct_type': None}, 'pric
ing': {'prompt': '0.00001320', 'completion': '0.00005282', 'image': '0.63600519'
, 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.
00000000', 'input_cache_read': '0.00000660', 'input_cache_write': '0.00000000'},
 'top_provider': {'context_length': 128000, 'max_completion_tokens': 16384, 'is_
moderated': True}, 'per_request_limits': None, 'supported_parameters': ['frequen
cy_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'presence_penalty', 'respon
se_format', 'seed', 'stop', 'structured_outputs', 'temperature', 'tool_choice',
'tools', 'top_logprobs', 'top_p', 'web_search_options']}, {'id': 'google/gemma-2
-27b-it', 'canonical_slug': 'google/gemma-2-27b-it', 'name': 'Google: Gemma 2 27
B', 'created': 1720828800, 'context_length': 8192, 'architecture': {'input_modal
ities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Gemini', 'instruc
t_type': 'gemma'}, 'pricing': {'prompt': '0.00005722', 'completion': '0.00005722
', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', '
internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cach
e_write': '0.00000000'}, 'top_provider': {'context_length': 8192, 'max_completio
n_tokens': 0, 'is_moderated': False}, 'per_request_limits': None, 'supported_par
ameters': ['frequency_penalty', 'max_tokens', 'presence_penalty', 'response_form
at', 'stop', 'structured_outputs', 'temperature', 'top_p']}, {'id': 'google/gemm
a-2-9b-it', 'canonical_slug': 'google/gemma-2-9b-it', 'name': 'Google: Gemma 2 9
B', 'created': 1719532800, 'context_length': 8192, 'architecture': {'input_modal
ities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Gemini', 'instruc
t_type': 'gemma'}, 'pricing': {'prompt': '0.00000088', 'completion': '0.00000088
', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', '
internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cach
e_write': '0.00000000'}, 'top_provider': {'context_length': 8192, 'max_completio
n_tokens': 8192, 'is_moderated': False}, 'per_request_limits': None, 'supported_
parameters': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'min_
p', 'presence_penalty', 'repetition_penalty', 'response_format', 'seed', 'stop',
 'temperature', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'anthropic/claude-3.5
-sonnet-20240620', 'canonical_slug': 'anthropic/claude-3.5-sonnet-20240620', 'na
me': 'Anthropic: Claude 3.5 Sonnet (2024-06-20)', 'created': 1718841600, 'contex
t_length': 200000, 'architecture': {'input_modalities': ['text', 'image', 'file'
], 'output_modalities': ['text'], 'tokenizer': 'Claude', 'instruct_type': None},
 'pricing': {'prompt': '0.00026409', 'completion': '0.00132043', 'image': '0.422
53632', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning
': '0.00000000', 'input_cache_read': '0.00002641', 'input_cache_write': '0.00033
011'}, 'top_provider': {'context_length': 200000, 'max_completion_tokens': 8192,
 'is_moderated': True}, 'per_request_limits': None, 'supported_parameters': ['ma
x_tokens', 'stop', 'temperature', 'tool_choice', 'tools', 'top_k', 'top_p']}, {'
id': 'sao10k/l3-euryale-70b', 'canonical_slug': 'sao10k/l3-euryale-70b', 'name':
 'Sao10k: Llama 3 Euryale 70B v2.1', 'created': 1718668800, 'context_length': 81
92, 'architecture': {'input_modalities': ['text'], 'output_modalities': ['text']
, 'tokenizer': 'Llama3', 'instruct_type': 'llama3'}, 'pricing': {'prompt': '0.00
013028', 'completion': '0.00013028', 'image': '0.00000000', 'request': '0.000000
00', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cach
e_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'con
text_length': 8192, 'max_completion_tokens': 8192, 'is_moderated': False}, 'per_
request_limits': None, 'supported_parameters': ['frequency_penalty', 'logit_bias
', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_penalty', 'seed', 'sto
p', 'temperature', 'top_k', 'top_p']}, {'id': 'cognitivecomputations/dolphin-mix
tral-8x22b', 'canonical_slug': 'cognitivecomputations/dolphin-mixtral-8x22b', 'n
ame': 'Dolphin 2.9.2 Mixtral 8x22B ', 'created': 1717804800, 'context_length':
 16000, 'architecture': {'input_modalities': ['text'], 'output_modalities': ['te
xt'], 'tokenizer': 'Mistral', 'instruct_type': 'chatml'}, 'pricing': {'prompt':
'0.00007923', 'completion': '0.00007923', 'image': '0.00000000', 'request': '0.0
0000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input
_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider':
{'context_length': 16000, 'max_completion_tokens': 8192, 'is_moderated': False},
 'per_request_limits': None, 'supported_parameters': ['frequency_penalty', 'logi
t_bias', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_penalty', 'seed'
, 'stop', 'temperature', 'top_k', 'top_p']}, {'id': 'qwen/qwen-2-72b-instruct',
'canonical_slug': 'qwen/qwen-2-72b-instruct', 'name': 'Qwen 2 72B Instruct', 'cr
eated': 1717718400, 'context_length': 32768, 'architecture': {'input_modalities'
: ['text'], 'output_modalities': ['text'], 'tokenizer': 'Qwen', 'instruct_type':
 'chatml'}, 'pricing': {'prompt': '0.00007923', 'completion': '0.00007923', 'ima
ge': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'interna
l_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write
': '0.00000000'}, 'top_provider': {'context_length': 32768, 'max_completion_toke
ns': 4096, 'is_moderated': False}, 'per_request_limits': None, 'supported_parame
ters': ['frequency_penalty', 'logit_bias', 'max_tokens', 'min_p', 'presence_pena
lty', 'repetition_penalty', 'stop', 'temperature', 'top_k', 'top_p']}, {'id': 'm
istralai/mistral-7b-instruct-v0.3', 'canonical_slug': 'mistralai/mistral-7b-inst
ruct-v0.3', 'name': 'Mistral: Mistral 7B Instruct v0.3', 'created': 1716768000,
'context_length': 32768, 'architecture': {'input_modalities': ['text'], 'output_
modalities': ['text'], 'tokenizer': 'Mistral', 'instruct_type': 'mistral'}, 'pri
cing': {'prompt': '0.00000246', 'completion': '0.00000475', 'image': '0.00000000
', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0
.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}
, 'top_provider': {'context_length': 32768, 'max_completion_tokens': 16384, 'is_
moderated': False}, 'per_request_limits': None, 'supported_parameters': ['freque
ncy_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'presence_penalty
', 'repetition_penalty', 'response_format', 'seed', 'stop', 'temperature', 'tool
_choice', 'tools', 'top_k', 'top_p']}, {'id': 'mistralai/mistral-7b-instruct', '
canonical_slug': 'mistralai/mistral-7b-instruct', 'name': 'Mistral: Mistral 7B I
nstruct', 'created': 1716768000, 'context_length': 32768, 'architecture': {'inpu
t_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Mistral',
'instruct_type': 'mistral'}, 'pricing': {'prompt': '0.00000246', 'completion': '
0.00000475', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00
000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', '
input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 32768, 'ma
x_completion_tokens': 16384, 'is_moderated': False}, 'per_request_limits': None,
 'supported_parameters': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_to
kens', 'min_p', 'presence_penalty', 'repetition_penalty', 'response_format', 'se
ed', 'stop', 'temperature', 'tool_choice', 'tools', 'top_k', 'top_p']}, {'id': '
nousresearch/hermes-2-pro-llama-3-8b', 'canonical_slug': 'nousresearch/hermes-2-
pro-llama-3-8b', 'name': 'NousResearch: Hermes 2 Pro - Llama-3 8B', 'created': 1
716768000, 'context_length': 131072, 'architecture': {'input_modalities': ['text
'], 'output_modalities': ['text'], 'tokenizer': 'Llama3', 'instruct_type': 'chat
ml'}, 'pricing': {'prompt': '0.00000220', 'completion': '0.00000352', 'image': '
0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reas
oning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.
00000000'}, 'top_provider': {'context_length': 131072, 'max_completion_tokens':
131072, 'is_moderated': False}, 'per_request_limits': None, 'supported_parameter
s': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'min_p', 'pres
ence_penalty', 'repetition_penalty', 'response_format', 'seed', 'stop', 'structu
red_outputs', 'temperature', 'top_k', 'top_logprobs', 'top_p']}, {'id': 'microso
ft/phi-3-mini-128k-instruct', 'canonical_slug': 'microsoft/phi-3-mini-128k-instr
uct', 'name': 'Microsoft: Phi-3 Mini 128K Instruct', 'created': 1716681600, 'con
text_length': 128000, 'architecture': {'input_modalities': ['text'], 'output_mod
alities': ['text'], 'tokenizer': 'Other', 'instruct_type': 'phi3'}, 'pricing': {
'prompt': '0.00000880', 'completion': '0.00000880', 'image': '0.00000000', 'requ
est': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.0000000
0', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_p
rovider': {'context_length': 128000, 'max_completion_tokens': 0, 'is_moderated':
 False}, 'per_request_limits': None, 'supported_parameters': ['max_tokens', 'tem
perature', 'tool_choice', 'tools', 'top_p']}, {'id': 'microsoft/phi-3-medium-128
k-instruct', 'canonical_slug': 'microsoft/phi-3-medium-128k-instruct', 'name': '
Microsoft: Phi-3 Medium 128K Instruct', 'created': 1716508800, 'context_length':
 128000, 'architecture': {'input_modalities': ['text'], 'output_modalities': ['t
ext'], 'tokenizer': 'Other', 'instruct_type': 'phi3'}, 'pricing': {'prompt': '0.
00008803', 'completion': '0.00008803', 'image': '0.00000000', 'request': '0.0000
0000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_ca
che_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'c
ontext_length': 128000, 'max_completion_tokens': 0, 'is_moderated': False}, 'per
_request_limits': None, 'supported_parameters': ['max_tokens', 'temperature', 't
ool_choice', 'tools', 'top_p']}, {'id': 'neversleep/llama-3-lumimaid-70b', 'cano
nical_slug': 'neversleep/llama-3-lumimaid-70b', 'name': 'NeverSleep: Llama 3 Lum
imaid 70B', 'created': 1715817600, 'context_length': 8192, 'architecture': {'inp
ut_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Llama3',
'instruct_type': 'llama3'}, 'pricing': {'prompt': '0.00035211', 'completion': '0
.00052817', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.000
00000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'i
nput_cache_write': '0.00000000'}, 'top_provider': {'context_length': 8192, 'max_
completion_tokens': 4096, 'is_moderated': False}, 'per_request_limits': None, 's
upported_parameters': ['frequency_penalty', 'max_tokens', 'min_p', 'presence_pen
alty', 'repetition_penalty', 'seed', 'stop', 'temperature', 'top_k', 'top_p']},
{'id': 'google/gemini-flash-1.5', 'canonical_slug': 'google/gemini-flash-1.5', '
name': 'Google: Gemini 1.5 Flash ', 'created': 1715644800, 'context_length': 100
0000, 'architecture': {'input_modalities': ['text', 'image'], 'output_modalities
': ['text'], 'tokenizer': 'Gemini', 'instruct_type': None}, 'pricing': {'prompt'
: '0.00000660', 'completion': '0.00002641', 'image': '0.00352114', 'request': '0
.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'inp
ut_cache_read': '0.00000165', 'input_cache_write': '0.00001393'}, 'top_provider'
: {'context_length': 1000000, 'max_completion_tokens': 8192, 'is_moderated': Fal
se}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty', '
max_tokens', 'presence_penalty', 'response_format', 'seed', 'stop', 'structured_
outputs', 'temperature', 'tool_choice', 'tools', 'top_p']}, {'id': 'openai/gpt-4
o', 'canonical_slug': 'openai/gpt-4o', 'name': 'OpenAI: GPT-4o', 'created': 1715
558400, 'context_length': 128000, 'architecture': {'input_modalities': ['text',
'image', 'file'], 'output_modalities': ['text'], 'tokenizer': 'GPT', 'instruct_t
ype': None}, 'pricing': {'prompt': '0.00022007', 'completion': '0.00088028', 'im
age': '0.31804661', 'request': '0.00000000', 'web_search': '0.00000000', 'intern
al_reasoning': '0.00000000', 'input_cache_read': '0.00011004', 'input_cache_writ
e': '0.00000000'}, 'top_provider': {'context_length': 128000, 'max_completion_to
kens': 16384, 'is_moderated': True}, 'per_request_limits': None, 'supported_para
meters': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'presence
_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperature
', 'tool_choice', 'tools', 'top_logprobs', 'top_p', 'web_search_options']}, {'id
': 'openai/gpt-4o:extended', 'canonical_slug': 'openai/gpt-4o', 'name': 'OpenAI:
 GPT-4o (extended)', 'created': 1715558400, 'context_length': 128000, 'architect
ure': {'input_modalities': ['text', 'image', 'file'], 'output_modalities': ['tex
t'], 'tokenizer': 'GPT', 'instruct_type': None}, 'pricing': {'prompt': '0.000528
17', 'completion': '0.00158451', 'image': '0.63600519', 'request': '0.00000000',
 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_re
ad': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context
_length': 128000, 'max_completion_tokens': 64000, 'is_moderated': True}, 'per_re
quest_limits': None, 'supported_parameters': ['frequency_penalty', 'logit_bias',
 'logprobs', 'max_tokens', 'presence_penalty', 'response_format', 'seed', 'stop'
, 'structured_outputs', 'temperature', 'tool_choice', 'tools', 'top_logprobs', '
top_p', 'web_search_options']}, {'id': 'meta-llama/llama-guard-2-8b', 'canonical
_slug': 'meta-llama/llama-guard-2-8b', 'name': 'Meta: LlamaGuard 2 8B', 'created
': 1715558400, 'context_length': 8192, 'architecture': {'input_modalities': ['te
xt'], 'output_modalities': ['text'], 'tokenizer': 'Llama3', 'instruct_type': 'no
ne'}, 'pricing': {'prompt': '0.00001761', 'completion': '0.00001761', 'image': '
0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reas
oning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.
00000000'}, 'top_provider': {'context_length': 8192, 'max_completion_tokens': 0,
 'is_moderated': False}, 'per_request_limits': None, 'supported_parameters': ['f
requency_penalty', 'logit_bias', 'max_tokens', 'min_p', 'presence_penalty', 'rep
etition_penalty', 'stop', 'temperature', 'top_k', 'top_p']}, {'id': 'openai/gpt-
4o-2024-05-13', 'canonical_slug': 'openai/gpt-4o-2024-05-13', 'name': 'OpenAI: G
PT-4o (2024-05-13)', 'created': 1715558400, 'context_length': 128000, 'architect
ure': {'input_modalities': ['text', 'image', 'file'], 'output_modalities': ['tex
t'], 'tokenizer': 'GPT', 'instruct_type': None}, 'pricing': {'prompt': '0.000440
14', 'completion': '0.00132043', 'image': '0.63600519', 'request': '0.00000000',
 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_re
ad': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context
_length': 128000, 'max_completion_tokens': 4096, 'is_moderated': True}, 'per_req
uest_limits': None, 'supported_parameters': ['frequency_penalty', 'logit_bias',
'logprobs', 'max_tokens', 'presence_penalty', 'response_format', 'seed', 'stop',
 'structured_outputs', 'temperature', 'tool_choice', 'tools', 'top_logprobs', 't
op_p', 'web_search_options']}, {'id': 'meta-llama/llama-3-70b-instruct', 'canoni
cal_slug': 'meta-llama/llama-3-70b-instruct', 'name': 'Meta: Llama 3 70B Instruc
t', 'created': 1713398400, 'context_length': 8192, 'architecture': {'input_modal
ities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Llama3', 'instruc
t_type': 'llama3'}, 'pricing': {'prompt': '0.00002641', 'completion': '0.0000352
1', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000',
'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cac
he_write': '0.00000000'}, 'top_provider': {'context_length': 8192, 'max_completi
on_tokens': 16384, 'is_moderated': False}, 'per_request_limits': None, 'supporte
d_parameters': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'mi
n_p', 'presence_penalty', 'repetition_penalty', 'response_format', 'seed', 'stop
', 'temperature', 'tool_choice', 'tools', 'top_k', 'top_logprobs', 'top_p']}, {'
id': 'meta-llama/llama-3-8b-instruct', 'canonical_slug': 'meta-llama/llama-3-8b-
instruct', 'name': 'Meta: Llama 3 8B Instruct', 'created': 1713398400, 'context_
length': 8192, 'architecture': {'input_modalities': ['text'], 'output_modalities
': ['text'], 'tokenizer': 'Llama3', 'instruct_type': 'llama3'}, 'pricing': {'pro
mpt': '0.00000264', 'completion': '0.00000528', 'image': '0.00000000', 'request'
: '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000',
'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provi
der': {'context_length': 8192, 'max_completion_tokens': 16384, 'is_moderated': F
alse}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty',
 'logit_bias', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_penalty',
'response_format', 'seed', 'stop', 'temperature', 'tool_choice', 'tools', 'top_k
', 'top_p']}, {'id': 'mistralai/mixtral-8x22b-instruct', 'canonical_slug': 'mist
ralai/mixtral-8x22b-instruct', 'name': 'Mistral: Mixtral 8x22B Instruct', 'creat
ed': 1713312000, 'context_length': 65536, 'architecture': {'input_modalities': [
'text'], 'output_modalities': ['text'], 'tokenizer': 'Mistral', 'instruct_type':
 'mistral'}, 'pricing': {'prompt': '0.00007923', 'completion': '0.00007923', 'im
age': '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'intern
al_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_writ
e': '0.00000000'}, 'top_provider': {'context_length': 65536, 'max_completion_tok
ens': 0, 'is_moderated': False}, 'per_request_limits': None, 'supported_paramete
rs': ['frequency_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'presence_pen
alty', 'repetition_penalty', 'response_format', 'seed', 'stop', 'structured_outp
uts', 'temperature', 'tool_choice', 'tools', 'top_k', 'top_logprobs', 'top_p']},
 {'id': 'microsoft/wizardlm-2-8x22b', 'canonical_slug': 'microsoft/wizardlm-2-8x
22b', 'name': 'WizardLM-2 8x22B', 'created': 1713225600, 'context_length': 65536
, 'architecture': {'input_modalities': ['text'], 'output_modalities': ['text'],
'tokenizer': 'Mistral', 'instruct_type': 'vicuna'}, 'pricing': {'prompt': '0.000
04225', 'completion': '0.00004225', 'image': '0.00000000', 'request': '0.0000000
0', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache
_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'cont
ext_length': 65536, 'max_completion_tokens': 65536, 'is_moderated': False}, 'per
_request_limits': None, 'supported_parameters': ['frequency_penalty', 'logit_bia
s', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_penalty', 'response_f
ormat', 'seed', 'stop', 'temperature', 'top_k', 'top_p']}, {'id': 'google/gemini
-pro-1.5', 'canonical_slug': 'google/gemini-pro-1.5', 'name': 'Google: Gemini 1.
5 Pro', 'created': 1712620800, 'context_length': 2000000, 'architecture': {'inpu
t_modalities': ['text', 'image'], 'output_modalities': ['text'], 'tokenizer': 'G
emini', 'instruct_type': None}, 'pricing': {'prompt': '0.00011004', 'completion'
: '0.00044014', 'image': '0.05787867', 'request': '0.00000000', 'web_search': '0
.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000'
, 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 2000000
, 'max_completion_tokens': 8192, 'is_moderated': False}, 'per_request_limits': N
one, 'supported_parameters': ['frequency_penalty', 'max_tokens', 'presence_penal
ty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperature', 'to
ol_choice', 'tools', 'top_p']}, {'id': 'openai/gpt-4-turbo', 'canonical_slug': '
openai/gpt-4-turbo', 'name': 'OpenAI: GPT-4 Turbo', 'created': 1712620800, 'cont
ext_length': 128000, 'architecture': {'input_modalities': ['text', 'image'], 'ou
tput_modalities': ['text'], 'tokenizer': 'GPT', 'instruct_type': None}, 'pricing
': {'prompt': '0.00088028', 'completion': '0.00264085', 'image': '1.27201038', '
request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.000
00000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 't
op_provider': {'context_length': 128000, 'max_completion_tokens': 4096, 'is_mode
rated': True}, 'per_request_limits': None, 'supported_parameters': ['frequency_p
enalty', 'logit_bias', 'logprobs', 'max_tokens', 'presence_penalty', 'response_f
ormat', 'seed', 'stop', 'structured_outputs', 'temperature', 'tool_choice', 'too
ls', 'top_logprobs', 'top_p']}, {'id': 'cohere/command-r-plus', 'canonical_slug'
: 'cohere/command-r-plus', 'name': 'Cohere: Command R+', 'created': 1712188800,
'context_length': 128000, 'architecture': {'input_modalities': ['text'], 'output
_modalities': ['text'], 'tokenizer': 'Cohere', 'instruct_type': None}, 'pricing'
: {'prompt': '0.00026409', 'completion': '0.00132043', 'image': '0.00000000', 'r
equest': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.0000
0000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'to
p_provider': {'context_length': 128000, 'max_completion_tokens': 4000, 'is_moder
ated': True}, 'per_request_limits': None, 'supported_parameters': ['frequency_pe
nalty', 'max_tokens', 'presence_penalty', 'response_format', 'seed', 'stop', 'st
ructured_outputs', 'temperature', 'tools', 'top_k', 'top_p']}, {'id': 'cohere/co
mmand-r-plus-04-2024', 'canonical_slug': 'cohere/command-r-plus-04-2024', 'name'
: 'Cohere: Command R+ (04-2024)', 'created': 1712016000, 'context_length': 12800
0, 'architecture': {'input_modalities': ['text'], 'output_modalities': ['text'],
 'tokenizer': 'Cohere', 'instruct_type': None}, 'pricing': {'prompt': '0.0002640
9', 'completion': '0.00132043', 'image': '0.00000000', 'request': '0.00000000',
'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_rea
d': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_
length': 128000, 'max_completion_tokens': 4000, 'is_moderated': True}, 'per_requ
est_limits': None, 'supported_parameters': ['frequency_penalty', 'max_tokens', '
presence_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'tem
perature', 'tools', 'top_k', 'top_p']}, {'id': 'sophosympatheia/midnight-rose-70
b', 'canonical_slug': 'sophosympatheia/midnight-rose-70b', 'name': 'Midnight Ros
e 70B', 'created': 1711065600, 'context_length': 4096, 'architecture': {'input_m
odalities': ['text'], 'output_modalities': ['text'], 'tokenizer': 'Llama2', 'ins
truct_type': 'airoboros'}, 'pricing': {'prompt': '0.00007042', 'completion': '0.
00007042', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '0.0000
0000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000', 'in
put_cache_write': '0.00000000'}, 'top_provider': {'context_length': 4096, 'max_c
ompletion_tokens': 2048, 'is_moderated': False}, 'per_request_limits': None, 'su
pported_parameters': ['frequency_penalty', 'logit_bias', 'max_tokens', 'min_p',
'presence_penalty', 'repetition_penalty', 'seed', 'stop', 'temperature', 'top_k'
, 'top_p']}, {'id': 'cohere/command', 'canonical_slug': 'cohere/command', 'name'
: 'Cohere: Command', 'created': 1710374400, 'context_length': 4096, 'architectur
e': {'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer': '
Cohere', 'instruct_type': None}, 'pricing': {'prompt': '0.00008803', 'completion
': '0.00017606', 'image': '0.00000000', 'request': '0.00000000', 'web_search': '
0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.00000000
', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length': 4096,
'max_completion_tokens': 4000, 'is_moderated': True}, 'per_request_limits': None
, 'supported_parameters': ['frequency_penalty', 'max_tokens', 'presence_penalty'
, 'response_format', 'seed', 'stop', 'structured_outputs', 'temperature', 'top_k
', 'top_p']}, {'id': 'cohere/command-r', 'canonical_slug': 'cohere/command-r', '
name': 'Cohere: Command R', 'created': 1710374400, 'context_length': 128000, 'ar
chitecture': {'input_modalities': ['text'], 'output_modalities': ['text'], 'toke
nizer': 'Cohere', 'instruct_type': None}, 'pricing': {'prompt': '0.00004401', 'c
ompletion': '0.00013204', 'image': '0.00000000', 'request': '0.00000000', 'web_s
earch': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0
.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length
': 128000, 'max_completion_tokens': 4000, 'is_moderated': True}, 'per_request_li
mits': None, 'supported_parameters': ['frequency_penalty', 'max_tokens', 'presen
ce_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperatu
re', 'tools', 'top_k', 'top_p']}, {'id': 'anthropic/claude-3-haiku', 'canonical_
slug': 'anthropic/claude-3-haiku', 'name': 'Anthropic: Claude 3 Haiku', 'created
': 1710288000, 'context_length': 200000, 'architecture': {'input_modalities': ['
text', 'image'], 'output_modalities': ['text'], 'tokenizer': 'Claude', 'instruct
_type': None}, 'pricing': {'prompt': '0.00002201', 'completion': '0.00011004', '
image': '0.03521136', 'request': '0.00000000', 'web_search': '0.00000000', 'inte
rnal_reasoning': '0.00000000', 'input_cache_read': '0.00000264', 'input_cache_wr
ite': '0.00002641'}, 'top_provider': {'context_length': 200000, 'max_completion_
tokens': 4096, 'is_moderated': True}, 'per_request_limits': None, 'supported_par
ameters': ['max_tokens', 'stop', 'temperature', 'tool_choice', 'tools', 'top_k',
 'top_p']}, {'id': 'anthropic/claude-3-opus', 'canonical_slug': 'anthropic/claud
e-3-opus', 'name': 'Anthropic: Claude 3 Opus', 'created': 1709596800, 'context_l
ength': 200000, 'architecture': {'input_modalities': ['text', 'image'], 'output_
modalities': ['text'], 'tokenizer': 'Claude', 'instruct_type': None}, 'pricing':
 {'prompt': '0.00132043', 'completion': '0.00660213', 'image': '2.11268160', 're
quest': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000
000', 'input_cache_read': '0.00013204', 'input_cache_write': '0.00165053'}, 'top
_provider': {'context_length': 200000, 'max_completion_tokens': 4096, 'is_modera
ted': True}, 'per_request_limits': None, 'supported_parameters': ['max_tokens',
'stop', 'temperature', 'tool_choice', 'tools', 'top_k', 'top_p']}, {'id': 'coher
e/command-r-03-2024', 'canonical_slug': 'cohere/command-r-03-2024', 'name': 'Coh
ere: Command R (03-2024)', 'created': 1709341200, 'context_length': 128000, 'arc
hitecture': {'input_modalities': ['text'], 'output_modalities': ['text'], 'token
izer': 'Cohere', 'instruct_type': None}, 'pricing': {'prompt': '0.00004401', 'co
mpletion': '0.00013204', 'image': '0.00000000', 'request': '0.00000000', 'web_se
arch': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.
00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length'
: 128000, 'max_completion_tokens': 4000, 'is_moderated': True}, 'per_request_lim
its': None, 'supported_parameters': ['frequency_penalty', 'max_tokens', 'presenc
e_penalty', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperatur
e', 'tools', 'top_k', 'top_p']}, {'id': 'mistralai/mistral-large', 'canonical_sl
ug': 'mistralai/mistral-large', 'name': 'Mistral Large', 'created': 1708905600,
'context_length': 128000, 'architecture': {'input_modalities': ['text'], 'output
_modalities': ['text'], 'tokenizer': 'Mistral', 'instruct_type': None}, 'pricing
': {'prompt': '0.00017606', 'completion': '0.00052817', 'image': '0.00000000', '
request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.000
00000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 't
op_provider': {'context_length': 128000, 'max_completion_tokens': 0, 'is_moderat
ed': False}, 'per_request_limits': None, 'supported_parameters': ['frequency_pen
alty', 'max_tokens', 'presence_penalty', 'response_format', 'seed', 'stop', 'str
uctured_outputs', 'temperature', 'tool_choice', 'tools', 'top_p']}, {'id': 'open
ai/gpt-4-turbo-preview', 'canonical_slug': 'openai/gpt-4-turbo-preview', 'name':
 'OpenAI: GPT-4 Turbo Preview', 'created': 1706140800, 'context_length': 128000,
 'architecture': {'input_modalities': ['text'], 'output_modalities': ['text'], '
tokenizer': 'GPT', 'instruct_type': None}, 'pricing': {'prompt': '0.00088028', '
completion': '0.00264085', 'image': '0.00000000', 'request': '0.00000000', 'web_
search': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '
0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_lengt
h': 128000, 'max_completion_tokens': 4096, 'is_moderated': True}, 'per_request_l
imits': None, 'supported_parameters': ['frequency_penalty', 'logit_bias', 'logpr
obs', 'max_tokens', 'presence_penalty', 'response_format', 'seed', 'stop', 'stru
ctured_outputs', 'temperature', 'tool_choice', 'tools', 'top_logprobs', 'top_p']
}, {'id': 'openai/gpt-3.5-turbo-0613', 'canonical_slug': 'openai/gpt-3.5-turbo-0
613', 'name': 'OpenAI: GPT-3.5 Turbo (older v0613)', 'created': 1706140800, 'con
text_length': 4095, 'architecture': {'input_modalities': ['text'], 'output_modal
ities': ['text'], 'tokenizer': 'GPT', 'instruct_type': None}, 'pricing': {'promp
t': '0.00008803', 'completion': '0.00017606', 'image': '0.00000000', 'request':
'0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'i
nput_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provide
r': {'context_length': 4095, 'max_completion_tokens': 4096, 'is_moderated': Fals
e}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty', 'l
ogit_bias', 'logprobs', 'max_tokens', 'presence_penalty', 'response_format', 'se
ed', 'stop', 'structured_outputs', 'temperature', 'tool_choice', 'tools', 'top_l
ogprobs', 'top_p']}, {'id': 'nousresearch/nous-hermes-2-mixtral-8x7b-dpo', 'cano
nical_slug': 'nousresearch/nous-hermes-2-mixtral-8x7b-dpo', 'name': 'Nous: Herme
s 2 Mixtral 8x7B DPO', 'created': 1705363200, 'context_length': 32768, 'architec
ture': {'input_modalities': ['text'], 'output_modalities': ['text'], 'tokenizer'
: 'Mistral', 'instruct_type': 'chatml'}, 'pricing': {'prompt': '0.00005282', 'co
mpletion': '0.00005282', 'image': '0.00000000', 'request': '0.00000000', 'web_se
arch': '0.00000000', 'internal_reasoning': '0.00000000', 'input_cache_read': '0.
00000000', 'input_cache_write': '0.00000000'}, 'top_provider': {'context_length'
: 32768, 'max_completion_tokens': 2048, 'is_moderated': False}, 'per_request_lim
its': None, 'supported_parameters': ['frequency_penalty', 'logit_bias', 'max_tok
ens', 'min_p', 'presence_penalty', 'repetition_penalty', 'stop', 'temperature',
'top_k', 'top_p']}, {'id': 'mistralai/mistral-small', 'canonical_slug': 'mistral
ai/mistral-small', 'name': 'Mistral Small', 'created': 1704844800, 'context_leng
th': 32768, 'architecture': {'input_modalities': ['text'], 'output_modalities':
['text'], 'tokenizer': 'Mistral', 'instruct_type': None}, 'pricing': {'prompt':
'0.00001761', 'completion': '0.00005282', 'image': '0.00000000', 'request': '0.0
0000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'input
_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provider':
{'context_length': 32768, 'max_completion_tokens': 0, 'is_moderated': False}, 'p
er_request_limits': None, 'supported_parameters': ['frequency_penalty', 'max_tok
ens', 'presence_penalty', 'response_format', 'seed', 'stop', 'structured_outputs
', 'temperature', 'tool_choice', 'tools', 'top_p']}, {'id': 'mistralai/mistral-t
iny', 'canonical_slug': 'mistralai/mistral-tiny', 'name': 'Mistral Tiny', 'creat
ed': 1704844800, 'context_length': 32768, 'architecture': {'input_modalities': [
'text'], 'output_modalities': ['text'], 'tokenizer': 'Mistral', 'instruct_type':
 None}, 'pricing': {'prompt': '0.00002201', 'completion': '0.00002201', 'image':
 '0.00000000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_re
asoning': '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '
0.00000000'}, 'top_provider': {'context_length': 32768, 'max_completion_tokens':
 0, 'is_moderated': False}, 'per_request_limits': None, 'supported_parameters':
['frequency_penalty', 'max_tokens', 'presence_penalty', 'response_format', 'seed
', 'stop', 'structured_outputs', 'temperature', 'tool_choice', 'tools', 'top_p']
}, {'id': 'mistralai/mixtral-8x7b-instruct', 'canonical_slug': 'mistralai/mixtra
l-8x7b-instruct', 'name': 'Mistral: Mixtral 8x7B Instruct', 'created': 170216640
0, 'context_length': 32768, 'architecture': {'input_modalities': ['text'], 'outp
ut_modalities': ['text'], 'tokenizer': 'Mistral', 'instruct_type': 'mistral'}, '
pricing': {'prompt': '0.00000704', 'completion': '0.00002113', 'image': '0.00000
000', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning':
 '0.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.0000000
0'}, 'top_provider': {'context_length': 32768, 'max_completion_tokens': 16384, '
is_moderated': False}, 'per_request_limits': None, 'supported_parameters': ['fre
quency_penalty', 'logit_bias', 'max_tokens', 'min_p', 'presence_penalty', 'repet
ition_penalty', 'response_format', 'seed', 'stop', 'temperature', 'tool_choice',
 'tools', 'top_k', 'top_p']}, {'id': 'neversleep/noromaid-20b', 'canonical_slug'
: 'neversleep/noromaid-20b', 'name': 'Noromaid 20B', 'created': 1700956800, 'con
text_length': 4096, 'architecture': {'input_modalities': ['text'], 'output_modal
ities': ['text'], 'tokenizer': 'Llama2', 'instruct_type': 'alpaca'}, 'pricing':
{'prompt': '0.00008803', 'completion': '0.00015405', 'image': '0.00000000', 'req
uest': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.000000
00', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_
provider': {'context_length': 4096, 'max_completion_tokens': 0, 'is_moderated':
False}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty'
, 'logit_bias', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_penalty',
 'response_format', 'seed', 'stop', 'structured_outputs', 'temperature', 'top_a'
, 'top_k', 'top_p']}, {'id': 'alpindale/goliath-120b', 'canonical_slug': 'alpind
ale/goliath-120b', 'name': 'Goliath 120B', 'created': 1699574400, 'context_lengt
h': 6144, 'architecture': {'input_modalities': ['text'], 'output_modalities': ['
text'], 'tokenizer': 'Llama2', 'instruct_type': 'airoboros'}, 'pricing': {'promp
t': '0.00035211', 'completion': '0.00048416', 'image': '0.00000000', 'request':
'0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0.00000000', 'i
nput_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}, 'top_provide
r': {'context_length': 6144, 'max_completion_tokens': 512, 'is_moderated': False
}, 'per_request_limits': None, 'supported_parameters': ['frequency_penalty', 'lo
git_bias', 'max_tokens', 'min_p', 'presence_penalty', 'repetition_penalty', 'res
ponse_format', 'seed', 'stop', 'structured_outputs', 'temperature', 'top_a', 'to
p_k', 'top_p']}, {'id': 'openai/gpt-4-1106-preview', 'canonical_slug': 'openai/g
pt-4-1106-preview', 'name': 'OpenAI: GPT-4 Turbo (older v1106)', 'created': 1699
228800, 'context_length': 128000, 'architecture': {'input_modalities': ['text'],
 'output_modalities': ['text'], 'tokenizer': 'GPT', 'instruct_type': None}, 'pri
cing': {'prompt': '0.00088028', 'completion': '0.00264085', 'image': '0.00000000
', 'request': '0.00000000', 'web_search': '0.00000000', 'internal_reasoning': '0
.00000000', 'input_cache_read': '0.00000000', 'input_cache_write': '0.00000000'}
, 'top_provider': {'context_length': 128000, 'max_completion_tokens': 4096, 'is_
